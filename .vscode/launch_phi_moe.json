{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python Debugger: Current File with Arguments",
            "type": "debugpy",
            "request": "launch",
            "program": "/home/data_llm/anaconda3/envs/moellava/bin/deepspeed",
            "console": "integratedTerminal",
            "cwd": "/home/data_llm/madehua/FoodHealthMMLLM",
            "args": [
                "--include=localhost:2,3,4",
                "--master_addr=127.0.0.1",
                "--master_port=2241",
                "--enable_each_rank_log=None",
                "/home/data_llm/FoodHealthMMLLM/moellava/train/train_xformers.py",
                "--moe_enable=True",
                "--num_experts=4",
                "--top_k_experts=2",
                "--capacity_factor=1.5",
                "--moe_mode=sparse",
                "--use_residual=False",
                "--router_aux_loss_coef=0.01",
                "--train_modules=fc1,fc2,wg",
                "--deepspeed=/home/data_llm/FoodHealthMMLLM/scripts/zero2_offload.json",
                "--model_name_or_path=/mnt/data_llm/model/checkpoints/checkpoints-phi-2.7b-v1",
                "--version=phi",
                "--data_path=/mnt/data_llm/json_file/101_train_prompt1.json",
                "--image_folder=/media/LLM_data/food_recognition_dataset",
                "--image_tower=/media/LLM_data/model/openai/clip-vit-large-patch14-336",
                "--image_projector_type=mlp2x_gelu",
                "--mm_vision_select_layer=-2",
                "--mm_use_im_start_end=False",
                "--mm_use_im_patch_token=False",
                "--image_aspect_ratio=pad",
                "--group_by_modality_length=True",
                "--bf16=True",
                "--check_point_file_name=/mnt/data_llm/model/checkpoints/checkpoints-phi-2.7b-v1-moe-v1.json",
                "--output_dir=/mnt/data_llm/model/checkpoints/checkpoints-phi-2.7b-v1-moe-v1",
                "--num_train_epochs=1",
                "--per_device_train_batch_size=4",
                "--per_device_eval_batch_size=4",
                "--gradient_accumulation_steps=4",
                "--evaluation_strategy=no",
                "--save_strategy=steps",
                "--save_steps=3000",
                "--save_total_limit=30",
                "--learning_rate=2e-5",
                "--weight_decay=0.",
                "--warmup_ratio=0.03",
                "--lr_scheduler_type=cosine",
                "--logging_steps=10",
                "--tf32=False",
                "--model_max_length=512",
                "--gradient_checkpointing=True",
                "--dataloader_num_workers=4",
                "--lazy_preprocess=True",
                "--report_to=tensorboard",
                "--cache_dir=/media/fast_data/huggingface/hub/"
            ]
        }
    ]
}
