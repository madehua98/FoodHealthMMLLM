nohup: 忽略输入
0,1,2,3,4
[2024-05-17 00:09:42,222] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-17 00:09:45,296] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-05-17 00:09:45,297] [INFO] [runner.py:555:main] cmd = /home/data_llm/anaconda3/envs/moellava/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNF19 --master_addr=127.0.0.1 --master_port=2227 --enable_each_rank_log=None /home/data_llm/madehua/FoodHealthMMLLM/moellava/train/train_xformers.py --do_train --moe_enable True --num_experts 4 --top_k_experts 2 --capacity_factor 1.5 --moe_mode sparse --use_residual False --router_aux_loss_coef 0.01 --train_modules fc1 fc2 wg --deepspeed ../../zero2_offload.json --model_name_or_path /mnt/data_llm/model/checkpoints/checkpoints-phi-2.7b-v0426 --version phi --data_path /mnt/data_llm/json_file/101_train_prompt10.json --image_folder /media/LLM_data/food_recognition_dataset --image_tower /mnt/data_llm/model/clip-vit-large-patch14-336 --image_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True --check_point_file_name /mnt/data_llm/model/checkpoints/checkpoints-phi-2.7b-moe-v101_0426.json --output_dir /mnt/data_llm/model/checkpoints/checkpoints-phi-2.7b-moe-v101_0426 --num_train_epochs 4 --per_device_train_batch_size 4 --per_device_eval_batch_size 4 --gradient_accumulation_steps 8 --evaluation_strategy no --save_strategy epoch --save_total_limit 5 --learning_rate 2e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 False --model_max_length 512 --gradient_checkpointing True --dataloader_num_workers 64 --lazy_preprocess True --report_to tensorboard --cache_dir /media/fast_data/huggingface/hub/
[2024-05-17 00:09:46,683] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-17 00:09:49,398] [INFO] [launch.py:138:main] 0 NCCL_P2P_DISABLE=1
[2024-05-17 00:09:49,398] [INFO] [launch.py:138:main] 0 NCCL_IB_TIMEOUT=22
[2024-05-17 00:09:49,398] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4]}
[2024-05-17 00:09:49,398] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=5, node_rank=0
[2024-05-17 00:09:49,398] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4]})
[2024-05-17 00:09:49,398] [INFO] [launch.py:163:main] dist_world_size=5
[2024-05-17 00:09:49,398] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4
[2024-05-17 00:09:53,185] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-17 00:09:53,208] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-17 00:09:53,270] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-17 00:09:53,273] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-17 00:09:53,395] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-17 00:09:54,869] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-05-17 00:09:54,869] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-05-17 00:09:54,879] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-05-17 00:09:54,879] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-05-17 00:09:54,900] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-05-17 00:09:54,900] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-05-17 00:09:54,901] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-05-17 00:09:54,947] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-05-17 00:09:54,947] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-05-17 00:09:55,008] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-05-17 00:09:55,009] [INFO] [comm.py:594:init_distributed] cdb=None
You are using a model of type llava_phi to instantiate a model of type moe_llava_phi. This is not supported for all configurations of models and can yield errors.
You are using a model of type llava_phi to instantiate a model of type moe_llava_phi. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]You are using a model of type llava_phi to instantiate a model of type moe_llava_phi. This is not supported for all configurations of models and can yield errors.
You are using a model of type llava_phi to instantiate a model of type moe_llava_phi. This is not supported for all configurations of models and can yield errors.
You are using a model of type llava_phi to instantiate a model of type moe_llava_phi. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.45s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.07s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.70s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.07s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.85s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.86s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.08s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.11s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.70s/it]
LLM init. firstly
 MoELLaVAPhiForCausalLM(
  (model): MoELLaVAPhiModel(
    (embed_tokens): Embedding(51200, 2560, padding_idx=50295)
    (embed_dropout): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0-31): 32 x PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
    (image_tower): CLIPVisionTower()
    (mm_projector): build_projector(
      (image_spatial_proj): Sequential(
        (0): Linear(in_features=1024, out_features=2560, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=2560, out_features=2560, bias=True)
      )
      (video_patch_proj): Identity()
      (video_spatial_proj): Identity()
      (video_temproal_proj): Identity()
      (video_global_proj): Identity()
    )
  )
  (lm_head): Linear(in_features=2560, out_features=51200, bias=False)
)
[2024-05-17 00:10:03,569] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[2024-05-17 00:10:11,514] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[2024-05-17 00:10:19,713] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[2024-05-17 00:10:28,245] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[2024-05-17 00:10:36,780] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[2024-05-17 00:10:45,293] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[2024-05-17 00:10:54,125] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[2024-05-17 00:11:02,891] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[2024-05-17 00:11:11,737] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[2024-05-17 00:11:20,525] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[2024-05-17 00:11:29,198] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[2024-05-17 00:11:37,897] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
****************************************************************************************************
[2024-05-17 00:11:46,121] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /home/data_llm/.cache/torch_extensions/py312_cu121 as PyTorch extensions root...
Emitting ninja build file /home/data_llm/.cache/torch_extensions/py312_cu121/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.57318377494812 seconds
[2024-05-17 00:11:53,858] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[2024-05-17 00:12:01,411] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
No existing process group found, creating a new group named: ep_size_1
[2024-05-17 00:12:08,403] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
****************************************************************************************************
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
****************************************************************************************************
Vision encoder and proj init.
 MoELLaVAPhiForCausalLM(
  (model): MoELLaVAPhiModel(
    (embed_tokens): Embedding(51200, 2560, padding_idx=50295)
    (embed_dropout): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (1): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (2): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (3): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (4): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (5): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (6): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (7): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (8): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (9): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (10): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (11): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (12): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (13): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (14): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (15): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (16): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (17): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (18): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (19): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (20): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (21): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (22): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (23): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (24): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (25): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (26): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (27): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (28): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (29): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (30): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (31): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
    (image_tower): CLIPVisionTower(
      (image_tower): CLIPVisionModel(
        (vision_model): CLIPVisionTransformer(
          (embeddings): CLIPVisionEmbeddings(
            (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)
            (position_embedding): Embedding(577, 1024)
          )
          (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (encoder): CLIPEncoder(
            (layers): ModuleList(
              (0-23): 24 x CLIPEncoderLayer(
                (self_attn): CLIPAttention(
                  (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
                )
                (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (mlp): CLIPMLP(
                  (activation_fn): QuickGELUActivation()
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                )
                (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (mm_projector): build_projector(
      (image_spatial_proj): Sequential(
        (0): Linear(in_features=1024, out_features=2560, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=2560, out_features=2560, bias=True)
      )
      (video_patch_proj): Identity()
      (video_spatial_proj): Identity()
      (video_temproal_proj): Identity()
      (video_global_proj): Identity()
    )
  )
  (lm_head): Linear(in_features=2560, out_features=51200, bias=False)
)
model.layers.0.mlp.deepspeed_moe.gate.wg.weight
model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight
model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias
model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight
model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias
model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight
model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias
model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight
model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias
model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight
model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias
model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight
model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias
model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight
model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias
model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight
model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias
model.layers.1.mlp.fc1.weight
model.layers.1.mlp.fc1.bias
model.layers.1.mlp.fc2.weight
model.layers.1.mlp.fc2.bias
model.layers.2.mlp.deepspeed_moe.gate.wg.weight
model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight
model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias
model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight
model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias
model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight
model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias
model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight
model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias
model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight
model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias
model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight
model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias
model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight
model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias
model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight
model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias
model.layers.3.mlp.fc1.weight
model.layers.3.mlp.fc1.bias
model.layers.3.mlp.fc2.weight
model.layers.3.mlp.fc2.bias
model.layers.4.mlp.deepspeed_moe.gate.wg.weight
model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight
model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias
model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight
model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias
model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight
model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias
model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight
model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias
model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight
model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias
model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight
model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias
model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight
model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias
model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight
model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias
model.layers.5.mlp.fc1.weight
model.layers.5.mlp.fc1.bias
model.layers.5.mlp.fc2.weight
model.layers.5.mlp.fc2.bias
model.layers.6.mlp.deepspeed_moe.gate.wg.weight
model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight
model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias
model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight
model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias
model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight
model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias
model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight
model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias
model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight
model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias
model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight
model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias
model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight
model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias
model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight
model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias
model.layers.7.mlp.fc1.weight
model.layers.7.mlp.fc1.bias
model.layers.7.mlp.fc2.weight
model.layers.7.mlp.fc2.bias
model.layers.8.mlp.deepspeed_moe.gate.wg.weight
model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight
model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias
model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight
model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias
model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight
model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias
model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight
model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias
model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight
model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias
model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight
model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias
model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight
model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias
model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight
model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias
model.layers.9.mlp.fc1.weight
model.layers.9.mlp.fc1.bias
model.layers.9.mlp.fc2.weight
model.layers.9.mlp.fc2.bias
model.layers.10.mlp.deepspeed_moe.gate.wg.weight
model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight
model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias
model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight
model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias
model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight
model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias
model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight
model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias
model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight
model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias
model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight
model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias
model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight
model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias
model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight
model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias
model.layers.11.mlp.fc1.weight
model.layers.11.mlp.fc1.bias
model.layers.11.mlp.fc2.weight
model.layers.11.mlp.fc2.bias
model.layers.12.mlp.deepspeed_moe.gate.wg.weight
model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight
model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias
model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight
model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias
model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight
model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias
model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight
model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias
model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight
model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias
model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight
model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias
model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight
model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias
model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight
model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias
model.layers.13.mlp.fc1.weight
model.layers.13.mlp.fc1.bias
model.layers.13.mlp.fc2.weight
model.layers.13.mlp.fc2.bias
model.layers.14.mlp.deepspeed_moe.gate.wg.weight
model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight
model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias
model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight
model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias
model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight
model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias
model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight
model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias
model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight
model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias
model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight
model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias
model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight
model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias
model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight
model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias
model.layers.15.mlp.fc1.weight
model.layers.15.mlp.fc1.bias
model.layers.15.mlp.fc2.weight
model.layers.15.mlp.fc2.bias
model.layers.16.mlp.deepspeed_moe.gate.wg.weight
model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight
model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias
model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight
model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias
model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight
model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias
model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight
model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias
model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight
model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias
model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight
model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias
model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight
model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias
model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight
model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias
model.layers.17.mlp.fc1.weight
model.layers.17.mlp.fc1.bias
model.layers.17.mlp.fc2.weight
model.layers.17.mlp.fc2.bias
model.layers.18.mlp.deepspeed_moe.gate.wg.weight
model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight
model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias
model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight
model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias
model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight
model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias
model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight
model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias
model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight
model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias
model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight
model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias
model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight
model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias
model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight
model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias
model.layers.19.mlp.fc1.weight
model.layers.19.mlp.fc1.bias
model.layers.19.mlp.fc2.weight
model.layers.19.mlp.fc2.bias
model.layers.20.mlp.deepspeed_moe.gate.wg.weight
model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight
model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias
model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight
model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias
model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight
model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias
model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight
model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias
model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight
model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias
model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight
model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias
model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight
model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias
model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight
model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias
model.layers.21.mlp.fc1.weight
model.layers.21.mlp.fc1.bias
model.layers.21.mlp.fc2.weight
model.layers.21.mlp.fc2.bias
model.layers.22.mlp.deepspeed_moe.gate.wg.weight
model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight
model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias
model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight
model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias
model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight
model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias
model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight
model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias
model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight
model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias
model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight
model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias
model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight
model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias
model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight
model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias
model.layers.23.mlp.fc1.weight
model.layers.23.mlp.fc1.bias
model.layers.23.mlp.fc2.weight
model.layers.23.mlp.fc2.bias
model.layers.24.mlp.deepspeed_moe.gate.wg.weight
model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight
model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias
model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight
model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias
model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight
model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias
model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight
model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias
model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight
model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias
model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight
model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias
model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight
model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias
model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight
model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias
model.layers.25.mlp.fc1.weight
model.layers.25.mlp.fc1.bias
model.layers.25.mlp.fc2.weight
model.layers.25.mlp.fc2.bias
model.layers.26.mlp.deepspeed_moe.gate.wg.weight
model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight
model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias
model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight
model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias
model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight
model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias
model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight
model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias
model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight
model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias
model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight
model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias
model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight
model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias
model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight
model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias
model.layers.27.mlp.fc1.weight
model.layers.27.mlp.fc1.bias
model.layers.27.mlp.fc2.weight
model.layers.27.mlp.fc2.bias
model.layers.28.mlp.deepspeed_moe.gate.wg.weight
model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight
model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias
model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight
model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias
model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight
model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias
model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight
model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias
model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight
model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias
model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight
model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias
model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight
model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias
model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight
model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias
model.layers.29.mlp.fc1.weight
model.layers.29.mlp.fc1.bias
model.layers.29.mlp.fc2.weight
model.layers.29.mlp.fc2.bias
model.layers.30.mlp.deepspeed_moe.gate.wg.weight
model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight
model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias
model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight
model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias
model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight
model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias
model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight
model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias
model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight
model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias
model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight
model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias
model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight
model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias
model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight
model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias
model.layers.31.mlp.fc1.weight
model.layers.31.mlp.fc1.bias
model.layers.31.mlp.fc2.weight
model.layers.31.mlp.fc2.bias
model.mm_projector.image_spatial_proj.0.weight
model.mm_projector.image_spatial_proj.0.bias
model.mm_projector.image_spatial_proj.2.weight
model.mm_projector.image_spatial_proj.2.bias
MoELLaVAPhiForCausalLM(
  (model): MoELLaVAPhiModel(
    (embed_tokens): Embedding(51200, 2560, padding_idx=50295)
    (embed_dropout): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (1): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (2): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (3): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (4): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (5): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (6): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (7): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (8): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (9): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (10): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (11): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (12): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (13): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (14): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (15): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (16): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (17): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (18): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (19): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (20): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (21): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (22): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (23): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (24): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (25): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (26): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (27): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (28): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (29): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (30): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): MoE(
          (deepspeed_moe): MOELayer(
            (gate): TopKGate(
              (wg): Linear(in_features=2560, out_features=4, bias=False)
            )
            (experts): Experts(
              (deepspeed_experts): ModuleList(
                (0-3): 4 x PhiMLP(
                  (activation_fn): NewGELUActivation()
                  (fc1): Linear(in_features=2560, out_features=10240, bias=True)
                  (fc2): Linear(in_features=10240, out_features=2560, bias=True)
                )
              )
            )
          )
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (31): PhiDecoderLayer(
        (self_attn): PhiAttention(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
    (image_tower): CLIPVisionTower(
      (image_tower): CLIPVisionModel(
        (vision_model): CLIPVisionTransformer(
          (embeddings): CLIPVisionEmbeddings(
            (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)
            (position_embedding): Embedding(577, 1024)
          )
          (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (encoder): CLIPEncoder(
            (layers): ModuleList(
              (0-23): 24 x CLIPEncoderLayer(
                (self_attn): CLIPAttention(
                  (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
                )
                (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (mlp): CLIPMLP(
                  (activation_fn): QuickGELUActivation()
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                )
                (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (mm_projector): build_projector(
      (image_spatial_proj): Sequential(
        (0): Linear(in_features=1024, out_features=2560, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=2560, out_features=2560, bias=True)
      )
      (video_patch_proj): Identity()
      (video_spatial_proj): Identity()
      (video_temproal_proj): Identity()
      (video_global_proj): Identity()
    )
  )
  (lm_head): Linear(in_features=2560, out_features=51200, bias=False)
)
****************************************************************************************************
Formatting inputs...Skip in lazy mode
****************************************************************************************************
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /home/data_llm/.cache/torch_extensions/py312_cu121 as PyTorch extensions root...
Emitting ninja build file /home/data_llm/.cache/torch_extensions/py312_cu121/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.4708335399627686 seconds
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /home/data_llm/.cache/torch_extensions/py312_cu121 as PyTorch extensions root...
Emitting ninja build file /home/data_llm/.cache/torch_extensions/py312_cu121/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.4826133251190186 seconds
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /home/data_llm/.cache/torch_extensions/py312_cu121 as PyTorch extensions root...
Emitting ninja build file /home/data_llm/.cache/torch_extensions/py312_cu121/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.5297775268554688 seconds
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /home/data_llm/.cache/torch_extensions/py312_cu121 as PyTorch extensions root...
Emitting ninja build file /home/data_llm/.cache/torch_extensions/py312_cu121/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.479623317718506 seconds
No existing process group found, creating a new group named: ep_size_1
No existing process group found, creating a new group named: ep_size_1
No existing process group found, creating a new group named: ep_size_1
No existing process group found, creating a new group named: ep_size_1
Rank: 1 partition count [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5] and sizes[(169639936, False), (41984, False), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (10485760, True), (163840, True)] 
Rank: 3 partition count [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5] and sizes[(169639936, False), (41984, False), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (10485760, True), (163840, True)] 
Rank: 2 partition count [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5] and sizes[(169639936, False), (41984, False), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (10485760, True), (163840, True)] 
Rank: 4 partition count [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5] and sizes[(169639936, False), (41984, False), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (10485760, True), (163840, True)] 
Rank: 0 partition count [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5] and sizes[(169639936, False), (41984, False), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (31457280, True), (10485760, True), (163840, True)] 
  0%|          | 0/1892 [00:00<?, ?it/s]/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
 75%|███████▌  | 1420/1892 [02:34<00:51,  9.19it/s]                                                   {'loss': 0.2636, 'learning_rate': 3.0911415074101446e-06, 'epoch': 3.0}
 75%|███████▌  | 1420/1892 [02:34<00:51,  9.19it/s] 75%|███████▌  | 1421/1892 [03:30<01:17,  6.07it/s]                                                   {'loss': 0.2181, 'learning_rate': 3.078774211128136e-06, 'epoch': 3.0}
 75%|███████▌  | 1421/1892 [03:30<01:17,  6.07it/s] 75%|███████▌  | 1422/1892 [04:25<01:54,  4.10it/s]                                                   {'loss': 0.2307, 'learning_rate': 3.0664272015046735e-06, 'epoch': 3.01}
 75%|███████▌  | 1422/1892 [04:25<01:54,  4.10it/s] 75%|███████▌  | 1423/1892 [05:21<02:47,  2.80it/s]                                                   {'loss': 0.2066, 'learning_rate': 3.054100514729815e-06, 'epoch': 3.01}
 75%|███████▌  | 1423/1892 [05:21<02:47,  2.80it/s] 75%|███████▌  | 1424/1892 [06:16<04:01,  1.93it/s]                                                   {'loss': 0.2321, 'learning_rate': 3.041794186934055e-06, 'epoch': 3.01}
 75%|███████▌  | 1424/1892 [06:16<04:01,  1.93it/s] 75%|███████▌  | 1425/1892 [07:11<05:47,  1.34it/s]                                                   {'loss': 0.2068, 'learning_rate': 3.029508254188205e-06, 'epoch': 3.01}
 75%|███████▌  | 1425/1892 [07:11<05:47,  1.34it/s] 75%|███████▌  | 1426/1892 [08:07<08:17,  1.07s/it]                                                   {'loss': 0.1978, 'learning_rate': 3.017242752503304e-06, 'epoch': 3.01}
 75%|███████▌  | 1426/1892 [08:07<08:17,  1.07s/it] 75%|███████▌  | 1427/1892 [09:02<11:46,  1.52s/it]                                                   {'loss': 0.2043, 'learning_rate': 3.004997717830508e-06, 'epoch': 3.02}
 75%|███████▌  | 1427/1892 [09:02<11:46,  1.52s/it] 75%|███████▌  | 1428/1892 [09:58<16:39,  2.15s/it]                                                   {'loss': 0.1964, 'learning_rate': 2.9927731860609752e-06, 'epoch': 3.02}
 75%|███████▌  | 1428/1892 [09:58<16:39,  2.15s/it] 76%|███████▌  | 1429/1892 [10:53<23:24,  3.03s/it]                                                   {'loss': 0.1881, 'learning_rate': 2.9805691930257784e-06, 'epoch': 3.02}
 76%|███████▌  | 1429/1892 [10:53<23:24,  3.03s/it] 76%|███████▌  | 1430/1892 [11:49<32:38,  4.24s/it]                                                   {'loss': 0.1955, 'learning_rate': 2.968385774495779e-06, 'epoch': 3.02}
 76%|███████▌  | 1430/1892 [11:49<32:38,  4.24s/it] 76%|███████▌  | 1431/1892 [12:44<45:07,  5.87s/it]                                                   {'loss': 0.206, 'learning_rate': 2.9562229661815334e-06, 'epoch': 3.03}
 76%|███████▌  | 1431/1892 [12:44<45:07,  5.87s/it] 76%|███████▌  | 1432/1892 [13:39<1:01:30,  8.02s/it]                                                     {'loss': 0.2192, 'learning_rate': 2.944080803733197e-06, 'epoch': 3.03}
 76%|███████▌  | 1432/1892 [13:39<1:01:30,  8.02s/it] 76%|███████▌  | 1433/1892 [14:34<1:22:34, 10.79s/it]                                                     {'loss': 0.2199, 'learning_rate': 2.9319593227404043e-06, 'epoch': 3.03}
 76%|███████▌  | 1433/1892 [14:34<1:22:34, 10.79s/it] 76%|███████▌  | 1434/1892 [15:30<1:48:33, 14.22s/it]                                                     {'loss': 0.2325, 'learning_rate': 2.919858558732175e-06, 'epoch': 3.03}
 76%|███████▌  | 1434/1892 [15:30<1:48:33, 14.22s/it] 76%|███████▌  | 1435/1892 [16:25<2:19:21, 18.30s/it]                                                     {'loss': 0.2314, 'learning_rate': 2.9077785471767962e-06, 'epoch': 3.03}
 76%|███████▌  | 1435/1892 [16:25<2:19:21, 18.30s/it] 76%|███████▌  | 1436/1892 [17:20<2:53:44, 22.86s/it]                                                     {'loss': 0.2258, 'learning_rate': 2.895719323481738e-06, 'epoch': 3.04}
 76%|███████▌  | 1436/1892 [17:20<2:53:44, 22.86s/it] 76%|███████▌  | 1437/1892 [18:15<3:30:12, 27.72s/it]                                                     {'loss': 0.2066, 'learning_rate': 2.883680922993536e-06, 'epoch': 3.04}
 76%|███████▌  | 1437/1892 [18:15<3:30:12, 27.72s/it] 76%|███████▌  | 1438/1892 [19:10<4:06:26, 32.57s/it]                                                     {'loss': 0.1944, 'learning_rate': 2.8716633809976923e-06, 'epoch': 3.04}
 76%|███████▌  | 1438/1892 [19:10<4:06:26, 32.57s/it] 76%|███████▌  | 1439/1892 [20:05<4:40:21, 37.13s/it]                                                     {'loss': 0.2033, 'learning_rate': 2.859666732718568e-06, 'epoch': 3.04}
 76%|███████▌  | 1439/1892 [20:05<4:40:21, 37.13s/it] 76%|███████▌  | 1440/1892 [21:00<5:10:16, 41.19s/it]                                                     {'loss': 0.2023, 'learning_rate': 2.8476910133192837e-06, 'epoch': 3.04}
 76%|███████▌  | 1440/1892 [21:00<5:10:16, 41.19s/it] 76%|███████▌  | 1441/1892 [21:56<5:35:11, 44.59s/it]                                                     {'loss': 0.2042, 'learning_rate': 2.835736257901621e-06, 'epoch': 3.05}
 76%|███████▌  | 1441/1892 [21:56<5:35:11, 44.59s/it] 76%|███████▌  | 1442/1892 [22:51<5:54:47, 47.31s/it]                                                     {'loss': 0.1906, 'learning_rate': 2.823802501505909e-06, 'epoch': 3.05}
 76%|███████▌  | 1442/1892 [22:51<5:54:47, 47.31s/it] 76%|███████▋  | 1443/1892 [23:46<6:09:37, 49.39s/it]                                                     {'loss': 0.1937, 'learning_rate': 2.8118897791109313e-06, 'epoch': 3.05}
 76%|███████▋  | 1443/1892 [23:46<6:09:37, 49.39s/it] 76%|███████▋  | 1444/1892 [24:41<6:20:47, 51.00s/it]                                                     {'loss': 0.1912, 'learning_rate': 2.799998125633815e-06, 'epoch': 3.05}
 76%|███████▋  | 1444/1892 [24:41<6:20:47, 51.00s/it] 76%|███████▋  | 1445/1892 [25:36<6:28:37, 52.16s/it]                                                     {'loss': 0.1965, 'learning_rate': 2.7881275759299297e-06, 'epoch': 3.05}
 76%|███████▋  | 1445/1892 [25:36<6:28:37, 52.16s/it] 76%|███████▋  | 1446/1892 [26:31<6:34:12, 53.03s/it]                                                     {'loss': 0.2106, 'learning_rate': 2.776278164792796e-06, 'epoch': 3.06}
 76%|███████▋  | 1446/1892 [26:31<6:34:12, 53.03s/it] 76%|███████▋  | 1447/1892 [27:26<6:37:54, 53.65s/it]                                                     {'loss': 0.2136, 'learning_rate': 2.7644499269539728e-06, 'epoch': 3.06}
 76%|███████▋  | 1447/1892 [27:26<6:37:54, 53.65s/it] 77%|███████▋  | 1448/1892 [28:22<6:40:23, 54.11s/it]                                                     {'loss': 0.2173, 'learning_rate': 2.752642897082961e-06, 'epoch': 3.06}
 77%|███████▋  | 1448/1892 [28:22<6:40:23, 54.11s/it] 77%|███████▋  | 1449/1892 [29:17<6:41:43, 54.41s/it]                                                     {'loss': 0.2249, 'learning_rate': 2.7408571097870893e-06, 'epoch': 3.06}
 77%|███████▋  | 1449/1892 [29:17<6:41:43, 54.41s/it] 77%|███████▋  | 1450/1892 [30:12<6:42:15, 54.60s/it]                                                     {'loss': 0.2301, 'learning_rate': 2.729092599611434e-06, 'epoch': 3.07}
 77%|███████▋  | 1450/1892 [30:12<6:42:15, 54.60s/it] 77%|███████▋  | 1451/1892 [31:07<6:42:04, 54.70s/it]                                                     {'loss': 0.2162, 'learning_rate': 2.7173494010387003e-06, 'epoch': 3.07}
 77%|███████▋  | 1451/1892 [31:07<6:42:04, 54.70s/it] 77%|███████▋  | 1452/1892 [32:02<6:41:57, 54.81s/it]                                                     {'loss': 0.2012, 'learning_rate': 2.70562754848913e-06, 'epoch': 3.07}
 77%|███████▋  | 1452/1892 [32:02<6:41:57, 54.81s/it] 77%|███████▋  | 1453/1892 [32:57<6:41:33, 54.88s/it]                                                     {'loss': 0.2115, 'learning_rate': 2.6939270763204005e-06, 'epoch': 3.07}
 77%|███████▋  | 1453/1892 [32:57<6:41:33, 54.88s/it] 77%|███████▋  | 1454/1892 [33:52<6:41:16, 54.97s/it]                                                     {'loss': 0.2317, 'learning_rate': 2.6822480188275125e-06, 'epoch': 3.07}
 77%|███████▋  | 1454/1892 [33:52<6:41:16, 54.97s/it] 77%|███████▋  | 1455/1892 [34:47<6:40:11, 54.95s/it]                                                     {'loss': 0.2203, 'learning_rate': 2.670590410242707e-06, 'epoch': 3.08}
 77%|███████▋  | 1455/1892 [34:47<6:40:11, 54.95s/it] 77%|███████▋  | 1456/1892 [35:42<6:39:31, 54.98s/it]                                                     {'loss': 0.2115, 'learning_rate': 2.6589542847353534e-06, 'epoch': 3.08}
 77%|███████▋  | 1456/1892 [35:42<6:39:31, 54.98s/it] 77%|███████▋  | 1457/1892 [36:37<6:38:40, 54.99s/it]                                                     {'loss': 0.196, 'learning_rate': 2.6473396764118575e-06, 'epoch': 3.08}
 77%|███████▋  | 1457/1892 [36:37<6:38:40, 54.99s/it] 77%|███████▋  | 1458/1892 [37:32<6:38:01, 55.03s/it]                                                     {'loss': 0.2175, 'learning_rate': 2.635746619315549e-06, 'epoch': 3.08}
 77%|███████▋  | 1458/1892 [37:32<6:38:01, 55.03s/it] 77%|███████▋  | 1459/1892 [38:27<6:37:16, 55.05s/it]                                                     {'loss': 0.22, 'learning_rate': 2.6241751474265873e-06, 'epoch': 3.08}
 77%|███████▋  | 1459/1892 [38:27<6:37:16, 55.05s/it] 77%|███████▋  | 1460/1892 [39:22<6:36:17, 55.04s/it]                                                     {'loss': 0.2113, 'learning_rate': 2.6126252946618748e-06, 'epoch': 3.09}
 77%|███████▋  | 1460/1892 [39:22<6:36:17, 55.04s/it] 77%|███████▋  | 1461/1892 [40:17<6:35:24, 55.04s/it]                                                     {'loss': 0.1937, 'learning_rate': 2.601097094874939e-06, 'epoch': 3.09}
 77%|███████▋  | 1461/1892 [40:17<6:35:24, 55.04s/it] 77%|███████▋  | 1462/1892 [41:12<6:34:35, 55.06s/it]                                                     {'loss': 0.1998, 'learning_rate': 2.589590581855843e-06, 'epoch': 3.09}
 77%|███████▋  | 1462/1892 [41:12<6:34:35, 55.06s/it] 77%|███████▋  | 1463/1892 [42:07<6:33:38, 55.06s/it]                                                     {'loss': 0.2157, 'learning_rate': 2.5781057893310866e-06, 'epoch': 3.09}
 77%|███████▋  | 1463/1892 [42:07<6:33:38, 55.06s/it] 77%|███████▋  | 1464/1892 [43:02<6:32:40, 55.05s/it]                                                     {'loss': 0.2147, 'learning_rate': 2.566642750963496e-06, 'epoch': 3.1}
 77%|███████▋  | 1464/1892 [43:02<6:32:40, 55.05s/it] 77%|███████▋  | 1465/1892 [43:57<6:31:37, 55.03s/it]                                                     {'loss': 0.1959, 'learning_rate': 2.5552015003521447e-06, 'epoch': 3.1}
 77%|███████▋  | 1465/1892 [43:57<6:31:37, 55.03s/it] 77%|███████▋  | 1466/1892 [44:52<6:30:33, 55.01s/it]                                                     {'loss': 0.2141, 'learning_rate': 2.543782071032238e-06, 'epoch': 3.1}
 77%|███████▋  | 1466/1892 [44:52<6:30:33, 55.01s/it] 78%|███████▊  | 1467/1892 [45:47<6:29:48, 55.03s/it]                                                     {'loss': 0.2308, 'learning_rate': 2.53238449647503e-06, 'epoch': 3.1}
 78%|███████▊  | 1467/1892 [45:47<6:29:48, 55.03s/it] 78%|███████▊  | 1468/1892 [46:43<6:28:57, 55.04s/it]                                                     {'loss': 0.2264, 'learning_rate': 2.5210088100877027e-06, 'epoch': 3.1}
 78%|███████▊  | 1468/1892 [46:43<6:28:57, 55.04s/it] 78%|███████▊  | 1469/1892 [47:38<6:27:56, 55.03s/it]                                                     {'loss': 0.1911, 'learning_rate': 2.5096550452132915e-06, 'epoch': 3.11}
 78%|███████▊  | 1469/1892 [47:38<6:27:56, 55.03s/it] 78%|███████▊  | 1470/1892 [48:33<6:26:58, 55.02s/it]                                                     {'loss': 0.2197, 'learning_rate': 2.49832323513058e-06, 'epoch': 3.11}
 78%|███████▊  | 1470/1892 [48:33<6:26:58, 55.02s/it] 78%|███████▊  | 1471/1892 [49:28<6:26:12, 55.04s/it]                                                     {'loss': 0.2232, 'learning_rate': 2.4870134130539936e-06, 'epoch': 3.11}
 78%|███████▊  | 1471/1892 [49:28<6:26:12, 55.04s/it] 78%|███████▊  | 1472/1892 [50:23<6:25:09, 55.02s/it]                                                     {'loss': 0.2103, 'learning_rate': 2.4757256121335182e-06, 'epoch': 3.11}
 78%|███████▊  | 1472/1892 [50:23<6:25:09, 55.02s/it] 78%|███████▊  | 1473/1892 [51:18<6:24:01, 54.99s/it]                                                     {'loss': 0.2243, 'learning_rate': 2.464459865454584e-06, 'epoch': 3.11}
 78%|███████▊  | 1473/1892 [51:18<6:24:01, 54.99s/it] 78%|███████▊  | 1474/1892 [52:13<6:23:11, 55.00s/it]                                                     {'loss': 0.2144, 'learning_rate': 2.4532162060379795e-06, 'epoch': 3.12}
 78%|███████▊  | 1474/1892 [52:13<6:23:11, 55.00s/it] 78%|███████▊  | 1475/1892 [53:08<6:22:15, 55.00s/it]                                                     {'loss': 0.2143, 'learning_rate': 2.4419946668397607e-06, 'epoch': 3.12}
 78%|███████▊  | 1475/1892 [53:08<6:22:15, 55.00s/it] 78%|███████▊  | 1476/1892 [54:03<6:21:28, 55.02s/it]                                                     {'loss': 0.222, 'learning_rate': 2.430795280751145e-06, 'epoch': 3.12}
 78%|███████▊  | 1476/1892 [54:03<6:21:28, 55.02s/it] 78%|███████▊  | 1477/1892 [54:58<6:20:20, 54.99s/it]                                                     {'loss': 0.2159, 'learning_rate': 2.419618080598417e-06, 'epoch': 3.12}
 78%|███████▊  | 1477/1892 [54:58<6:20:20, 54.99s/it] 78%|███████▊  | 1478/1892 [55:53<6:19:24, 54.99s/it]                                                     {'loss': 0.224, 'learning_rate': 2.408463099142827e-06, 'epoch': 3.12}
 78%|███████▊  | 1478/1892 [55:53<6:19:24, 54.99s/it] 78%|███████▊  | 1479/1892 [56:48<6:19:10, 55.09s/it]                                                     {'loss': 0.2079, 'learning_rate': 2.397330369080508e-06, 'epoch': 3.13}
 78%|███████▊  | 1479/1892 [56:48<6:19:10, 55.09s/it] 78%|███████▊  | 1480/1892 [57:43<6:18:14, 55.08s/it]                                                     {'loss': 0.213, 'learning_rate': 2.38621992304237e-06, 'epoch': 3.13}
 78%|███████▊  | 1480/1892 [57:43<6:18:14, 55.08s/it] 78%|███████▊  | 1481/1892 [58:38<6:17:30, 55.11s/it]                                                     {'loss': 0.2112, 'learning_rate': 2.3751317935940055e-06, 'epoch': 3.13}
 78%|███████▊  | 1481/1892 [58:38<6:17:30, 55.11s/it] 78%|███████▊  | 1482/1892 [59:33<6:16:36, 55.11s/it]                                                     {'loss': 0.1969, 'learning_rate': 2.3640660132356e-06, 'epoch': 3.13}
 78%|███████▊  | 1482/1892 [59:33<6:16:36, 55.11s/it] 78%|███████▊  | 1483/1892 [1:00:28<6:15:29, 55.08s/it]                                                       {'loss': 0.2046, 'learning_rate': 2.353022614401821e-06, 'epoch': 3.14}
 78%|███████▊  | 1483/1892 [1:00:28<6:15:29, 55.08s/it] 78%|███████▊  | 1484/1892 [1:01:23<6:14:15, 55.04s/it]                                                       {'loss': 0.1973, 'learning_rate': 2.3420016294617465e-06, 'epoch': 3.14}
 78%|███████▊  | 1484/1892 [1:01:23<6:14:15, 55.04s/it] 78%|███████▊  | 1485/1892 [1:02:18<6:13:07, 55.01s/it]                                                       {'loss': 0.2041, 'learning_rate': 2.3310030907187542e-06, 'epoch': 3.14}
 78%|███████▊  | 1485/1892 [1:02:18<6:13:07, 55.01s/it] 79%|███████▊  | 1486/1892 [1:03:13<6:12:20, 55.03s/it]                                                       {'loss': 0.214, 'learning_rate': 2.320027030410422e-06, 'epoch': 3.14}
 79%|███████▊  | 1486/1892 [1:03:13<6:12:20, 55.03s/it] 79%|███████▊  | 1487/1892 [1:04:08<6:11:32, 55.04s/it]                                                       {'loss': 0.2286, 'learning_rate': 2.3090734807084545e-06, 'epoch': 3.14}
 79%|███████▊  | 1487/1892 [1:04:08<6:11:32, 55.04s/it] 79%|███████▊  | 1488/1892 [1:05:03<6:10:55, 55.09s/it]                                                       {'loss': 0.2223, 'learning_rate': 2.298142473718564e-06, 'epoch': 3.15}
 79%|███████▊  | 1488/1892 [1:05:03<6:10:55, 55.09s/it] 79%|███████▊  | 1489/1892 [1:05:59<6:09:57, 55.08s/it]                                                       {'loss': 0.2191, 'learning_rate': 2.287234041480396e-06, 'epoch': 3.15}
 79%|███████▊  | 1489/1892 [1:05:59<6:09:57, 55.08s/it] 79%|███████▉  | 1490/1892 [1:06:54<6:09:12, 55.11s/it]                                                       {'loss': 0.2151, 'learning_rate': 2.276348215967428e-06, 'epoch': 3.15}
 79%|███████▉  | 1490/1892 [1:06:54<6:09:12, 55.11s/it] 79%|███████▉  | 1491/1892 [1:07:49<6:08:13, 55.09s/it]                                                       {'loss': 0.2089, 'learning_rate': 2.2654850290868725e-06, 'epoch': 3.15}
 79%|███████▉  | 1491/1892 [1:07:49<6:08:13, 55.09s/it] 79%|███████▉  | 1492/1892 [1:08:44<6:07:30, 55.13s/it]                                                       {'loss': 0.2137, 'learning_rate': 2.2546445126795822e-06, 'epoch': 3.15}
 79%|███████▉  | 1492/1892 [1:08:44<6:07:30, 55.13s/it] 79%|███████▉  | 1493/1892 [1:09:39<6:06:41, 55.14s/it]                                                       {'loss': 0.2292, 'learning_rate': 2.2438266985199707e-06, 'epoch': 3.16}
 79%|███████▉  | 1493/1892 [1:09:39<6:06:41, 55.14s/it] 79%|███████▉  | 1494/1892 [1:10:34<6:05:50, 55.15s/it]                                                       {'loss': 0.2018, 'learning_rate': 2.2330316183159007e-06, 'epoch': 3.16}
 79%|███████▉  | 1494/1892 [1:10:34<6:05:50, 55.15s/it] 79%|███████▉  | 1495/1892 [1:11:29<6:04:49, 55.14s/it]                                                       {'loss': 0.1983, 'learning_rate': 2.222259303708606e-06, 'epoch': 3.16}
 79%|███████▉  | 1495/1892 [1:11:29<6:04:49, 55.14s/it] 79%|███████▉  | 1496/1892 [1:12:25<6:03:59, 55.15s/it]                                                       {'loss': 0.2053, 'learning_rate': 2.211509786272592e-06, 'epoch': 3.16}
 79%|███████▉  | 1496/1892 [1:12:25<6:03:59, 55.15s/it] 79%|███████▉  | 1497/1892 [1:13:20<6:02:57, 55.13s/it]                                                       {'loss': 0.2113, 'learning_rate': 2.2007830975155366e-06, 'epoch': 3.16}
 79%|███████▉  | 1497/1892 [1:13:20<6:02:57, 55.13s/it] 79%|███████▉  | 1498/1892 [1:14:15<6:01:43, 55.08s/it]                                                       {'loss': 0.2215, 'learning_rate': 2.1900792688782124e-06, 'epoch': 3.17}
 79%|███████▉  | 1498/1892 [1:14:15<6:01:43, 55.08s/it] 79%|███████▉  | 1499/1892 [1:15:10<6:01:01, 55.12s/it]                                                       {'loss': 0.2101, 'learning_rate': 2.1793983317343892e-06, 'epoch': 3.17}
 79%|███████▉  | 1499/1892 [1:15:10<6:01:01, 55.12s/it] 79%|███████▉  | 1500/1892 [1:16:05<6:00:07, 55.12s/it]                                                       {'loss': 0.2132, 'learning_rate': 2.1687403173907305e-06, 'epoch': 3.17}
 79%|███████▉  | 1500/1892 [1:16:05<6:00:07, 55.12s/it] 79%|███████▉  | 1501/1892 [1:17:00<5:59:02, 55.10s/it]                                                       {'loss': 0.2133, 'learning_rate': 2.15810525708672e-06, 'epoch': 3.17}
 79%|███████▉  | 1501/1892 [1:17:00<5:59:02, 55.10s/it] 79%|███████▉  | 1502/1892 [1:17:55<5:57:52, 55.06s/it]                                                       {'loss': 0.1976, 'learning_rate': 2.1474931819945555e-06, 'epoch': 3.18}
 79%|███████▉  | 1502/1892 [1:17:55<5:57:52, 55.06s/it] 79%|███████▉  | 1503/1892 [1:18:50<5:56:56, 55.05s/it]                                                       {'loss': 0.2036, 'learning_rate': 2.136904123219067e-06, 'epoch': 3.18}
 79%|███████▉  | 1503/1892 [1:18:50<5:56:56, 55.05s/it] 79%|███████▉  | 1504/1892 [1:19:45<5:56:02, 55.06s/it]                                                       {'loss': 0.2074, 'learning_rate': 2.126338111797621e-06, 'epoch': 3.18}
 79%|███████▉  | 1504/1892 [1:19:45<5:56:02, 55.06s/it] 80%|███████▉  | 1505/1892 [1:20:40<5:55:10, 55.06s/it]                                                       {'loss': 0.2066, 'learning_rate': 2.1157951787000298e-06, 'epoch': 3.18}
 80%|███████▉  | 1505/1892 [1:20:40<5:55:10, 55.06s/it] 80%|███████▉  | 1506/1892 [1:21:35<5:54:05, 55.04s/it]                                                       {'loss': 0.2016, 'learning_rate': 2.1052753548284653e-06, 'epoch': 3.18}
 80%|███████▉  | 1506/1892 [1:21:35<5:54:05, 55.04s/it] 80%|███████▉  | 1507/1892 [1:22:30<5:53:22, 55.07s/it]                                                       {'loss': 0.2136, 'learning_rate': 2.0947786710173545e-06, 'epoch': 3.19}
 80%|███████▉  | 1507/1892 [1:22:30<5:53:22, 55.07s/it] 80%|███████▉  | 1508/1892 [1:23:25<5:52:38, 55.10s/it]                                                       {'loss': 0.2297, 'learning_rate': 2.0843051580333083e-06, 'epoch': 3.19}
 80%|███████▉  | 1508/1892 [1:23:25<5:52:38, 55.10s/it] 80%|███████▉  | 1509/1892 [1:24:21<5:51:48, 55.11s/it]                                                       {'loss': 0.196, 'learning_rate': 2.07385484657502e-06, 'epoch': 3.19}
 80%|███████▉  | 1509/1892 [1:24:21<5:51:48, 55.11s/it] 80%|███████▉  | 1510/1892 [1:25:16<5:50:55, 55.12s/it]                                                       {'loss': 0.2218, 'learning_rate': 2.0634277672731775e-06, 'epoch': 3.19}
 80%|███████▉  | 1510/1892 [1:25:16<5:50:55, 55.12s/it] 80%|███████▉  | 1511/1892 [1:26:11<5:50:04, 55.13s/it]                                                       {'loss': 0.2008, 'learning_rate': 2.053023950690368e-06, 'epoch': 3.19}
 80%|███████▉  | 1511/1892 [1:26:11<5:50:04, 55.13s/it] 80%|███████▉  | 1512/1892 [1:27:06<5:49:09, 55.13s/it]                                                       {'loss': 0.219, 'learning_rate': 2.0426434273210016e-06, 'epoch': 3.2}
 80%|███████▉  | 1512/1892 [1:27:06<5:49:09, 55.13s/it] 80%|███████▉  | 1513/1892 [1:28:01<5:48:06, 55.11s/it]                                                       {'loss': 0.2045, 'learning_rate': 2.0322862275912126e-06, 'epoch': 3.2}
 80%|███████▉  | 1513/1892 [1:28:01<5:48:06, 55.11s/it] 80%|████████  | 1514/1892 [1:28:56<5:47:00, 55.08s/it]                                                       {'loss': 0.2162, 'learning_rate': 2.021952381858765e-06, 'epoch': 3.2}
 80%|████████  | 1514/1892 [1:28:56<5:47:00, 55.08s/it] 80%|████████  | 1515/1892 [1:29:51<5:45:55, 55.05s/it]                                                       {'loss': 0.1973, 'learning_rate': 2.0116419204129776e-06, 'epoch': 3.2}
 80%|████████  | 1515/1892 [1:29:51<5:45:55, 55.05s/it] 80%|████████  | 1516/1892 [1:30:46<5:44:57, 55.05s/it]                                                       {'loss': 0.2157, 'learning_rate': 2.0013548734746304e-06, 'epoch': 3.2}
 80%|████████  | 1516/1892 [1:30:46<5:44:57, 55.05s/it] 80%|████████  | 1517/1892 [1:31:41<5:44:01, 55.04s/it]                                                       {'loss': 0.2212, 'learning_rate': 1.991091271195862e-06, 'epoch': 3.21}
 80%|████████  | 1517/1892 [1:31:41<5:44:01, 55.04s/it] 80%|████████  | 1518/1892 [1:32:36<5:43:02, 55.03s/it]                                                       {'loss': 0.2092, 'learning_rate': 1.980851143660103e-06, 'epoch': 3.21}
 80%|████████  | 1518/1892 [1:32:36<5:43:02, 55.03s/it] 80%|████████  | 1519/1892 [1:33:31<5:41:56, 55.00s/it]                                                       {'loss': 0.1969, 'learning_rate': 1.9706345208819744e-06, 'epoch': 3.21}
 80%|████████  | 1519/1892 [1:33:31<5:41:56, 55.00s/it] 80%|████████  | 1520/1892 [1:34:26<5:41:01, 55.00s/it]                                                       {'loss': 0.2068, 'learning_rate': 1.960441432807206e-06, 'epoch': 3.21}
 80%|████████  | 1520/1892 [1:34:26<5:41:01, 55.00s/it] 80%|████████  | 1521/1892 [1:35:21<5:40:07, 55.01s/it]                                                       {'loss': 0.2262, 'learning_rate': 1.950271909312539e-06, 'epoch': 3.22}
 80%|████████  | 1521/1892 [1:35:21<5:40:07, 55.01s/it] 80%|████████  | 1522/1892 [1:36:16<5:39:09, 55.00s/it]                                                       {'loss': 0.2169, 'learning_rate': 1.9401259802056495e-06, 'epoch': 3.22}
 80%|████████  | 1522/1892 [1:36:16<5:39:09, 55.00s/it] 80%|████████  | 1523/1892 [1:37:11<5:38:09, 54.99s/it]                                                       {'loss': 0.2112, 'learning_rate': 1.9300036752250563e-06, 'epoch': 3.22}
 80%|████████  | 1523/1892 [1:37:11<5:38:09, 54.99s/it] 81%|████████  | 1524/1892 [1:38:06<5:37:36, 55.05s/it]                                                       {'loss': 0.204, 'learning_rate': 1.919905024040034e-06, 'epoch': 3.22}
 81%|████████  | 1524/1892 [1:38:06<5:37:36, 55.05s/it] 81%|████████  | 1525/1892 [1:39:01<5:36:36, 55.03s/it]                                                       {'loss': 0.2143, 'learning_rate': 1.9098300562505266e-06, 'epoch': 3.22}
 81%|████████  | 1525/1892 [1:39:01<5:36:36, 55.03s/it] 81%|████████  | 1526/1892 [1:39:56<5:35:45, 55.04s/it]                                                       {'loss': 0.2132, 'learning_rate': 1.8997788013870556e-06, 'epoch': 3.23}
 81%|████████  | 1526/1892 [1:39:56<5:35:45, 55.04s/it] 81%|████████  | 1527/1892 [1:40:51<5:34:55, 55.06s/it]                                                       {'loss': 0.2008, 'learning_rate': 1.8897512889106451e-06, 'epoch': 3.23}
 81%|████████  | 1527/1892 [1:40:51<5:34:55, 55.06s/it] 81%|████████  | 1528/1892 [1:41:46<5:33:48, 55.02s/it]                                                       {'loss': 0.2094, 'learning_rate': 1.8797475482127214e-06, 'epoch': 3.23}
 81%|████████  | 1528/1892 [1:41:46<5:33:48, 55.02s/it] 81%|████████  | 1529/1892 [1:42:41<5:32:50, 55.02s/it]                                                       {'loss': 0.1892, 'learning_rate': 1.8697676086150386e-06, 'epoch': 3.23}
 81%|████████  | 1529/1892 [1:42:41<5:32:50, 55.02s/it] 81%|████████  | 1530/1892 [1:43:36<5:31:47, 54.99s/it]                                                       {'loss': 0.2018, 'learning_rate': 1.8598114993695904e-06, 'epoch': 3.23}
 81%|████████  | 1530/1892 [1:43:36<5:31:47, 54.99s/it] 81%|████████  | 1531/1892 [1:44:31<5:30:52, 54.99s/it]                                                       {'loss': 0.2014, 'learning_rate': 1.8498792496585117e-06, 'epoch': 3.24}
 81%|████████  | 1531/1892 [1:44:31<5:30:52, 54.99s/it] 81%|████████  | 1532/1892 [1:45:26<5:30:05, 55.01s/it]                                                       {'loss': 0.2113, 'learning_rate': 1.8399708885940136e-06, 'epoch': 3.24}
 81%|████████  | 1532/1892 [1:45:26<5:30:05, 55.01s/it] 81%|████████  | 1533/1892 [1:46:21<5:28:59, 54.99s/it]                                                       {'loss': 0.2003, 'learning_rate': 1.830086445218282e-06, 'epoch': 3.24}
 81%|████████  | 1533/1892 [1:46:21<5:28:59, 54.99s/it] 81%|████████  | 1534/1892 [1:47:16<5:28:02, 54.98s/it]                                                       {'loss': 0.2125, 'learning_rate': 1.8202259485034002e-06, 'epoch': 3.24}
 81%|████████  | 1534/1892 [1:47:16<5:28:02, 54.98s/it] 81%|████████  | 1535/1892 [1:48:11<5:27:32, 55.05s/it]                                                       {'loss': 0.2205, 'learning_rate': 1.8103894273512656e-06, 'epoch': 3.24}
 81%|████████  | 1535/1892 [1:48:11<5:27:32, 55.05s/it] 81%|████████  | 1536/1892 [1:49:07<5:26:48, 55.08s/it]                                                       {'loss': 0.1978, 'learning_rate': 1.800576910593491e-06, 'epoch': 3.25}
 81%|████████  | 1536/1892 [1:49:07<5:26:48, 55.08s/it] 81%|████████  | 1537/1892 [1:50:02<5:26:20, 55.16s/it]                                                       {'loss': 0.2032, 'learning_rate': 1.790788426991339e-06, 'epoch': 3.25}
 81%|████████  | 1537/1892 [1:50:02<5:26:20, 55.16s/it] 81%|████████▏ | 1538/1892 [1:50:57<5:25:26, 55.16s/it]                                                       {'loss': 0.1929, 'learning_rate': 1.7810240052356275e-06, 'epoch': 3.25}
 81%|████████▏ | 1538/1892 [1:50:57<5:25:26, 55.16s/it] 81%|████████▏ | 1539/1892 [1:51:52<5:24:16, 55.12s/it]                                                       {'loss': 0.2216, 'learning_rate': 1.77128367394665e-06, 'epoch': 3.25}
 81%|████████▏ | 1539/1892 [1:51:52<5:24:16, 55.12s/it] 81%|████████▏ | 1540/1892 [1:52:47<5:23:18, 55.11s/it]                                                       {'loss': 0.2097, 'learning_rate': 1.7615674616740786e-06, 'epoch': 3.26}
 81%|████████▏ | 1540/1892 [1:52:47<5:23:18, 55.11s/it] 81%|████████▏ | 1541/1892 [1:53:42<5:22:19, 55.10s/it]                                                       {'loss': 0.1964, 'learning_rate': 1.7518753968969037e-06, 'epoch': 3.26}
 81%|████████▏ | 1541/1892 [1:53:42<5:22:19, 55.10s/it] 82%|████████▏ | 1542/1892 [1:54:37<5:21:17, 55.08s/it]                                                       {'loss': 0.2193, 'learning_rate': 1.742207508023327e-06, 'epoch': 3.26}
 82%|████████▏ | 1542/1892 [1:54:37<5:21:17, 55.08s/it] 82%|████████▏ | 1543/1892 [1:55:33<5:20:35, 55.12s/it]                                                       {'loss': 0.2291, 'learning_rate': 1.732563823390695e-06, 'epoch': 3.26}
 82%|████████▏ | 1543/1892 [1:55:33<5:20:35, 55.12s/it] 82%|████████▏ | 1544/1892 [1:56:28<5:19:36, 55.11s/it]                                                       {'loss': 0.2039, 'learning_rate': 1.7229443712654093e-06, 'epoch': 3.26}
 82%|████████▏ | 1544/1892 [1:56:28<5:19:36, 55.11s/it] 82%|████████▏ | 1545/1892 [1:57:23<5:18:37, 55.09s/it]                                                       {'loss': 0.204, 'learning_rate': 1.7133491798428392e-06, 'epoch': 3.27}
 82%|████████▏ | 1545/1892 [1:57:23<5:18:37, 55.09s/it] 82%|████████▏ | 1546/1892 [1:58:18<5:17:45, 55.10s/it]                                                       {'loss': 0.2202, 'learning_rate': 1.7037782772472489e-06, 'epoch': 3.27}
 82%|████████▏ | 1546/1892 [1:58:18<5:17:45, 55.10s/it] 82%|████████▏ | 1547/1892 [1:59:13<5:16:42, 55.08s/it]                                                       {'loss': 0.195, 'learning_rate': 1.6942316915317091e-06, 'epoch': 3.27}
 82%|████████▏ | 1547/1892 [1:59:13<5:16:42, 55.08s/it] 82%|████████▏ | 1548/1892 [2:00:08<5:15:44, 55.07s/it]                                                       {'loss': 0.2073, 'learning_rate': 1.6847094506780148e-06, 'epoch': 3.27}
 82%|████████▏ | 1548/1892 [2:00:08<5:15:44, 55.07s/it] 82%|████████▏ | 1549/1892 [2:01:03<5:14:44, 55.06s/it]                                                       {'loss': 0.2437, 'learning_rate': 1.6752115825966087e-06, 'epoch': 3.27}
 82%|████████▏ | 1549/1892 [2:01:03<5:14:44, 55.06s/it] 82%|████████▏ | 1550/1892 [2:01:58<5:13:58, 55.08s/it]                                                       {'loss': 0.1975, 'learning_rate': 1.665738115126484e-06, 'epoch': 3.28}
 82%|████████▏ | 1550/1892 [2:01:58<5:13:58, 55.08s/it] 82%|████████▏ | 1551/1892 [2:02:53<5:12:53, 55.05s/it]                                                       {'loss': 0.2301, 'learning_rate': 1.6562890760351247e-06, 'epoch': 3.28}
 82%|████████▏ | 1551/1892 [2:02:53<5:12:53, 55.05s/it] 82%|████████▏ | 1552/1892 [2:03:48<5:12:04, 55.07s/it]                                                       {'loss': 0.2028, 'learning_rate': 1.6468644930184097e-06, 'epoch': 3.28}
 82%|████████▏ | 1552/1892 [2:03:48<5:12:04, 55.07s/it] 82%|████████▏ | 1553/1892 [2:04:43<5:11:07, 55.07s/it]                                                       {'loss': 0.2079, 'learning_rate': 1.6374643937005353e-06, 'epoch': 3.28}
 82%|████████▏ | 1553/1892 [2:04:43<5:11:07, 55.07s/it] 82%|████████▏ | 1554/1892 [2:05:38<5:10:08, 55.05s/it]                                                       {'loss': 0.1841, 'learning_rate': 1.628088805633934e-06, 'epoch': 3.29}
 82%|████████▏ | 1554/1892 [2:05:38<5:10:08, 55.05s/it] 82%|████████▏ | 1555/1892 [2:06:33<5:09:00, 55.02s/it]                                                       {'loss': 0.2034, 'learning_rate': 1.6187377562991903e-06, 'epoch': 3.29}
 82%|████████▏ | 1555/1892 [2:06:33<5:09:00, 55.02s/it] 82%|████████▏ | 1556/1892 [2:07:28<5:08:06, 55.02s/it]                                                       {'loss': 0.2032, 'learning_rate': 1.6094112731049693e-06, 'epoch': 3.29}
 82%|████████▏ | 1556/1892 [2:07:28<5:08:06, 55.02s/it] 82%|████████▏ | 1557/1892 [2:08:23<5:07:14, 55.03s/it]                                                       {'loss': 0.2304, 'learning_rate': 1.6001093833879288e-06, 'epoch': 3.29}
 82%|████████▏ | 1557/1892 [2:08:23<5:07:14, 55.03s/it] 82%|████████▏ | 1558/1892 [2:09:18<5:06:16, 55.02s/it]                                                       {'loss': 0.1985, 'learning_rate': 1.5908321144126415e-06, 'epoch': 3.29}
 82%|████████▏ | 1558/1892 [2:09:18<5:06:16, 55.02s/it] 82%|████████▏ | 1559/1892 [2:10:13<5:05:32, 55.05s/it]                                                       {'loss': 0.2491, 'learning_rate': 1.5815794933715168e-06, 'epoch': 3.3}
 82%|████████▏ | 1559/1892 [2:10:13<5:05:32, 55.05s/it] 82%|████████▏ | 1560/1892 [2:11:08<5:04:28, 55.02s/it]                                                       {'loss': 0.2003, 'learning_rate': 1.5723515473847095e-06, 'epoch': 3.3}
 82%|████████▏ | 1560/1892 [2:11:08<5:04:28, 55.02s/it] 83%|████████▎ | 1561/1892 [2:12:03<5:03:36, 55.04s/it]                                                       {'loss': 0.2377, 'learning_rate': 1.5631483035000627e-06, 'epoch': 3.3}
 83%|████████▎ | 1561/1892 [2:12:03<5:03:36, 55.04s/it] 83%|████████▎ | 1562/1892 [2:12:58<5:02:32, 55.01s/it]                                                       {'loss': 0.2425, 'learning_rate': 1.5539697886930082e-06, 'epoch': 3.3}
 83%|████████▎ | 1562/1892 [2:12:58<5:02:32, 55.01s/it] 83%|████████▎ | 1563/1892 [2:13:53<5:01:40, 55.02s/it]                                                       {'loss': 0.2244, 'learning_rate': 1.5448160298664982e-06, 'epoch': 3.3}
 83%|████████▎ | 1563/1892 [2:13:53<5:01:40, 55.02s/it] 83%|████████▎ | 1564/1892 [2:14:48<5:00:35, 54.99s/it]                                                       {'loss': 0.2215, 'learning_rate': 1.5356870538509195e-06, 'epoch': 3.31}
 83%|████████▎ | 1564/1892 [2:14:48<5:00:35, 54.99s/it] 83%|████████▎ | 1565/1892 [2:15:43<4:59:31, 54.96s/it]                                                       {'loss': 0.203, 'learning_rate': 1.52658288740402e-06, 'epoch': 3.31}
 83%|████████▎ | 1565/1892 [2:15:43<4:59:31, 54.96s/it] 83%|████████▎ | 1566/1892 [2:16:38<4:58:37, 54.96s/it]                                                       {'loss': 0.225, 'learning_rate': 1.517503557210831e-06, 'epoch': 3.31}
 83%|████████▎ | 1566/1892 [2:16:38<4:58:37, 54.96s/it] 83%|████████▎ | 1567/1892 [2:17:33<4:57:53, 55.00s/it]                                                       {'loss': 0.2057, 'learning_rate': 1.5084490898835857e-06, 'epoch': 3.31}
 83%|████████▎ | 1567/1892 [2:17:33<4:57:53, 55.00s/it] 83%|████████▎ | 1568/1892 [2:18:28<4:56:54, 54.98s/it]                                                       {'loss': 0.2327, 'learning_rate': 1.4994195119616428e-06, 'epoch': 3.31}
 83%|████████▎ | 1568/1892 [2:18:28<4:56:54, 54.98s/it] 83%|████████▎ | 1569/1892 [2:19:23<4:55:56, 54.97s/it]                                                       {'loss': 0.1917, 'learning_rate': 1.4904148499114057e-06, 'epoch': 3.32}
 83%|████████▎ | 1569/1892 [2:19:23<4:55:56, 54.97s/it] 83%|████████▎ | 1570/1892 [2:20:18<4:54:55, 54.95s/it]                                                       {'loss': 0.207, 'learning_rate': 1.4814351301262463e-06, 'epoch': 3.32}
 83%|████████▎ | 1570/1892 [2:20:18<4:54:55, 54.95s/it] 83%|████████▎ | 1571/1892 [2:21:13<4:54:01, 54.96s/it]                                                       {'loss': 0.2072, 'learning_rate': 1.472480378926434e-06, 'epoch': 3.32}
 83%|████████▎ | 1571/1892 [2:21:13<4:54:01, 54.96s/it] 83%|████████▎ | 1572/1892 [2:22:08<4:52:51, 54.91s/it]                                                       {'loss': 0.2063, 'learning_rate': 1.4635506225590511e-06, 'epoch': 3.32}
 83%|████████▎ | 1572/1892 [2:22:08<4:52:51, 54.91s/it] 83%|████████▎ | 1573/1892 [2:23:03<4:51:55, 54.91s/it]                                                       {'loss': 0.2054, 'learning_rate': 1.4546458871979185e-06, 'epoch': 3.33}
 83%|████████▎ | 1573/1892 [2:23:03<4:51:55, 54.91s/it] 83%|████████▎ | 1574/1892 [2:23:58<4:51:15, 54.95s/it]                                                       {'loss': 0.2127, 'learning_rate': 1.4457661989435146e-06, 'epoch': 3.33}
 83%|████████▎ | 1574/1892 [2:23:58<4:51:15, 54.95s/it] 83%|████████▎ | 1575/1892 [2:24:53<4:50:18, 54.95s/it]                                                       {'loss': 0.2217, 'learning_rate': 1.4369115838229075e-06, 'epoch': 3.33}
 83%|████████▎ | 1575/1892 [2:24:53<4:50:18, 54.95s/it] 83%|████████▎ | 1576/1892 [2:25:48<4:49:31, 54.97s/it]                                                       {'loss': 0.2251, 'learning_rate': 1.4280820677896723e-06, 'epoch': 3.33}
 83%|████████▎ | 1576/1892 [2:25:48<4:49:31, 54.97s/it] 83%|████████▎ | 1577/1892 [2:26:43<4:48:35, 54.97s/it]                                                       {'loss': 0.2189, 'learning_rate': 1.419277676723816e-06, 'epoch': 3.33}
 83%|████████▎ | 1577/1892 [2:26:43<4:48:35, 54.97s/it] 83%|████████▎ | 1578/1892 [2:27:38<4:47:33, 54.95s/it]                                                       {'loss': 0.214, 'learning_rate': 1.4104984364317066e-06, 'epoch': 3.34}
 83%|████████▎ | 1578/1892 [2:27:38<4:47:33, 54.95s/it] 83%|████████▎ | 1579/1892 [2:28:33<4:46:39, 54.95s/it]                                                       {'loss': 0.2182, 'learning_rate': 1.4017443726459855e-06, 'epoch': 3.34}
 83%|████████▎ | 1579/1892 [2:28:33<4:46:39, 54.95s/it] 84%|████████▎ | 1580/1892 [2:29:27<4:45:44, 54.95s/it]                                                       {'loss': 0.2276, 'learning_rate': 1.3930155110255038e-06, 'epoch': 3.34}
 84%|████████▎ | 1580/1892 [2:29:27<4:45:44, 54.95s/it] 84%|████████▎ | 1581/1892 [2:30:22<4:44:46, 54.94s/it]                                                       {'loss': 0.2248, 'learning_rate': 1.3843118771552455e-06, 'epoch': 3.34}
 84%|████████▎ | 1581/1892 [2:30:22<4:44:46, 54.94s/it] 84%|████████▎ | 1582/1892 [2:31:17<4:43:42, 54.91s/it]                                                       {'loss': 0.2388, 'learning_rate': 1.3756334965462502e-06, 'epoch': 3.34}
 84%|████████▎ | 1582/1892 [2:31:17<4:43:42, 54.91s/it] 84%|████████▎ | 1583/1892 [2:32:12<4:43:01, 54.96s/it]                                                       {'loss': 0.2021, 'learning_rate': 1.366980394635532e-06, 'epoch': 3.35}
 84%|████████▎ | 1583/1892 [2:32:12<4:43:01, 54.96s/it] 84%|████████▎ | 1584/1892 [2:33:07<4:42:15, 54.98s/it]                                                       {'loss': 0.2067, 'learning_rate': 1.3583525967860122e-06, 'epoch': 3.35}
 84%|████████▎ | 1584/1892 [2:33:07<4:42:15, 54.98s/it] 84%|████████▍ | 1585/1892 [2:34:02<4:41:14, 54.97s/it]                                                       {'loss': 0.2016, 'learning_rate': 1.3497501282864512e-06, 'epoch': 3.35}
 84%|████████▍ | 1585/1892 [2:34:02<4:41:14, 54.97s/it] 84%|████████▍ | 1586/1892 [2:34:57<4:40:17, 54.96s/it]                                                       {'loss': 0.2115, 'learning_rate': 1.3411730143513612e-06, 'epoch': 3.35}
 84%|████████▍ | 1586/1892 [2:34:57<4:40:17, 54.96s/it] 84%|████████▍ | 1587/1892 [2:35:52<4:39:07, 54.91s/it]                                                       {'loss': 0.2018, 'learning_rate': 1.3326212801209392e-06, 'epoch': 3.35}
 84%|████████▍ | 1587/1892 [2:35:52<4:39:07, 54.91s/it] 84%|████████▍ | 1588/1892 [2:36:47<4:38:04, 54.88s/it]                                                       {'loss': 0.2024, 'learning_rate': 1.3240949506609945e-06, 'epoch': 3.36}
 84%|████████▍ | 1588/1892 [2:36:47<4:38:04, 54.88s/it] 84%|████████▍ | 1589/1892 [2:37:42<4:37:12, 54.89s/it]                                                       {'loss': 0.2068, 'learning_rate': 1.3155940509628685e-06, 'epoch': 3.36}
 84%|████████▍ | 1589/1892 [2:37:42<4:37:12, 54.89s/it] 84%|████████▍ | 1590/1892 [2:38:37<4:36:16, 54.89s/it]                                                       {'loss': 0.2172, 'learning_rate': 1.3071186059433694e-06, 'epoch': 3.36}
 84%|████████▍ | 1590/1892 [2:38:37<4:36:16, 54.89s/it] 84%|████████▍ | 1591/1892 [2:39:32<4:35:35, 54.93s/it]                                                       {'loss': 0.2091, 'learning_rate': 1.2986686404446947e-06, 'epoch': 3.36}
 84%|████████▍ | 1591/1892 [2:39:32<4:35:35, 54.93s/it] 84%|████████▍ | 1592/1892 [2:40:27<4:34:35, 54.92s/it]                                                       {'loss': 0.2274, 'learning_rate': 1.2902441792343611e-06, 'epoch': 3.37}
 84%|████████▍ | 1592/1892 [2:40:27<4:34:35, 54.92s/it] 84%|████████▍ | 1593/1892 [2:41:21<4:33:35, 54.90s/it]                                                       {'loss': 0.2229, 'learning_rate': 1.2818452470051267e-06, 'epoch': 3.37}
 84%|████████▍ | 1593/1892 [2:41:21<4:33:35, 54.90s/it] 84%|████████▍ | 1594/1892 [2:42:16<4:32:36, 54.89s/it]                                                       {'loss': 0.2048, 'learning_rate': 1.2734718683749237e-06, 'epoch': 3.37}
 84%|████████▍ | 1594/1892 [2:42:16<4:32:36, 54.89s/it] 84%|████████▍ | 1595/1892 [2:43:11<4:31:29, 54.85s/it]                                                       {'loss': 0.2183, 'learning_rate': 1.265124067886787e-06, 'epoch': 3.37}
 84%|████████▍ | 1595/1892 [2:43:11<4:31:29, 54.85s/it] 84%|████████▍ | 1596/1892 [2:44:06<4:30:35, 54.85s/it]                                                       {'loss': 0.1918, 'learning_rate': 1.2568018700087793e-06, 'epoch': 3.37}
 84%|████████▍ | 1596/1892 [2:44:06<4:30:35, 54.85s/it] 84%|████████▍ | 1597/1892 [2:45:01<4:29:37, 54.84s/it]                                                       {'loss': 0.2166, 'learning_rate': 1.2485052991339174e-06, 'epoch': 3.38}
 84%|████████▍ | 1597/1892 [2:45:01<4:29:37, 54.84s/it] 84%|████████▍ | 1598/1892 [2:45:56<4:28:57, 54.89s/it]                                                       {'loss': 0.2091, 'learning_rate': 1.240234379580102e-06, 'epoch': 3.38}
 84%|████████▍ | 1598/1892 [2:45:56<4:28:57, 54.89s/it] 85%|████████▍ | 1599/1892 [2:46:51<4:28:06, 54.90s/it]                                                       {'loss': 0.1973, 'learning_rate': 1.2319891355900526e-06, 'epoch': 3.38}
 85%|████████▍ | 1599/1892 [2:46:51<4:28:06, 54.90s/it] 85%|████████▍ | 1600/1892 [2:47:45<4:26:55, 54.85s/it]                                                       {'loss': 0.2109, 'learning_rate': 1.2237695913312286e-06, 'epoch': 3.38}
 85%|████████▍ | 1600/1892 [2:47:45<4:26:55, 54.85s/it] 85%|████████▍ | 1601/1892 [2:48:40<4:25:56, 54.83s/it]                                                       {'loss': 0.2238, 'learning_rate': 1.215575770895765e-06, 'epoch': 3.38}
 85%|████████▍ | 1601/1892 [2:48:40<4:25:56, 54.83s/it] 85%|████████▍ | 1602/1892 [2:49:35<4:25:07, 54.85s/it]                                                       {'loss': 0.2291, 'learning_rate': 1.2074076983003956e-06, 'epoch': 3.39}
 85%|████████▍ | 1602/1892 [2:49:35<4:25:07, 54.85s/it] 85%|████████▍ | 1603/1892 [2:50:30<4:24:04, 54.83s/it]                                                       {'loss': 0.2207, 'learning_rate': 1.199265397486381e-06, 'epoch': 3.39}
 85%|████████▍ | 1603/1892 [2:50:30<4:24:04, 54.83s/it] 85%|████████▍ | 1604/1892 [2:51:25<4:23:04, 54.81s/it]                                                       {'loss': 0.2115, 'learning_rate': 1.1911488923194502e-06, 'epoch': 3.39}
 85%|████████▍ | 1604/1892 [2:51:25<4:23:04, 54.81s/it] 85%|████████▍ | 1605/1892 [2:52:19<4:22:10, 54.81s/it]                                                       {'loss': 0.2297, 'learning_rate': 1.183058206589719e-06, 'epoch': 3.39}
 85%|████████▍ | 1605/1892 [2:52:19<4:22:10, 54.81s/it] 85%|████████▍ | 1606/1892 [2:53:14<4:21:28, 54.85s/it]                                                       {'loss': 0.2035, 'learning_rate': 1.1749933640116285e-06, 'epoch': 3.39}
 85%|████████▍ | 1606/1892 [2:53:14<4:21:28, 54.85s/it] 85%|████████▍ | 1607/1892 [2:54:09<4:20:24, 54.82s/it]                                                       {'loss': 0.2137, 'learning_rate': 1.166954388223862e-06, 'epoch': 3.4}
 85%|████████▍ | 1607/1892 [2:54:09<4:20:24, 54.82s/it] 85%|████████▍ | 1608/1892 [2:55:04<4:19:37, 54.85s/it]                                                       {'loss': 0.2004, 'learning_rate': 1.1589413027892949e-06, 'epoch': 3.4}
 85%|████████▍ | 1608/1892 [2:55:04<4:19:37, 54.85s/it] 85%|████████▌ | 1609/1892 [2:55:59<4:18:40, 54.84s/it]                                                       {'loss': 0.2047, 'learning_rate': 1.1509541311949125e-06, 'epoch': 3.4}
 85%|████████▌ | 1609/1892 [2:55:59<4:18:40, 54.84s/it] 85%|████████▌ | 1610/1892 [2:56:54<4:17:39, 54.82s/it]                                                       {'loss': 0.2186, 'learning_rate': 1.1429928968517456e-06, 'epoch': 3.4}
 85%|████████▌ | 1610/1892 [2:56:54<4:17:39, 54.82s/it] 85%|████████▌ | 1611/1892 [2:57:49<4:16:54, 54.85s/it]                                                       {'loss': 0.2089, 'learning_rate': 1.1350576230947974e-06, 'epoch': 3.41}
 85%|████████▌ | 1611/1892 [2:57:49<4:16:54, 54.85s/it] 85%|████████▌ | 1612/1892 [2:58:43<4:15:58, 54.85s/it]                                                       {'loss': 0.1987, 'learning_rate': 1.1271483331829835e-06, 'epoch': 3.41}
 85%|████████▌ | 1612/1892 [2:58:43<4:15:58, 54.85s/it] 85%|████████▌ | 1613/1892 [2:59:38<4:14:57, 54.83s/it]                                                       {'loss': 0.2114, 'learning_rate': 1.1192650502990531e-06, 'epoch': 3.41}
 85%|████████▌ | 1613/1892 [2:59:38<4:14:57, 54.83s/it] 85%|████████▌ | 1614/1892 [3:00:33<4:13:57, 54.81s/it]                                                       {'loss': 0.1954, 'learning_rate': 1.111407797549532e-06, 'epoch': 3.41}
 85%|████████▌ | 1614/1892 [3:00:33<4:13:57, 54.81s/it] 85%|████████▌ | 1615/1892 [3:01:28<4:13:11, 54.84s/it]                                                       {'loss': 0.1928, 'learning_rate': 1.1035765979646473e-06, 'epoch': 3.41}
 85%|████████▌ | 1615/1892 [3:01:28<4:13:11, 54.84s/it] 85%|████████▌ | 1616/1892 [3:02:23<4:12:07, 54.81s/it]                                                       {'loss': 0.2006, 'learning_rate': 1.095771474498265e-06, 'epoch': 3.42}
 85%|████████▌ | 1616/1892 [3:02:23<4:12:07, 54.81s/it] 85%|████████▌ | 1617/1892 [3:03:17<4:11:11, 54.80s/it]                                                       {'loss': 0.1935, 'learning_rate': 1.0879924500278116e-06, 'epoch': 3.42}
 85%|████████▌ | 1617/1892 [3:03:17<4:11:11, 54.80s/it] 86%|████████▌ | 1618/1892 [3:04:12<4:10:22, 54.83s/it]                                                       {'loss': 0.2054, 'learning_rate': 1.080239547354226e-06, 'epoch': 3.42}
 86%|████████▌ | 1618/1892 [3:04:12<4:10:22, 54.83s/it] 86%|████████▌ | 1619/1892 [3:05:07<4:09:30, 54.84s/it]                                                       {'loss': 0.2229, 'learning_rate': 1.0725127892018749e-06, 'epoch': 3.42}
 86%|████████▌ | 1619/1892 [3:05:07<4:09:30, 54.84s/it] 86%|████████▌ | 1620/1892 [3:06:02<4:08:32, 54.83s/it]                                                       {'loss': 0.2432, 'learning_rate': 1.0648121982184968e-06, 'epoch': 3.42}
 86%|████████▌ | 1620/1892 [3:06:02<4:08:32, 54.83s/it] 86%|████████▌ | 1621/1892 [3:06:57<4:07:37, 54.82s/it]                                                       {'loss': 0.1966, 'learning_rate': 1.0571377969751339e-06, 'epoch': 3.43}
 86%|████████▌ | 1621/1892 [3:06:57<4:07:37, 54.82s/it] 86%|████████▌ | 1622/1892 [3:07:52<4:06:43, 54.83s/it]                                                       {'loss': 0.2082, 'learning_rate': 1.0494896079660554e-06, 'epoch': 3.43}
 86%|████████▌ | 1622/1892 [3:07:52<4:06:43, 54.83s/it] 86%|████████▌ | 1623/1892 [3:08:46<4:05:53, 54.85s/it]                                                       {'loss': 0.2053, 'learning_rate': 1.0418676536087113e-06, 'epoch': 3.43}
 86%|████████▌ | 1623/1892 [3:08:46<4:05:53, 54.85s/it] 86%|████████▌ | 1624/1892 [3:09:41<4:04:52, 54.82s/it]                                                       {'loss': 0.205, 'learning_rate': 1.0342719562436477e-06, 'epoch': 3.43}
 86%|████████▌ | 1624/1892 [3:09:41<4:04:52, 54.82s/it] 86%|████████▌ | 1625/1892 [3:10:36<4:04:06, 54.86s/it]                                                       {'loss': 0.2017, 'learning_rate': 1.026702538134453e-06, 'epoch': 3.44}
 86%|████████▌ | 1625/1892 [3:10:36<4:04:06, 54.86s/it] 86%|████████▌ | 1626/1892 [3:11:31<4:03:22, 54.90s/it]                                                       {'loss': 0.2157, 'learning_rate': 1.0191594214676926e-06, 'epoch': 3.44}
 86%|████████▌ | 1626/1892 [3:11:31<4:03:22, 54.90s/it] 86%|████████▌ | 1627/1892 [3:12:26<4:02:16, 54.85s/it]                                                       {'loss': 0.2147, 'learning_rate': 1.0116426283528301e-06, 'epoch': 3.44}
 86%|████████▌ | 1627/1892 [3:12:26<4:02:16, 54.85s/it] 86%|████████▌ | 1628/1892 [3:13:21<4:01:13, 54.82s/it]                                                       {'loss': 0.2178, 'learning_rate': 1.004152180822182e-06, 'epoch': 3.44}
 86%|████████▌ | 1628/1892 [3:13:21<4:01:13, 54.82s/it] 86%|████████▌ | 1629/1892 [3:14:15<4:00:17, 54.82s/it]                                                       {'loss': 0.2126, 'learning_rate': 9.966881008308404e-07, 'epoch': 3.44}
 86%|████████▌ | 1629/1892 [3:14:15<4:00:17, 54.82s/it] 86%|████████▌ | 1630/1892 [3:15:10<3:59:21, 54.82s/it]                                                       {'loss': 0.2163, 'learning_rate': 9.892504102566115e-07, 'epoch': 3.45}
 86%|████████▌ | 1630/1892 [3:15:10<3:59:21, 54.82s/it] 86%|████████▌ | 1631/1892 [3:16:05<3:58:31, 54.83s/it]                                                       {'loss': 0.2226, 'learning_rate': 9.818391308999563e-07, 'epoch': 3.45}
 86%|████████▌ | 1631/1892 [3:16:05<3:58:31, 54.83s/it] 86%|████████▋ | 1632/1892 [3:17:00<3:57:30, 54.81s/it]                                                       {'loss': 0.2188, 'learning_rate': 9.744542844839145e-07, 'epoch': 3.45}
 86%|████████▋ | 1632/1892 [3:17:00<3:57:30, 54.81s/it] 86%|████████▋ | 1633/1892 [3:17:55<3:56:41, 54.83s/it]                                                       {'loss': 0.2171, 'learning_rate': 9.670958926540553e-07, 'epoch': 3.45}
 86%|████████▋ | 1633/1892 [3:17:55<3:56:41, 54.83s/it] 86%|████████▋ | 1634/1892 [3:18:50<3:55:43, 54.82s/it]                                                       {'loss': 0.2069, 'learning_rate': 9.59763976978405e-07, 'epoch': 3.45}
 86%|████████▋ | 1634/1892 [3:18:50<3:55:43, 54.82s/it] 86%|████████▋ | 1635/1892 [3:19:44<3:54:42, 54.80s/it]                                                       {'loss': 0.2248, 'learning_rate': 9.524585589473878e-07, 'epoch': 3.46}
 86%|████████▋ | 1635/1892 [3:19:44<3:54:42, 54.80s/it] 86%|████████▋ | 1636/1892 [3:20:39<3:53:39, 54.76s/it]                                                       {'loss': 0.2233, 'learning_rate': 9.451796599737584e-07, 'epoch': 3.46}
 86%|████████▋ | 1636/1892 [3:20:39<3:53:39, 54.76s/it] 87%|████████▋ | 1637/1892 [3:21:34<3:52:45, 54.77s/it]                                                       {'loss': 0.1971, 'learning_rate': 9.379273013925449e-07, 'epoch': 3.46}
 87%|████████▋ | 1637/1892 [3:21:34<3:52:45, 54.77s/it] 87%|████████▋ | 1638/1892 [3:22:28<3:51:44, 54.74s/it]                                                       {'loss': 0.2277, 'learning_rate': 9.307015044609813e-07, 'epoch': 3.46}
 87%|████████▋ | 1638/1892 [3:22:28<3:51:44, 54.74s/it] 87%|████████▋ | 1639/1892 [3:23:23<3:50:51, 54.75s/it]                                                       {'loss': 0.2087, 'learning_rate': 9.235022903584467e-07, 'epoch': 3.46}
 87%|████████▋ | 1639/1892 [3:23:23<3:50:51, 54.75s/it] 87%|████████▋ | 1640/1892 [3:24:18<3:49:57, 54.75s/it]                                                       {'loss': 0.2147, 'learning_rate': 9.163296801864074e-07, 'epoch': 3.47}
 87%|████████▋ | 1640/1892 [3:24:18<3:49:57, 54.75s/it] 87%|████████▋ | 1641/1892 [3:25:13<3:49:10, 54.78s/it]                                                       {'loss': 0.1942, 'learning_rate': 9.091836949683519e-07, 'epoch': 3.47}
 87%|████████▋ | 1641/1892 [3:25:13<3:49:10, 54.78s/it] 87%|████████▋ | 1642/1892 [3:26:08<3:48:10, 54.76s/it]                                                       {'loss': 0.2086, 'learning_rate': 9.020643556497211e-07, 'epoch': 3.47}
 87%|████████▋ | 1642/1892 [3:26:08<3:48:10, 54.76s/it] 87%|████████▋ | 1643/1892 [3:27:02<3:47:22, 54.79s/it]                                                       {'loss': 0.2017, 'learning_rate': 8.949716830978616e-07, 'epoch': 3.47}
 87%|████████▋ | 1643/1892 [3:27:02<3:47:22, 54.79s/it] 87%|████████▋ | 1644/1892 [3:27:57<3:46:30, 54.80s/it]                                                       {'loss': 0.2101, 'learning_rate': 8.879056981019574e-07, 'epoch': 3.48}
 87%|████████▋ | 1644/1892 [3:27:57<3:46:30, 54.80s/it] 87%|████████▋ | 1645/1892 [3:28:52<3:45:45, 54.84s/it]                                                       {'loss': 0.2368, 'learning_rate': 8.808664213729678e-07, 'epoch': 3.48}
 87%|████████▋ | 1645/1892 [3:28:52<3:45:45, 54.84s/it] 87%|████████▋ | 1646/1892 [3:29:47<3:44:38, 54.79s/it]                                                       {'loss': 0.2107, 'learning_rate': 8.738538735435654e-07, 'epoch': 3.48}
 87%|████████▋ | 1646/1892 [3:29:47<3:44:38, 54.79s/it] 87%|████████▋ | 1647/1892 [3:30:42<3:43:50, 54.82s/it]                                                       {'loss': 0.1946, 'learning_rate': 8.668680751680836e-07, 'epoch': 3.48}
 87%|████████▋ | 1647/1892 [3:30:42<3:43:50, 54.82s/it] 87%|████████▋ | 1648/1892 [3:31:37<3:42:57, 54.83s/it]                                                       {'loss': 0.2192, 'learning_rate': 8.599090467224458e-07, 'epoch': 3.48}
 87%|████████▋ | 1648/1892 [3:31:37<3:42:57, 54.83s/it] 87%|████████▋ | 1649/1892 [3:32:31<3:42:07, 54.84s/it]                                                       {'loss': 0.2224, 'learning_rate': 8.529768086041157e-07, 'epoch': 3.49}
 87%|████████▋ | 1649/1892 [3:32:31<3:42:07, 54.84s/it] 87%|████████▋ | 1650/1892 [3:33:26<3:41:12, 54.84s/it]                                                       {'loss': 0.2121, 'learning_rate': 8.460713811320298e-07, 'epoch': 3.49}
 87%|████████▋ | 1650/1892 [3:33:26<3:41:12, 54.84s/it] 87%|████████▋ | 1651/1892 [3:34:21<3:40:16, 54.84s/it]                                                       {'loss': 0.2239, 'learning_rate': 8.391927845465398e-07, 'epoch': 3.49}
 87%|████████▋ | 1651/1892 [3:34:21<3:40:16, 54.84s/it] 87%|████████▋ | 1652/1892 [3:35:16<3:39:06, 54.78s/it]                                                       {'loss': 0.2059, 'learning_rate': 8.323410390093523e-07, 'epoch': 3.49}
 87%|████████▋ | 1652/1892 [3:35:16<3:39:06, 54.78s/it] 87%|████████▋ | 1653/1892 [3:36:11<3:38:15, 54.79s/it]                                                       {'loss': 0.2016, 'learning_rate': 8.255161646034748e-07, 'epoch': 3.49}
 87%|████████▋ | 1653/1892 [3:36:11<3:38:15, 54.79s/it] 87%|████████▋ | 1654/1892 [3:37:05<3:37:16, 54.78s/it]                                                       {'loss': 0.2144, 'learning_rate': 8.187181813331547e-07, 'epoch': 3.5}
 87%|████████▋ | 1654/1892 [3:37:05<3:37:16, 54.78s/it] 87%|████████▋ | 1655/1892 [3:38:00<3:36:23, 54.78s/it]                                                       {'loss': 0.2188, 'learning_rate': 8.119471091238162e-07, 'epoch': 3.5}
 87%|████████▋ | 1655/1892 [3:38:00<3:36:23, 54.78s/it] 88%|████████▊ | 1656/1892 [3:38:55<3:35:30, 54.79s/it]                                                       {'loss': 0.2005, 'learning_rate': 8.052029678220042e-07, 'epoch': 3.5}
 88%|████████▊ | 1656/1892 [3:38:55<3:35:30, 54.79s/it] 88%|████████▊ | 1657/1892 [3:39:50<3:34:36, 54.79s/it]                                                       {'loss': 0.2247, 'learning_rate': 7.984857771953303e-07, 'epoch': 3.5}
 88%|████████▊ | 1657/1892 [3:39:50<3:34:36, 54.79s/it] 88%|████████▊ | 1658/1892 [3:40:45<3:33:42, 54.79s/it]                                                       {'loss': 0.199, 'learning_rate': 7.917955569324087e-07, 'epoch': 3.5}
 88%|████████▊ | 1658/1892 [3:40:45<3:33:42, 54.79s/it] 88%|████████▊ | 1659/1892 [3:41:39<3:32:39, 54.76s/it]                                                       {'loss': 0.2218, 'learning_rate': 7.851323266428046e-07, 'epoch': 3.51}
 88%|████████▊ | 1659/1892 [3:41:39<3:32:39, 54.76s/it] 88%|████████▊ | 1660/1892 [3:42:34<3:31:44, 54.76s/it]                                                       {'loss': 0.2129, 'learning_rate': 7.784961058569684e-07, 'epoch': 3.51}
 88%|████████▊ | 1660/1892 [3:42:34<3:31:44, 54.76s/it] 88%|████████▊ | 1661/1892 [3:43:29<3:30:49, 54.76s/it]                                                       {'loss': 0.2359, 'learning_rate': 7.718869140261875e-07, 'epoch': 3.51}
 88%|████████▊ | 1661/1892 [3:43:29<3:30:49, 54.76s/it] 88%|████████▊ | 1662/1892 [3:44:24<3:29:58, 54.77s/it]                                                       {'loss': 0.1964, 'learning_rate': 7.653047705225258e-07, 'epoch': 3.51}
 88%|████████▊ | 1662/1892 [3:44:24<3:29:58, 54.77s/it] 88%|████████▊ | 1663/1892 [3:45:18<3:29:03, 54.78s/it]                                                       {'loss': 0.2147, 'learning_rate': 7.587496946387629e-07, 'epoch': 3.52}
 88%|████████▊ | 1663/1892 [3:45:18<3:29:03, 54.78s/it] 88%|████████▊ | 1664/1892 [3:46:13<3:28:07, 54.77s/it]                                                       {'loss': 0.2012, 'learning_rate': 7.522217055883463e-07, 'epoch': 3.52}
 88%|████████▊ | 1664/1892 [3:46:13<3:28:07, 54.77s/it] 88%|████████▊ | 1665/1892 [3:47:08<3:27:15, 54.78s/it]                                                       {'loss': 0.2126, 'learning_rate': 7.457208225053248e-07, 'epoch': 3.52}
 88%|████████▊ | 1665/1892 [3:47:08<3:27:15, 54.78s/it] 88%|████████▊ | 1666/1892 [3:48:03<3:26:13, 54.75s/it]                                                       {'loss': 0.2216, 'learning_rate': 7.392470644442973e-07, 'epoch': 3.52}
 88%|████████▊ | 1666/1892 [3:48:03<3:26:13, 54.75s/it] 88%|████████▊ | 1667/1892 [3:48:57<3:25:13, 54.72s/it]                                                       {'loss': 0.2204, 'learning_rate': 7.328004503803609e-07, 'epoch': 3.52}
 88%|████████▊ | 1667/1892 [3:48:57<3:25:13, 54.72s/it] 88%|████████▊ | 1668/1892 [3:49:52<3:24:22, 54.74s/it]                                                       {'loss': 0.2141, 'learning_rate': 7.263809992090498e-07, 'epoch': 3.53}
 88%|████████▊ | 1668/1892 [3:49:52<3:24:22, 54.74s/it] 88%|████████▊ | 1669/1892 [3:50:47<3:23:30, 54.76s/it]                                                       {'loss': 0.2142, 'learning_rate': 7.199887297462838e-07, 'epoch': 3.53}
 88%|████████▊ | 1669/1892 [3:50:47<3:23:30, 54.76s/it] 88%|████████▊ | 1670/1892 [3:51:42<3:22:37, 54.76s/it]                                                       {'loss': 0.2121, 'learning_rate': 7.136236607283032e-07, 'epoch': 3.53}
 88%|████████▊ | 1670/1892 [3:51:42<3:22:37, 54.76s/it] 88%|████████▊ | 1671/1892 [3:52:36<3:21:38, 54.75s/it]                                                       {'loss': 0.1992, 'learning_rate': 7.07285810811632e-07, 'epoch': 3.53}
 88%|████████▊ | 1671/1892 [3:52:36<3:21:38, 54.75s/it] 88%|████████▊ | 1672/1892 [3:53:31<3:20:40, 54.73s/it]                                                       {'loss': 0.2105, 'learning_rate': 7.009751985730062e-07, 'epoch': 3.53}
 88%|████████▊ | 1672/1892 [3:53:31<3:20:40, 54.73s/it] 88%|████████▊ | 1673/1892 [3:54:26<3:19:39, 54.70s/it]                                                       {'loss': 0.2393, 'learning_rate': 6.946918425093274e-07, 'epoch': 3.54}
 88%|████████▊ | 1673/1892 [3:54:26<3:19:39, 54.70s/it] 88%|████████▊ | 1674/1892 [3:55:20<3:18:48, 54.72s/it]                                                       {'loss': 0.2038, 'learning_rate': 6.884357610376113e-07, 'epoch': 3.54}
 88%|████████▊ | 1674/1892 [3:55:20<3:18:48, 54.72s/it] 89%|████████▊ | 1675/1892 [3:56:15<3:17:51, 54.71s/it]                                                       {'loss': 0.2005, 'learning_rate': 6.822069724949209e-07, 'epoch': 3.54}
 89%|████████▊ | 1675/1892 [3:56:15<3:17:51, 54.71s/it] 89%|████████▊ | 1676/1892 [3:57:10<3:16:56, 54.71s/it]                                                       {'loss': 0.2225, 'learning_rate': 6.760054951383288e-07, 'epoch': 3.54}
 89%|████████▊ | 1676/1892 [3:57:10<3:16:56, 54.71s/it] 89%|████████▊ | 1677/1892 [3:58:05<3:16:04, 54.72s/it]                                                       {'loss': 0.2165, 'learning_rate': 6.698313471448547e-07, 'epoch': 3.54}
 89%|████████▊ | 1677/1892 [3:58:05<3:16:04, 54.72s/it] 89%|████████▊ | 1678/1892 [3:58:59<3:15:17, 54.75s/it]                                                       {'loss': 0.2131, 'learning_rate': 6.63684546611414e-07, 'epoch': 3.55}
 89%|████████▊ | 1678/1892 [3:58:59<3:15:17, 54.75s/it] 89%|████████▊ | 1679/1892 [3:59:54<3:14:23, 54.76s/it]                                                       {'loss': 0.207, 'learning_rate': 6.575651115547632e-07, 'epoch': 3.55}
 89%|████████▊ | 1679/1892 [3:59:54<3:14:23, 54.76s/it] 89%|████████▉ | 1680/1892 [4:00:49<3:13:27, 54.75s/it]                                                       {'loss': 0.1967, 'learning_rate': 6.51473059911446e-07, 'epoch': 3.55}
 89%|████████▉ | 1680/1892 [4:00:49<3:13:27, 54.75s/it] 89%|████████▉ | 1681/1892 [4:01:44<3:12:33, 54.76s/it]                                                       {'loss': 0.2098, 'learning_rate': 6.454084095377478e-07, 'epoch': 3.55}
 89%|████████▉ | 1681/1892 [4:01:44<3:12:33, 54.76s/it] 89%|████████▉ | 1682/1892 [4:02:38<3:11:38, 54.75s/it]                                                       {'loss': 0.2076, 'learning_rate': 6.39371178209639e-07, 'epoch': 3.56}
 89%|████████▉ | 1682/1892 [4:02:38<3:11:38, 54.75s/it] 89%|████████▉ | 1683/1892 [4:03:33<3:10:47, 54.78s/it]                                                       {'loss': 0.2191, 'learning_rate': 6.333613836227181e-07, 'epoch': 3.56}
 89%|████████▉ | 1683/1892 [4:03:33<3:10:47, 54.78s/it] 89%|████████▉ | 1684/1892 [4:04:28<3:09:56, 54.79s/it]                                                       {'loss': 0.2061, 'learning_rate': 6.273790433921712e-07, 'epoch': 3.56}
 89%|████████▉ | 1684/1892 [4:04:28<3:09:56, 54.79s/it] 89%|████████▉ | 1685/1892 [4:05:23<3:09:08, 54.82s/it]                                                       {'loss': 0.2017, 'learning_rate': 6.214241750527039e-07, 'epoch': 3.56}
 89%|████████▉ | 1685/1892 [4:05:23<3:09:08, 54.82s/it] 89%|████████▉ | 1686/1892 [4:06:18<3:08:20, 54.86s/it]                                                       {'loss': 0.2154, 'learning_rate': 6.154967960585068e-07, 'epoch': 3.56}
 89%|████████▉ | 1686/1892 [4:06:18<3:08:20, 54.86s/it] 89%|████████▉ | 1687/1892 [4:07:13<3:07:17, 54.82s/it]                                                       {'loss': 0.2089, 'learning_rate': 6.095969237831956e-07, 'epoch': 3.57}
 89%|████████▉ | 1687/1892 [4:07:13<3:07:17, 54.82s/it] 89%|████████▉ | 1688/1892 [4:08:07<3:06:15, 54.78s/it]                                                       {'loss': 0.2104, 'learning_rate': 6.03724575519763e-07, 'epoch': 3.57}
 89%|████████▉ | 1688/1892 [4:08:07<3:06:15, 54.78s/it] 89%|████████▉ | 1689/1892 [4:09:02<3:05:17, 54.77s/it]                                                       {'loss': 0.2256, 'learning_rate': 5.978797684805216e-07, 'epoch': 3.57}
 89%|████████▉ | 1689/1892 [4:09:02<3:05:17, 54.77s/it] 89%|████████▉ | 1690/1892 [4:09:57<3:04:23, 54.77s/it]                                                       {'loss': 0.1957, 'learning_rate': 5.920625197970631e-07, 'epoch': 3.57}
 89%|████████▉ | 1690/1892 [4:09:57<3:04:23, 54.77s/it] 89%|████████▉ | 1691/1892 [4:10:52<3:03:28, 54.77s/it]                                                       {'loss': 0.2138, 'learning_rate': 5.862728465202017e-07, 'epoch': 3.57}
 89%|████████▉ | 1691/1892 [4:10:52<3:03:28, 54.77s/it] 89%|████████▉ | 1692/1892 [4:11:46<3:02:30, 54.75s/it]                                                       {'loss': 0.2221, 'learning_rate': 5.805107656199272e-07, 'epoch': 3.58}
 89%|████████▉ | 1692/1892 [4:11:46<3:02:30, 54.75s/it] 89%|████████▉ | 1693/1892 [4:12:41<3:01:42, 54.79s/it]                                                       {'loss': 0.2107, 'learning_rate': 5.747762939853518e-07, 'epoch': 3.58}
 89%|████████▉ | 1693/1892 [4:12:41<3:01:42, 54.79s/it] 90%|████████▉ | 1694/1892 [4:13:36<3:00:46, 54.78s/it]                                                       {'loss': 0.2325, 'learning_rate': 5.690694484246661e-07, 'epoch': 3.58}
 90%|████████▉ | 1694/1892 [4:13:36<3:00:46, 54.78s/it] 90%|████████▉ | 1695/1892 [4:14:31<2:59:52, 54.79s/it]                                                       {'loss': 0.2208, 'learning_rate': 5.63390245665082e-07, 'epoch': 3.58}
 90%|████████▉ | 1695/1892 [4:14:31<2:59:52, 54.79s/it] 90%|████████▉ | 1696/1892 [4:15:25<2:58:55, 54.77s/it]                                                       {'loss': 0.1863, 'learning_rate': 5.577387023527914e-07, 'epoch': 3.59}
 90%|████████▉ | 1696/1892 [4:15:25<2:58:55, 54.77s/it] 90%|████████▉ | 1697/1892 [4:16:20<2:57:59, 54.77s/it]                                                       {'loss': 0.2526, 'learning_rate': 5.521148350529137e-07, 'epoch': 3.59}
 90%|████████▉ | 1697/1892 [4:16:20<2:57:59, 54.77s/it] 90%|████████▉ | 1698/1892 [4:17:15<2:57:05, 54.77s/it]                                                       {'loss': 0.2123, 'learning_rate': 5.465186602494488e-07, 'epoch': 3.59}
 90%|████████▉ | 1698/1892 [4:17:15<2:57:05, 54.77s/it] 90%|████████▉ | 1699/1892 [4:18:10<2:56:08, 54.76s/it]                                                       {'loss': 0.235, 'learning_rate': 5.409501943452234e-07, 'epoch': 3.59}
 90%|████████▉ | 1699/1892 [4:18:10<2:56:08, 54.76s/it] 90%|████████▉ | 1700/1892 [4:19:05<2:55:16, 54.77s/it]                                                       {'loss': 0.2177, 'learning_rate': 5.354094536618515e-07, 'epoch': 3.59}
 90%|████████▉ | 1700/1892 [4:19:05<2:55:16, 54.77s/it] 90%|████████▉ | 1701/1892 [4:19:59<2:54:18, 54.76s/it]                                                       {'loss': 0.2162, 'learning_rate': 5.298964544396812e-07, 'epoch': 3.6}
 90%|████████▉ | 1701/1892 [4:19:59<2:54:18, 54.76s/it] 90%|████████▉ | 1702/1892 [4:20:54<2:53:23, 54.75s/it]                                                       {'loss': 0.222, 'learning_rate': 5.244112128377477e-07, 'epoch': 3.6}
 90%|████████▉ | 1702/1892 [4:20:54<2:53:23, 54.75s/it] 90%|█████████ | 1703/1892 [4:21:49<2:52:33, 54.78s/it]                                                       {'loss': 0.2095, 'learning_rate': 5.189537449337289e-07, 'epoch': 3.6}
 90%|█████████ | 1703/1892 [4:21:49<2:52:33, 54.78s/it] 90%|█████████ | 1704/1892 [4:22:44<2:51:49, 54.84s/it]                                                       {'loss': 0.2077, 'learning_rate': 5.135240667238895e-07, 'epoch': 3.6}
 90%|█████████ | 1704/1892 [4:22:44<2:51:49, 54.84s/it] 90%|█████████ | 1705/1892 [4:23:39<2:51:02, 54.88s/it]                                                       {'loss': 0.21, 'learning_rate': 5.081221941230463e-07, 'epoch': 3.6}
 90%|█████████ | 1705/1892 [4:23:39<2:51:02, 54.88s/it] 90%|█████████ | 1706/1892 [4:24:34<2:50:01, 54.85s/it]                                                       {'loss': 0.2333, 'learning_rate': 5.027481429645154e-07, 'epoch': 3.61}
 90%|█████████ | 1706/1892 [4:24:34<2:50:01, 54.85s/it] 90%|█████████ | 1707/1892 [4:25:28<2:49:06, 54.85s/it]                                                       {'loss': 0.194, 'learning_rate': 4.97401929000062e-07, 'epoch': 3.61}
 90%|█████████ | 1707/1892 [4:25:28<2:49:06, 54.85s/it] 90%|█████████ | 1708/1892 [4:26:23<2:48:13, 54.86s/it]                                                       {'loss': 0.2139, 'learning_rate': 4.920835678998625e-07, 'epoch': 3.61}
 90%|█████████ | 1708/1892 [4:26:23<2:48:13, 54.86s/it] 90%|█████████ | 1709/1892 [4:27:18<2:47:16, 54.85s/it]                                                       {'loss': 0.2123, 'learning_rate': 4.867930752524519e-07, 'epoch': 3.61}
 90%|█████████ | 1709/1892 [4:27:18<2:47:16, 54.85s/it] 90%|█████████ | 1710/1892 [4:28:13<2:46:23, 54.85s/it]                                                       {'loss': 0.2328, 'learning_rate': 4.815304665646803e-07, 'epoch': 3.61}
 90%|█████████ | 1710/1892 [4:28:13<2:46:23, 54.85s/it] 90%|█████████ | 1711/1892 [4:29:08<2:45:23, 54.83s/it]                                                       {'loss': 0.2316, 'learning_rate': 4.762957572616711e-07, 'epoch': 3.62}
 90%|█████████ | 1711/1892 [4:29:08<2:45:23, 54.83s/it] 90%|█████████ | 1712/1892 [4:30:02<2:44:23, 54.80s/it]                                                       {'loss': 0.2073, 'learning_rate': 4.710889626867687e-07, 'epoch': 3.62}
 90%|█████████ | 1712/1892 [4:30:02<2:44:23, 54.80s/it] 91%|█████████ | 1713/1892 [4:30:57<2:43:22, 54.76s/it]                                                       {'loss': 0.2125, 'learning_rate': 4.659100981014986e-07, 'epoch': 3.62}
 91%|█████████ | 1713/1892 [4:30:57<2:43:22, 54.76s/it] 91%|█████████ | 1714/1892 [4:31:52<2:42:27, 54.76s/it]                                                       {'loss': 0.2158, 'learning_rate': 4.607591786855203e-07, 'epoch': 3.62}
 91%|█████████ | 1714/1892 [4:31:52<2:42:27, 54.76s/it] 91%|█████████ | 1715/1892 [4:32:47<2:41:27, 54.73s/it]                                                       {'loss': 0.2153, 'learning_rate': 4.556362195365871e-07, 'epoch': 3.63}
 91%|█████████ | 1715/1892 [4:32:47<2:41:27, 54.73s/it] 91%|█████████ | 1716/1892 [4:33:41<2:40:33, 54.73s/it]                                                       {'loss': 0.2062, 'learning_rate': 4.505412356704941e-07, 'epoch': 3.63}
 91%|█████████ | 1716/1892 [4:33:41<2:40:33, 54.73s/it] 91%|█████████ | 1717/1892 [4:34:36<2:39:36, 54.72s/it]                                                       {'loss': 0.192, 'learning_rate': 4.454742420210434e-07, 'epoch': 3.63}
 91%|█████████ | 1717/1892 [4:34:36<2:39:36, 54.72s/it] 91%|█████████ | 1718/1892 [4:35:31<2:38:45, 54.74s/it]                                                       {'loss': 0.2162, 'learning_rate': 4.404352534399892e-07, 'epoch': 3.63}
 91%|█████████ | 1718/1892 [4:35:31<2:38:45, 54.74s/it] 91%|█████████ | 1719/1892 [4:36:26<2:37:52, 54.75s/it]                                                       {'loss': 0.2064, 'learning_rate': 4.3542428469700694e-07, 'epoch': 3.63}
 91%|█████████ | 1719/1892 [4:36:26<2:37:52, 54.75s/it] 91%|█████████ | 1720/1892 [4:37:20<2:36:57, 54.75s/it]                                                       {'loss': 0.2119, 'learning_rate': 4.304413504796412e-07, 'epoch': 3.64}
 91%|█████████ | 1720/1892 [4:37:20<2:36:57, 54.75s/it] 91%|█████████ | 1721/1892 [4:38:15<2:36:04, 54.76s/it]                                                       {'loss': 0.2053, 'learning_rate': 4.2548646539326334e-07, 'epoch': 3.64}
 91%|█████████ | 1721/1892 [4:38:15<2:36:04, 54.76s/it] 91%|█████████ | 1722/1892 [4:39:10<2:35:10, 54.77s/it]                                                       {'loss': 0.2314, 'learning_rate': 4.205596439610349e-07, 'epoch': 3.64}
 91%|█████████ | 1722/1892 [4:39:10<2:35:10, 54.77s/it] 91%|█████████ | 1723/1892 [4:40:05<2:34:15, 54.77s/it]                                                       {'loss': 0.2234, 'learning_rate': 4.156609006238554e-07, 'epoch': 3.64}
 91%|█████████ | 1723/1892 [4:40:05<2:34:15, 54.77s/it] 91%|█████████ | 1724/1892 [4:41:00<2:33:27, 54.80s/it]                                                       {'loss': 0.1934, 'learning_rate': 4.1079024974032823e-07, 'epoch': 3.64}
 91%|█████████ | 1724/1892 [4:41:00<2:33:27, 54.80s/it] 91%|█████████ | 1725/1892 [4:41:54<2:32:32, 54.80s/it]                                                       {'loss': 0.1977, 'learning_rate': 4.059477055867167e-07, 'epoch': 3.65}
 91%|█████████ | 1725/1892 [4:41:54<2:32:32, 54.80s/it] 91%|█████████ | 1726/1892 [4:42:49<2:31:34, 54.78s/it]                                                       {'loss': 0.2075, 'learning_rate': 4.0113328235689806e-07, 'epoch': 3.65}
 91%|█████████ | 1726/1892 [4:42:49<2:31:34, 54.78s/it] 91%|█████████▏| 1727/1892 [4:43:44<2:30:39, 54.79s/it]                                                       {'loss': 0.2112, 'learning_rate': 3.963469941623288e-07, 'epoch': 3.65}
 91%|█████████▏| 1727/1892 [4:43:44<2:30:39, 54.79s/it] 91%|█████████▏| 1728/1892 [4:44:39<2:29:44, 54.78s/it]                                                       {'loss': 0.2245, 'learning_rate': 3.915888550319935e-07, 'epoch': 3.65}
 91%|█████████▏| 1728/1892 [4:44:39<2:29:44, 54.78s/it] 91%|█████████▏| 1729/1892 [4:45:33<2:28:43, 54.75s/it]                                                       {'loss': 0.1967, 'learning_rate': 3.8685887891237505e-07, 'epoch': 3.65}
 91%|█████████▏| 1729/1892 [4:45:33<2:28:43, 54.75s/it] 91%|█████████▏| 1730/1892 [4:46:28<2:27:52, 54.77s/it]                                                       {'loss': 0.2209, 'learning_rate': 3.8215707966740677e-07, 'epoch': 3.66}
 91%|█████████▏| 1730/1892 [4:46:28<2:27:52, 54.77s/it] 91%|█████████▏| 1731/1892 [4:47:23<2:26:59, 54.78s/it]                                                       {'loss': 0.1981, 'learning_rate': 3.774834710784325e-07, 'epoch': 3.66}
 91%|█████████▏| 1731/1892 [4:47:23<2:26:59, 54.78s/it] 92%|█████████▏| 1732/1892 [4:48:18<2:26:04, 54.78s/it]                                                       {'loss': 0.211, 'learning_rate': 3.7283806684416777e-07, 'epoch': 3.66}
 92%|█████████▏| 1732/1892 [4:48:18<2:26:04, 54.78s/it] 92%|█████████▏| 1733/1892 [4:49:12<2:25:09, 54.78s/it]                                                       {'loss': 0.1871, 'learning_rate': 3.682208805806575e-07, 'epoch': 3.66}
 92%|█████████▏| 1733/1892 [4:49:12<2:25:09, 54.78s/it] 92%|█████████▏| 1734/1892 [4:50:07<2:24:16, 54.79s/it]                                                       {'loss': 0.2059, 'learning_rate': 3.636319258212417e-07, 'epoch': 3.67}
 92%|█████████▏| 1734/1892 [4:50:07<2:24:16, 54.79s/it] 92%|█████████▏| 1735/1892 [4:51:02<2:23:19, 54.77s/it]                                                       {'loss': 0.2043, 'learning_rate': 3.590712160165055e-07, 'epoch': 3.67}
 92%|█████████▏| 1735/1892 [4:51:02<2:23:19, 54.77s/it] 92%|█████████▏| 1736/1892 [4:51:57<2:22:24, 54.77s/it]                                                       {'loss': 0.2082, 'learning_rate': 3.5453876453425016e-07, 'epoch': 3.67}
 92%|█████████▏| 1736/1892 [4:51:57<2:22:24, 54.77s/it] 92%|█████████▏| 1737/1892 [4:52:51<2:21:23, 54.73s/it]                                                       {'loss': 0.2049, 'learning_rate': 3.5003458465944884e-07, 'epoch': 3.67}
 92%|█████████▏| 1737/1892 [4:52:51<2:21:23, 54.73s/it] 92%|█████████▏| 1738/1892 [4:53:46<2:20:32, 54.76s/it]                                                       {'loss': 0.1961, 'learning_rate': 3.4555868959420646e-07, 'epoch': 3.67}
 92%|█████████▏| 1738/1892 [4:53:46<2:20:32, 54.76s/it] 92%|█████████▏| 1739/1892 [4:54:41<2:19:41, 54.78s/it]                                                       {'loss': 0.1927, 'learning_rate': 3.4111109245772544e-07, 'epoch': 3.68}
 92%|█████████▏| 1739/1892 [4:54:41<2:19:41, 54.78s/it] 92%|█████████▏| 1740/1892 [4:55:36<2:18:45, 54.77s/it]                                                       {'loss': 0.2323, 'learning_rate': 3.3669180628626343e-07, 'epoch': 3.68}
 92%|█████████▏| 1740/1892 [4:55:36<2:18:45, 54.77s/it] 92%|█████████▏| 1741/1892 [4:56:31<2:17:55, 54.81s/it]                                                       {'loss': 0.2188, 'learning_rate': 3.323008440330988e-07, 'epoch': 3.68}
 92%|█████████▏| 1741/1892 [4:56:31<2:17:55, 54.81s/it] 92%|█████████▏| 1742/1892 [4:57:25<2:16:54, 54.76s/it]                                                       {'loss': 0.21, 'learning_rate': 3.279382185684843e-07, 'epoch': 3.68}
 92%|█████████▏| 1742/1892 [4:57:25<2:16:54, 54.76s/it] 92%|█████████▏| 1743/1892 [4:58:20<2:16:03, 54.79s/it]                                                       {'loss': 0.2364, 'learning_rate': 3.2360394267962114e-07, 'epoch': 3.68}
 92%|█████████▏| 1743/1892 [4:58:20<2:16:03, 54.79s/it] 92%|█████████▏| 1744/1892 [4:59:15<2:15:07, 54.78s/it]                                                       {'loss': 0.2036, 'learning_rate': 3.192980290706138e-07, 'epoch': 3.69}
 92%|█████████▏| 1744/1892 [4:59:15<2:15:07, 54.78s/it] 92%|█████████▏| 1745/1892 [5:00:10<2:14:08, 54.75s/it]                                                       {'loss': 0.2199, 'learning_rate': 3.1502049036243434e-07, 'epoch': 3.69}
 92%|█████████▏| 1745/1892 [5:00:10<2:14:08, 54.75s/it] 92%|█████████▏| 1746/1892 [5:01:04<2:13:13, 54.75s/it]                                                       {'loss': 0.2159, 'learning_rate': 3.107713390928868e-07, 'epoch': 3.69}
 92%|█████████▏| 1746/1892 [5:01:04<2:13:13, 54.75s/it] 92%|█████████▏| 1747/1892 [5:01:59<2:12:21, 54.77s/it]                                                       {'loss': 0.2249, 'learning_rate': 3.0655058771656755e-07, 'epoch': 3.69}
 92%|█████████▏| 1747/1892 [5:01:59<2:12:21, 54.77s/it] 92%|█████████▏| 1748/1892 [5:02:54<2:11:24, 54.76s/it]                                                       {'loss': 0.2003, 'learning_rate': 3.023582486048326e-07, 'epoch': 3.69}
 92%|█████████▏| 1748/1892 [5:02:54<2:11:24, 54.76s/it] 92%|█████████▏| 1749/1892 [5:03:49<2:10:26, 54.73s/it]                                                       {'loss': 0.1944, 'learning_rate': 2.9819433404575714e-07, 'epoch': 3.7}
 92%|█████████▏| 1749/1892 [5:03:49<2:10:26, 54.73s/it] 92%|█████████▏| 1750/1892 [5:04:43<2:09:31, 54.73s/it]                                                       {'loss': 0.2371, 'learning_rate': 2.940588562441038e-07, 'epoch': 3.7}
 92%|█████████▏| 1750/1892 [5:04:43<2:09:31, 54.73s/it] 93%|█████████▎| 1751/1892 [5:05:38<2:08:36, 54.73s/it]                                                       {'loss': 0.2015, 'learning_rate': 2.8995182732128535e-07, 'epoch': 3.7}
 93%|█████████▎| 1751/1892 [5:05:38<2:08:36, 54.73s/it] 93%|█████████▎| 1752/1892 [5:06:33<2:07:43, 54.74s/it]                                                       {'loss': 0.2442, 'learning_rate': 2.858732593153246e-07, 'epoch': 3.7}
 93%|█████████▎| 1752/1892 [5:06:33<2:07:43, 54.74s/it] 93%|█████████▎| 1753/1892 [5:07:28<2:06:48, 54.74s/it]                                                       {'loss': 0.2191, 'learning_rate': 2.818231641808278e-07, 'epoch': 3.71}
 93%|█████████▎| 1753/1892 [5:07:28<2:06:48, 54.74s/it] 93%|█████████▎| 1754/1892 [5:08:22<2:05:49, 54.71s/it]                                                       {'loss': 0.2143, 'learning_rate': 2.7780155378894336e-07, 'epoch': 3.71}
 93%|█████████▎| 1754/1892 [5:08:22<2:05:49, 54.71s/it] 93%|█████████▎| 1755/1892 [5:09:17<2:05:00, 54.75s/it]                                                       {'loss': 0.1983, 'learning_rate': 2.7380843992732774e-07, 'epoch': 3.71}
 93%|█████████▎| 1755/1892 [5:09:17<2:05:00, 54.75s/it] 93%|█████████▎| 1756/1892 [5:10:12<2:04:07, 54.76s/it]                                                       {'loss': 0.1843, 'learning_rate': 2.6984383430011417e-07, 'epoch': 3.71}
 93%|█████████▎| 1756/1892 [5:10:12<2:04:07, 54.76s/it] 93%|█████████▎| 1757/1892 [5:11:07<2:03:09, 54.74s/it]                                                       {'loss': 0.2087, 'learning_rate': 2.659077485278716e-07, 'epoch': 3.71}
 93%|█████████▎| 1757/1892 [5:11:07<2:03:09, 54.74s/it] 93%|█████████▎| 1758/1892 [5:12:01<2:02:14, 54.74s/it]                                                       {'loss': 0.1904, 'learning_rate': 2.6200019414758025e-07, 'epoch': 3.72}
 93%|█████████▎| 1758/1892 [5:12:01<2:02:14, 54.74s/it] 93%|█████████▎| 1759/1892 [5:12:56<2:01:21, 54.75s/it]                                                       {'loss': 0.2031, 'learning_rate': 2.5812118261258845e-07, 'epoch': 3.72}
 93%|█████████▎| 1759/1892 [5:12:56<2:01:21, 54.75s/it] 93%|█████████▎| 1760/1892 [5:13:51<2:00:28, 54.76s/it]                                                       {'loss': 0.2218, 'learning_rate': 2.542707252925869e-07, 'epoch': 3.72}
 93%|█████████▎| 1760/1892 [5:13:51<2:00:28, 54.76s/it] 93%|█████████▎| 1761/1892 [5:14:46<1:59:30, 54.73s/it]                                                       {'loss': 0.2072, 'learning_rate': 2.5044883347356773e-07, 'epoch': 3.72}
 93%|█████████▎| 1761/1892 [5:14:46<1:59:30, 54.73s/it] 93%|█████████▎| 1762/1892 [5:15:40<1:58:32, 54.71s/it]                                                       {'loss': 0.1896, 'learning_rate': 2.466555183577968e-07, 'epoch': 3.72}
 93%|█████████▎| 1762/1892 [5:15:40<1:58:32, 54.71s/it] 93%|█████████▎| 1763/1892 [5:16:35<1:57:38, 54.72s/it]                                                       {'loss': 0.199, 'learning_rate': 2.428907910637812e-07, 'epoch': 3.73}
 93%|█████████▎| 1763/1892 [5:16:35<1:57:38, 54.72s/it] 93%|█████████▎| 1764/1892 [5:17:30<1:56:42, 54.70s/it]                                                       {'loss': 0.2081, 'learning_rate': 2.391546626262331e-07, 'epoch': 3.73}
 93%|█████████▎| 1764/1892 [5:17:30<1:56:42, 54.70s/it] 93%|█████████▎| 1765/1892 [5:18:24<1:55:47, 54.70s/it]                                                       {'loss': 0.193, 'learning_rate': 2.354471439960404e-07, 'epoch': 3.73}
 93%|█████████▎| 1765/1892 [5:18:24<1:55:47, 54.70s/it] 93%|█████████▎| 1766/1892 [5:19:19<1:54:52, 54.70s/it]                                                       {'loss': 0.2041, 'learning_rate': 2.317682460402304e-07, 'epoch': 3.73}
 93%|█████████▎| 1766/1892 [5:19:19<1:54:52, 54.70s/it] 93%|█████████▎| 1767/1892 [5:20:14<1:54:00, 54.72s/it]                                                       {'loss': 0.2157, 'learning_rate': 2.2811797954194527e-07, 'epoch': 3.73}
 93%|█████████▎| 1767/1892 [5:20:14<1:54:00, 54.72s/it] 93%|█████████▎| 1768/1892 [5:21:09<1:53:08, 54.75s/it]                                                       {'loss': 0.2136, 'learning_rate': 2.2449635520040314e-07, 'epoch': 3.74}
 93%|█████████▎| 1768/1892 [5:21:09<1:53:08, 54.75s/it] 93%|█████████▎| 1769/1892 [5:22:03<1:52:15, 54.76s/it]                                                       {'loss': 0.2228, 'learning_rate': 2.209033836308694e-07, 'epoch': 3.74}
 93%|█████████▎| 1769/1892 [5:22:03<1:52:15, 54.76s/it] 94%|█████████▎| 1770/1892 [5:22:58<1:51:21, 54.77s/it]                                                       {'loss': 0.2128, 'learning_rate': 2.1733907536462984e-07, 'epoch': 3.74}
 94%|█████████▎| 1770/1892 [5:22:58<1:51:21, 54.77s/it] 94%|█████████▎| 1771/1892 [5:23:53<1:50:26, 54.76s/it]                                                       {'loss': 0.198, 'learning_rate': 2.1380344084894976e-07, 'epoch': 3.74}
 94%|█████████▎| 1771/1892 [5:23:53<1:50:26, 54.76s/it] 94%|█████████▎| 1772/1892 [5:24:48<1:49:30, 54.76s/it]                                                       {'loss': 0.2182, 'learning_rate': 2.10296490447055e-07, 'epoch': 3.75}
 94%|█████████▎| 1772/1892 [5:24:48<1:49:30, 54.76s/it] 94%|█████████▎| 1773/1892 [5:25:43<1:48:42, 54.81s/it]                                                       {'loss': 0.2175, 'learning_rate': 2.068182344380931e-07, 'epoch': 3.75}
 94%|█████████▎| 1773/1892 [5:25:43<1:48:42, 54.81s/it] 94%|█████████▍| 1774/1892 [5:26:37<1:47:44, 54.79s/it]                                                       {'loss': 0.2201, 'learning_rate': 2.0336868301710667e-07, 'epoch': 3.75}
 94%|█████████▍| 1774/1892 [5:26:37<1:47:44, 54.79s/it] 94%|█████████▍| 1775/1892 [5:27:32<1:46:50, 54.79s/it]                                                       {'loss': 0.2102, 'learning_rate': 1.999478462950033e-07, 'epoch': 3.75}
 94%|█████████▍| 1775/1892 [5:27:32<1:46:50, 54.79s/it] 94%|█████████▍| 1776/1892 [5:28:27<1:45:54, 54.78s/it]                                                       {'loss': 0.2042, 'learning_rate': 1.965557342985247e-07, 'epoch': 3.75}
 94%|█████████▍| 1776/1892 [5:28:27<1:45:54, 54.78s/it] 94%|█████████▍| 1777/1892 [5:29:22<1:45:01, 54.79s/it]                                                       {'loss': 0.1953, 'learning_rate': 1.9319235697021766e-07, 'epoch': 3.76}
 94%|█████████▍| 1777/1892 [5:29:22<1:45:01, 54.79s/it] 94%|█████████▍| 1778/1892 [5:30:16<1:44:02, 54.76s/it]                                                       {'loss': 0.2113, 'learning_rate': 1.8985772416840742e-07, 'epoch': 3.76}
 94%|█████████▍| 1778/1892 [5:30:16<1:44:02, 54.76s/it] 94%|█████████▍| 1779/1892 [5:31:11<1:43:04, 54.73s/it]                                                       {'loss': 0.2115, 'learning_rate': 1.8655184566716556e-07, 'epoch': 3.76}
 94%|█████████▍| 1779/1892 [5:31:11<1:43:04, 54.73s/it] 94%|█████████▍| 1780/1892 [5:32:06<1:42:11, 54.74s/it]                                                       {'loss': 0.212, 'learning_rate': 1.8327473115628325e-07, 'epoch': 3.76}
 94%|█████████▍| 1780/1892 [5:32:06<1:42:11, 54.74s/it] 94%|█████████▍| 1781/1892 [5:33:00<1:41:15, 54.74s/it]                                                       {'loss': 0.2279, 'learning_rate': 1.8002639024124024e-07, 'epoch': 3.76}
 94%|█████████▍| 1781/1892 [5:33:00<1:41:15, 54.74s/it] 94%|█████████▍| 1782/1892 [5:33:55<1:40:24, 54.76s/it]                                                       {'loss': 0.22, 'learning_rate': 1.7680683244318154e-07, 'epoch': 3.77}
 94%|█████████▍| 1782/1892 [5:33:55<1:40:24, 54.76s/it] 94%|█████████▍| 1783/1892 [5:34:50<1:39:27, 54.75s/it]                                                       {'loss': 0.207, 'learning_rate': 1.736160671988829e-07, 'epoch': 3.77}
 94%|█████████▍| 1783/1892 [5:34:50<1:39:27, 54.75s/it] 94%|█████████▍| 1784/1892 [5:35:45<1:38:29, 54.72s/it]                                                       {'loss': 0.234, 'learning_rate': 1.7045410386073103e-07, 'epoch': 3.77}
 94%|█████████▍| 1784/1892 [5:35:45<1:38:29, 54.72s/it] 94%|█████████▍| 1785/1892 [5:36:39<1:37:32, 54.70s/it]                                                       {'loss': 0.2089, 'learning_rate': 1.6732095169668783e-07, 'epoch': 3.77}
 94%|█████████▍| 1785/1892 [5:36:39<1:37:32, 54.70s/it] 94%|█████████▍| 1786/1892 [5:37:34<1:36:35, 54.67s/it]                                                       {'loss': 0.2003, 'learning_rate': 1.642166198902706e-07, 'epoch': 3.78}
 94%|█████████▍| 1786/1892 [5:37:34<1:36:35, 54.67s/it] 94%|█████████▍| 1787/1892 [5:38:29<1:35:41, 54.68s/it]                                                       {'loss': 0.2274, 'learning_rate': 1.6114111754051976e-07, 'epoch': 3.78}
 94%|█████████▍| 1787/1892 [5:38:29<1:35:41, 54.68s/it] 95%|█████████▍| 1788/1892 [5:39:23<1:34:47, 54.69s/it]                                                       {'loss': 0.2268, 'learning_rate': 1.580944536619755e-07, 'epoch': 3.78}
 95%|█████████▍| 1788/1892 [5:39:23<1:34:47, 54.69s/it] 95%|█████████▍| 1789/1892 [5:40:18<1:33:51, 54.67s/it]                                                       {'loss': 0.2038, 'learning_rate': 1.5507663718465237e-07, 'epoch': 3.78}
 95%|█████████▍| 1789/1892 [5:40:18<1:33:51, 54.67s/it] 95%|█████████▍| 1790/1892 [5:41:13<1:33:01, 54.72s/it]                                                       {'loss': 0.1958, 'learning_rate': 1.5208767695400473e-07, 'epoch': 3.78}
 95%|█████████▍| 1790/1892 [5:41:13<1:33:01, 54.72s/it] 95%|█████████▍| 1791/1892 [5:42:07<1:32:04, 54.69s/it]                                                       {'loss': 0.2191, 'learning_rate': 1.4912758173091124e-07, 'epoch': 3.79}
 95%|█████████▍| 1791/1892 [5:42:07<1:32:04, 54.69s/it] 95%|█████████▍| 1792/1892 [5:43:02<1:31:11, 54.71s/it]                                                       {'loss': 0.2219, 'learning_rate': 1.4619636019164608e-07, 'epoch': 3.79}
 95%|█████████▍| 1792/1892 [5:43:02<1:31:11, 54.71s/it] 95%|█████████▍| 1793/1892 [5:43:57<1:30:15, 54.70s/it]                                                       {'loss': 0.2197, 'learning_rate': 1.4329402092784995e-07, 'epoch': 3.79}
 95%|█████████▍| 1793/1892 [5:43:57<1:30:15, 54.70s/it] 95%|█████████▍| 1794/1892 [5:44:52<1:29:21, 54.71s/it]                                                       {'loss': 0.2124, 'learning_rate': 1.404205724465091e-07, 'epoch': 3.79}
 95%|█████████▍| 1794/1892 [5:44:52<1:29:21, 54.71s/it] 95%|█████████▍| 1795/1892 [5:45:46<1:28:25, 54.70s/it]                                                       {'loss': 0.2092, 'learning_rate': 1.3757602316992526e-07, 'epoch': 3.79}
 95%|█████████▍| 1795/1892 [5:45:46<1:28:25, 54.70s/it] 95%|█████████▍| 1796/1892 [5:46:41<1:27:30, 54.69s/it]                                                       {'loss': 0.2271, 'learning_rate': 1.3476038143569792e-07, 'epoch': 3.8}
 95%|█████████▍| 1796/1892 [5:46:41<1:27:30, 54.69s/it] 95%|█████████▍| 1797/1892 [5:47:36<1:26:36, 54.70s/it]                                                       {'loss': 0.1997, 'learning_rate': 1.319736554966955e-07, 'epoch': 3.8}
 95%|█████████▍| 1797/1892 [5:47:36<1:26:36, 54.70s/it] 95%|█████████▌| 1798/1892 [5:48:30<1:25:42, 54.71s/it]                                                       {'loss': 0.2287, 'learning_rate': 1.2921585352103083e-07, 'epoch': 3.8}
 95%|█████████▌| 1798/1892 [5:48:30<1:25:42, 54.71s/it] 95%|█████████▌| 1799/1892 [5:49:25<1:24:46, 54.69s/it]                                                       {'loss': 0.2098, 'learning_rate': 1.2648698359203903e-07, 'epoch': 3.8}
 95%|█████████▌| 1799/1892 [5:49:25<1:24:46, 54.69s/it] 95%|█████████▌| 1800/1892 [5:50:20<1:23:51, 54.69s/it]                                                       {'loss': 0.203, 'learning_rate': 1.2378705370825417e-07, 'epoch': 3.8}
 95%|█████████▌| 1800/1892 [5:50:20<1:23:51, 54.69s/it] 95%|█████████▌| 1801/1892 [5:51:14<1:22:57, 54.70s/it]                                                       {'loss': 0.2214, 'learning_rate': 1.2111607178338147e-07, 'epoch': 3.81}
 95%|█████████▌| 1801/1892 [5:51:14<1:22:57, 54.70s/it] 95%|█████████▌| 1802/1892 [5:52:09<1:22:04, 54.72s/it]                                                       {'loss': 0.221, 'learning_rate': 1.1847404564628185e-07, 'epoch': 3.81}
 95%|█████████▌| 1802/1892 [5:52:09<1:22:04, 54.72s/it] 95%|█████████▌| 1803/1892 [5:53:04<1:21:12, 54.75s/it]                                                       {'loss': 0.222, 'learning_rate': 1.1586098304094073e-07, 'epoch': 3.81}
 95%|█████████▌| 1803/1892 [5:53:04<1:21:12, 54.75s/it] 95%|█████████▌| 1804/1892 [5:53:59<1:20:16, 54.73s/it]                                                       {'loss': 0.2044, 'learning_rate': 1.132768916264515e-07, 'epoch': 3.81}
 95%|█████████▌| 1804/1892 [5:53:59<1:20:16, 54.73s/it] 95%|█████████▌| 1805/1892 [5:54:53<1:19:18, 54.69s/it]                                                       {'loss': 0.205, 'learning_rate': 1.1072177897698877e-07, 'epoch': 3.82}
 95%|█████████▌| 1805/1892 [5:54:53<1:19:18, 54.69s/it] 95%|█████████▌| 1806/1892 [5:55:48<1:18:24, 54.70s/it]                                                       {'loss': 0.19, 'learning_rate': 1.0819565258179066e-07, 'epoch': 3.82}
 95%|█████████▌| 1806/1892 [5:55:48<1:18:24, 54.70s/it] 96%|█████████▌| 1807/1892 [5:56:43<1:17:29, 54.70s/it]                                                       {'loss': 0.1925, 'learning_rate': 1.0569851984513102e-07, 'epoch': 3.82}
 96%|█████████▌| 1807/1892 [5:56:43<1:17:29, 54.70s/it] 96%|█████████▌| 1808/1892 [5:57:38<1:16:37, 54.74s/it]                                                       {'loss': 0.2397, 'learning_rate': 1.0323038808630392e-07, 'epoch': 3.82}
 96%|█████████▌| 1808/1892 [5:57:38<1:16:37, 54.74s/it] 96%|█████████▌| 1809/1892 [5:58:32<1:15:41, 54.71s/it]                                                       {'loss': 0.2412, 'learning_rate': 1.007912645395992e-07, 'epoch': 3.82}
 96%|█████████▌| 1809/1892 [5:58:32<1:15:41, 54.71s/it] 96%|█████████▌| 1810/1892 [5:59:27<1:14:46, 54.71s/it]                                                       {'loss': 0.203, 'learning_rate': 9.838115635427914e-08, 'epoch': 3.83}
 96%|█████████▌| 1810/1892 [5:59:27<1:14:46, 54.71s/it] 96%|█████████▌| 1811/1892 [6:00:22<1:13:48, 54.67s/it]                                                       {'loss': 0.198, 'learning_rate': 9.600007059455963e-08, 'epoch': 3.83}
 96%|█████████▌| 1811/1892 [6:00:22<1:13:48, 54.67s/it] 96%|█████████▌| 1812/1892 [6:01:16<1:12:53, 54.67s/it]                                                       {'loss': 0.2143, 'learning_rate': 9.364801423959235e-08, 'epoch': 3.83}
 96%|█████████▌| 1812/1892 [6:01:16<1:12:53, 54.67s/it] 96%|█████████▌| 1813/1892 [6:02:11<1:12:00, 54.69s/it]                                                       {'loss': 0.2014, 'learning_rate': 9.132499418344043e-08, 'epoch': 3.83}
 96%|█████████▌| 1813/1892 [6:02:11<1:12:00, 54.69s/it] 96%|█████████▌| 1814/1892 [6:03:06<1:11:05, 54.68s/it]                                                       {'loss': 0.2319, 'learning_rate': 8.903101723505836e-08, 'epoch': 3.83}
 96%|█████████▌| 1814/1892 [6:03:06<1:11:05, 54.68s/it] 96%|█████████▌| 1815/1892 [6:04:00<1:10:14, 54.73s/it]                                                       {'loss': 0.2073, 'learning_rate': 8.676609011827209e-08, 'epoch': 3.84}
 96%|█████████▌| 1815/1892 [6:04:00<1:10:14, 54.73s/it] 96%|█████████▌| 1816/1892 [6:04:55<1:09:16, 54.69s/it]                                                       {'loss': 0.2326, 'learning_rate': 8.453021947176343e-08, 'epoch': 3.84}
 96%|█████████▌| 1816/1892 [6:04:55<1:09:16, 54.69s/it] 96%|█████████▌| 1817/1892 [6:05:50<1:08:23, 54.72s/it]                                                       {'loss': 0.2084, 'learning_rate': 8.232341184904458e-08, 'epoch': 3.84}
 96%|█████████▌| 1817/1892 [6:05:50<1:08:23, 54.72s/it] 96%|█████████▌| 1818/1892 [6:06:44<1:07:26, 54.68s/it]                                                       {'loss': 0.21, 'learning_rate': 8.014567371844362e-08, 'epoch': 3.84}
 96%|█████████▌| 1818/1892 [6:06:44<1:07:26, 54.68s/it] 96%|█████████▌| 1819/1892 [6:07:39<1:06:28, 54.64s/it]                                                       {'loss': 0.2111, 'learning_rate': 7.799701146308015e-08, 'epoch': 3.84}
 96%|█████████▌| 1819/1892 [6:07:39<1:06:28, 54.64s/it] 96%|█████████▌| 1820/1892 [6:08:34<1:05:38, 54.71s/it]                                                       {'loss': 0.2279, 'learning_rate': 7.587743138085635e-08, 'epoch': 3.85}
 96%|█████████▌| 1820/1892 [6:08:34<1:05:38, 54.71s/it] 96%|█████████▌| 1821/1892 [6:09:29<1:04:43, 54.70s/it]                                                       {'loss': 0.2068, 'learning_rate': 7.378693968442596e-08, 'epoch': 3.85}
 96%|█████████▌| 1821/1892 [6:09:29<1:04:43, 54.70s/it] 96%|█████████▋| 1822/1892 [6:10:23<1:03:49, 54.70s/it]                                                       {'loss': 0.2161, 'learning_rate': 7.172554250118535e-08, 'epoch': 3.85}
 96%|█████████▋| 1822/1892 [6:10:23<1:03:49, 54.70s/it] 96%|█████████▋| 1823/1892 [6:11:18<1:02:53, 54.69s/it]                                                       {'loss': 0.2129, 'learning_rate': 6.969324587325354e-08, 'epoch': 3.85}
 96%|█████████▋| 1823/1892 [6:11:18<1:02:53, 54.69s/it] 96%|█████████▋| 1824/1892 [6:12:13<1:01:59, 54.69s/it]                                                       {'loss': 0.2511, 'learning_rate': 6.769005575745113e-08, 'epoch': 3.86}
 96%|█████████▋| 1824/1892 [6:12:13<1:01:59, 54.69s/it] 96%|█████████▋| 1825/1892 [6:13:07<1:01:02, 54.66s/it]                                                       {'loss': 0.1949, 'learning_rate': 6.571597802528584e-08, 'epoch': 3.86}
 96%|█████████▋| 1825/1892 [6:13:07<1:01:02, 54.66s/it] 97%|█████████▋| 1826/1892 [6:14:02<1:00:07, 54.66s/it]                                                       {'loss': 0.2144, 'learning_rate': 6.377101846293698e-08, 'epoch': 3.86}
 97%|█████████▋| 1826/1892 [6:14:02<1:00:07, 54.66s/it] 97%|█████████▋| 1827/1892 [6:14:56<59:12, 54.65s/it]                                                       {'loss': 0.1968, 'learning_rate': 6.185518277123215e-08, 'epoch': 3.86}
 97%|█████████▋| 1827/1892 [6:14:56<59:12, 54.65s/it] 97%|█████████▋| 1828/1892 [6:15:51<58:16, 54.63s/it]                                                     {'loss': 0.2127, 'learning_rate': 5.996847656563831e-08, 'epoch': 3.86}
 97%|█████████▋| 1828/1892 [6:15:51<58:16, 54.63s/it] 97%|█████████▋| 1829/1892 [6:16:46<57:20, 54.62s/it]                                                     {'loss': 0.2199, 'learning_rate': 5.8110905376239644e-08, 'epoch': 3.87}
 97%|█████████▋| 1829/1892 [6:16:46<57:20, 54.62s/it] 97%|█████████▋| 1830/1892 [6:17:40<56:28, 54.66s/it]                                                     {'loss': 0.2137, 'learning_rate': 5.628247464772418e-08, 'epoch': 3.87}
 97%|█████████▋| 1830/1892 [6:17:40<56:28, 54.66s/it] 97%|█████████▋| 1831/1892 [6:18:35<55:34, 54.66s/it]                                                     {'loss': 0.1908, 'learning_rate': 5.448318973936606e-08, 'epoch': 3.87}
 97%|█████████▋| 1831/1892 [6:18:35<55:34, 54.66s/it] 97%|█████████▋| 1832/1892 [6:19:30<54:38, 54.65s/it]                                                     {'loss': 0.2068, 'learning_rate': 5.271305592501108e-08, 'epoch': 3.87}
 97%|█████████▋| 1832/1892 [6:19:30<54:38, 54.65s/it] 97%|█████████▋| 1833/1892 [6:20:24<53:43, 54.64s/it]                                                     {'loss': 0.2058, 'learning_rate': 5.0972078393062284e-08, 'epoch': 3.87}
 97%|█████████▋| 1833/1892 [6:20:24<53:43, 54.64s/it] 97%|█████████▋| 1834/1892 [6:21:19<52:48, 54.62s/it]                                                     {'loss': 0.2279, 'learning_rate': 4.9260262246461074e-08, 'epoch': 3.88}
 97%|█████████▋| 1834/1892 [6:21:19<52:48, 54.62s/it] 97%|█████████▋| 1835/1892 [6:22:13<51:52, 54.60s/it]                                                     {'loss': 0.2145, 'learning_rate': 4.757761250267501e-08, 'epoch': 3.88}
 97%|█████████▋| 1835/1892 [6:22:13<51:52, 54.60s/it] 97%|█████████▋| 1836/1892 [6:23:08<50:59, 54.64s/it]                                                     {'loss': 0.1947, 'learning_rate': 4.592413409368335e-08, 'epoch': 3.88}
 97%|█████████▋| 1836/1892 [6:23:08<50:59, 54.64s/it] 97%|█████████▋| 1837/1892 [6:24:03<50:05, 54.64s/it]                                                     {'loss': 0.2025, 'learning_rate': 4.4299831865962653e-08, 'epoch': 3.88}
 97%|█████████▋| 1837/1892 [6:24:03<50:05, 54.64s/it] 97%|█████████▋| 1838/1892 [6:24:57<49:09, 54.61s/it]                                                     {'loss': 0.2112, 'learning_rate': 4.270471058047121e-08, 'epoch': 3.88}
 97%|█████████▋| 1838/1892 [6:24:57<49:09, 54.61s/it] 97%|█████████▋| 1839/1892 [6:25:52<48:15, 54.62s/it]                                                     {'loss': 0.2154, 'learning_rate': 4.1138774912633514e-08, 'epoch': 3.89}
 97%|█████████▋| 1839/1892 [6:25:52<48:15, 54.62s/it] 97%|█████████▋| 1840/1892 [6:26:47<47:19, 54.61s/it]                                                     {'loss': 0.2354, 'learning_rate': 3.960202945233138e-08, 'epoch': 3.89}
 97%|█████████▋| 1840/1892 [6:26:47<47:19, 54.61s/it] 97%|█████████▋| 1841/1892 [6:27:41<46:24, 54.59s/it]                                                     {'loss': 0.2394, 'learning_rate': 3.8094478703887275e-08, 'epoch': 3.89}
 97%|█████████▋| 1841/1892 [6:27:41<46:24, 54.59s/it] 97%|█████████▋| 1842/1892 [6:28:36<45:30, 54.61s/it]                                                     {'loss': 0.2125, 'learning_rate': 3.6616127086051e-08, 'epoch': 3.89}
 97%|█████████▋| 1842/1892 [6:28:36<45:30, 54.61s/it] 97%|█████████▋| 1843/1892 [6:29:30<44:36, 54.62s/it]                                                     {'loss': 0.2099, 'learning_rate': 3.5166978931987506e-08, 'epoch': 3.9}
 97%|█████████▋| 1843/1892 [6:29:30<44:36, 54.62s/it] 97%|█████████▋| 1844/1892 [6:30:25<43:41, 54.62s/it]                                                     {'loss': 0.2114, 'learning_rate': 3.3747038489264637e-08, 'epoch': 3.9}
 97%|█████████▋| 1844/1892 [6:30:25<43:41, 54.62s/it] 98%|█████████▊| 1845/1892 [6:31:20<42:48, 54.65s/it]                                                     {'loss': 0.2213, 'learning_rate': 3.2356309919838736e-08, 'epoch': 3.9}
 98%|█████████▊| 1845/1892 [6:31:20<42:48, 54.65s/it] 98%|█████████▊| 1846/1892 [6:32:14<41:53, 54.65s/it]                                                     {'loss': 0.2135, 'learning_rate': 3.099479730004684e-08, 'epoch': 3.9}
 98%|█████████▊| 1846/1892 [6:32:14<41:53, 54.65s/it] 98%|█████████▊| 1847/1892 [6:33:09<40:58, 54.64s/it]                                                     {'loss': 0.2035, 'learning_rate': 2.966250462058895e-08, 'epoch': 3.9}
 98%|█████████▊| 1847/1892 [6:33:09<40:58, 54.64s/it] 98%|█████████▊| 1848/1892 [6:34:04<40:06, 54.69s/it]                                                     {'loss': 0.2066, 'learning_rate': 2.835943578651912e-08, 'epoch': 3.91}
 98%|█████████▊| 1848/1892 [6:34:04<40:06, 54.69s/it] 98%|█████████▊| 1849/1892 [6:34:58<39:11, 54.68s/it]                                                     {'loss': 0.2143, 'learning_rate': 2.708559461723659e-08, 'epoch': 3.91}
 98%|█████████▊| 1849/1892 [6:34:58<39:11, 54.68s/it] 98%|█████████▊| 1850/1892 [6:35:53<38:16, 54.67s/it]                                                     {'loss': 0.1914, 'learning_rate': 2.584098484646802e-08, 'epoch': 3.91}
 98%|█████████▊| 1850/1892 [6:35:53<38:16, 54.67s/it] 98%|█████████▊| 1851/1892 [6:36:48<37:21, 54.67s/it]                                                     {'loss': 0.215, 'learning_rate': 2.4625610122264166e-08, 'epoch': 3.91}
 98%|█████████▊| 1851/1892 [6:36:48<37:21, 54.67s/it] 98%|█████████▊| 1852/1892 [6:37:42<36:26, 54.66s/it]                                                     {'loss': 0.2043, 'learning_rate': 2.343947400698432e-08, 'epoch': 3.91}
 98%|█████████▊| 1852/1892 [6:37:42<36:26, 54.66s/it] 98%|█████████▊| 1853/1892 [6:38:37<35:31, 54.64s/it]                                                     {'loss': 0.1873, 'learning_rate': 2.2282579977286335e-08, 'epoch': 3.92}
 98%|█████████▊| 1853/1892 [6:38:37<35:31, 54.64s/it] 98%|█████████▊| 1854/1892 [6:39:32<34:36, 54.66s/it]                                                     {'loss': 0.2076, 'learning_rate': 2.115493142411884e-08, 'epoch': 3.92}
 98%|█████████▊| 1854/1892 [6:39:32<34:36, 54.66s/it] 98%|█████████▊| 1855/1892 [6:40:26<33:43, 54.68s/it]                                                     {'loss': 0.1821, 'learning_rate': 2.0056531652706822e-08, 'epoch': 3.92}
 98%|█████████▊| 1855/1892 [6:40:26<33:43, 54.68s/it] 98%|█████████▊| 1856/1892 [6:41:21<32:48, 54.67s/it]                                                     {'loss': 0.2372, 'learning_rate': 1.8987383882549392e-08, 'epoch': 3.92}
 98%|█████████▊| 1856/1892 [6:41:21<32:48, 54.67s/it] 98%|█████████▊| 1857/1892 [6:42:16<31:53, 54.66s/it]                                                     {'loss': 0.2081, 'learning_rate': 1.7947491247399808e-08, 'epoch': 3.93}
 98%|█████████▊| 1857/1892 [6:42:16<31:53, 54.66s/it] 98%|█████████▊| 1858/1892 [6:43:10<30:57, 54.64s/it]                                                     {'loss': 0.2038, 'learning_rate': 1.6936856795267685e-08, 'epoch': 3.93}
 98%|█████████▊| 1858/1892 [6:43:10<30:57, 54.64s/it] 98%|█████████▊| 1859/1892 [6:44:05<30:02, 54.62s/it]                                                     {'loss': 0.1951, 'learning_rate': 1.5955483488401257e-08, 'epoch': 3.93}
 98%|█████████▊| 1859/1892 [6:44:05<30:02, 54.62s/it] 98%|█████████▊| 1860/1892 [6:45:00<29:08, 54.66s/it]                                                     {'loss': 0.2, 'learning_rate': 1.5003374203284015e-08, 'epoch': 3.93}
 98%|█████████▊| 1860/1892 [6:45:00<29:08, 54.66s/it] 98%|█████████▊| 1861/1892 [6:45:54<28:12, 54.61s/it]                                                     {'loss': 0.2235, 'learning_rate': 1.4080531730621406e-08, 'epoch': 3.93}
 98%|█████████▊| 1861/1892 [6:45:54<28:12, 54.61s/it] 98%|█████████▊| 1862/1892 [6:46:49<27:17, 54.60s/it]                                                     {'loss': 0.2291, 'learning_rate': 1.3186958775339709e-08, 'epoch': 3.94}
 98%|█████████▊| 1862/1892 [6:46:49<27:17, 54.60s/it] 98%|█████████▊| 1863/1892 [6:47:43<26:23, 54.62s/it]                                                     {'loss': 0.2296, 'learning_rate': 1.2322657956570506e-08, 'epoch': 3.94}
 98%|█████████▊| 1863/1892 [6:47:43<26:23, 54.62s/it] 99%|█████████▊| 1864/1892 [6:48:38<25:30, 54.67s/it]                                                     {'loss': 0.2216, 'learning_rate': 1.1487631807648448e-08, 'epoch': 3.94}
 99%|█████████▊| 1864/1892 [6:48:38<25:30, 54.67s/it] 99%|█████████▊| 1865/1892 [6:49:33<24:35, 54.65s/it]                                                     {'loss': 0.2173, 'learning_rate': 1.0681882776100161e-08, 'epoch': 3.94}
 99%|█████████▊| 1865/1892 [6:49:33<24:35, 54.65s/it] 99%|█████████▊| 1866/1892 [6:50:27<23:40, 54.62s/it]                                                     {'loss': 0.2358, 'learning_rate': 9.905413223639804e-09, 'epoch': 3.94}
 99%|█████████▊| 1866/1892 [6:50:27<23:40, 54.62s/it] 99%|█████████▊| 1867/1892 [6:51:22<22:45, 54.64s/it]                                                     {'loss': 0.2079, 'learning_rate': 9.158225426160183e-09, 'epoch': 3.95}
 99%|█████████▊| 1867/1892 [6:51:22<22:45, 54.64s/it] 99%|█████████▊| 1868/1892 [6:52:17<21:50, 54.62s/it]                                                     {'loss': 0.1941, 'learning_rate': 8.440321573729427e-09, 'epoch': 3.95}
 99%|█████████▊| 1868/1892 [6:52:17<21:50, 54.62s/it] 99%|█████████▉| 1869/1892 [6:53:11<20:56, 54.64s/it]                                                     {'loss': 0.2014, 'learning_rate': 7.751703770578768e-09, 'epoch': 3.95}
 99%|█████████▉| 1869/1892 [6:53:11<20:56, 54.64s/it] 99%|█████████▉| 1870/1892 [6:54:06<20:02, 54.64s/it]                                                     {'loss': 0.2299, 'learning_rate': 7.092374035102545e-09, 'epoch': 3.95}
 99%|█████████▉| 1870/1892 [6:54:06<20:02, 54.64s/it] 99%|█████████▉| 1871/1892 [6:55:01<19:07, 54.63s/it]                                                     {'loss': 0.2192, 'learning_rate': 6.4623342998471065e-09, 'epoch': 3.95}
 99%|█████████▉| 1871/1892 [6:55:01<19:07, 54.63s/it] 99%|█████████▉| 1872/1892 [6:55:55<18:12, 54.65s/it]                                                     {'loss': 0.2036, 'learning_rate': 5.86158641150969e-09, 'epoch': 3.96}
 99%|█████████▉| 1872/1892 [6:55:55<18:12, 54.65s/it] 99%|█████████▉| 1873/1892 [6:56:50<17:17, 54.63s/it]                                                     {'loss': 0.209, 'learning_rate': 5.290132130928438e-09, 'epoch': 3.96}
 99%|█████████▉| 1873/1892 [6:56:50<17:17, 54.63s/it] 99%|█████████▉| 1874/1892 [6:57:44<16:22, 54.59s/it]                                                     {'loss': 0.1976, 'learning_rate': 4.747973133081285e-09, 'epoch': 3.96}
 99%|█████████▉| 1874/1892 [6:57:44<16:22, 54.59s/it] 99%|█████████▉| 1875/1892 [6:58:39<15:28, 54.59s/it]                                                     {'loss': 0.1967, 'learning_rate': 4.235111007079296e-09, 'epoch': 3.96}
 99%|█████████▉| 1875/1892 [6:58:39<15:28, 54.59s/it] 99%|█████████▉| 1876/1892 [6:59:33<14:33, 54.60s/it]                                                     {'loss': 0.2005, 'learning_rate': 3.751547256162225e-09, 'epoch': 3.97}
 99%|█████████▉| 1876/1892 [6:59:34<14:33, 54.60s/it] 99%|█████████▉| 1877/1892 [7:00:28<13:39, 54.62s/it]                                                     {'loss': 0.1973, 'learning_rate': 3.2972832976918557e-09, 'epoch': 3.97}
 99%|█████████▉| 1877/1892 [7:00:28<13:39, 54.62s/it] 99%|█████████▉| 1878/1892 [7:01:23<12:44, 54.61s/it]                                                     {'loss': 0.2203, 'learning_rate': 2.872320463154221e-09, 'epoch': 3.97}
 99%|█████████▉| 1878/1892 [7:01:23<12:44, 54.61s/it] 99%|█████████▉| 1879/1892 [7:02:17<11:50, 54.62s/it]                                                     {'loss': 0.2142, 'learning_rate': 2.4766599981473905e-09, 'epoch': 3.97}
 99%|█████████▉| 1879/1892 [7:02:17<11:50, 54.62s/it] 99%|█████████▉| 1880/1892 [7:03:12<10:55, 54.62s/it]                                                     {'loss': 0.2128, 'learning_rate': 2.1103030623836897e-09, 'epoch': 3.97}
 99%|█████████▉| 1880/1892 [7:03:12<10:55, 54.62s/it] 99%|█████████▉| 1881/1892 [7:04:07<10:00, 54.62s/it]                                                     {'loss': 0.1981, 'learning_rate': 1.7732507296830403e-09, 'epoch': 3.98}
 99%|█████████▉| 1881/1892 [7:04:07<10:00, 54.62s/it] 99%|█████████▉| 1882/1892 [7:05:01<09:05, 54.59s/it]                                                     {'loss': 0.211, 'learning_rate': 1.4655039879740706e-09, 'epoch': 3.98}
 99%|█████████▉| 1882/1892 [7:05:01<09:05, 54.59s/it]100%|█████████▉| 1883/1892 [7:05:56<08:11, 54.58s/it]                                                     {'loss': 0.208, 'learning_rate': 1.1870637392863426e-09, 'epoch': 3.98}
100%|█████████▉| 1883/1892 [7:05:56<08:11, 54.58s/it]100%|█████████▉| 1884/1892 [7:06:50<07:16, 54.58s/it]                                                     {'loss': 0.2096, 'learning_rate': 9.379307997492426e-10, 'epoch': 3.98}
100%|█████████▉| 1884/1892 [7:06:50<07:16, 54.58s/it]100%|█████████▉| 1885/1892 [7:07:45<06:22, 54.58s/it]                                                     {'loss': 0.222, 'learning_rate': 7.181058995930912e-10, 'epoch': 3.98}
100%|█████████▉| 1885/1892 [7:07:45<06:22, 54.58s/it]100%|█████████▉| 1886/1892 [7:08:39<05:27, 54.56s/it]                                                     {'loss': 0.2109, 'learning_rate': 5.275896831391514e-10, 'epoch': 3.99}
100%|█████████▉| 1886/1892 [7:08:39<05:27, 54.56s/it]100%|█████████▉| 1887/1892 [7:09:34<04:33, 54.64s/it]                                                     {'loss': 0.2135, 'learning_rate': 3.6638270880851034e-10, 'epoch': 3.99}
100%|█████████▉| 1887/1892 [7:09:34<04:33, 54.64s/it]100%|█████████▉| 1888/1892 [7:10:29<03:38, 54.62s/it]                                                     {'loss': 0.1955, 'learning_rate': 2.344854491087567e-10, 'epoch': 3.99}
100%|█████████▉| 1888/1892 [7:10:29<03:38, 54.62s/it]100%|█████████▉| 1889/1892 [7:11:24<02:44, 54.68s/it]                                                     {'loss': 0.2113, 'learning_rate': 1.318982906428623e-10, 'epoch': 3.99}
100%|█████████▉| 1889/1892 [7:11:24<02:44, 54.68s/it]100%|█████████▉| 1890/1892 [7:12:18<01:49, 54.65s/it]                                                     {'loss': 0.2213, 'learning_rate': 5.86215341014107e-11, 'epoch': 3.99}
100%|█████████▉| 1890/1892 [7:12:18<01:49, 54.65s/it]100%|█████████▉| 1891/1892 [7:13:13<00:54, 54.60s/it]                                                     {'loss': 0.2046, 'learning_rate': 1.4655394264817545e-11, 'epoch': 4.0}
100%|█████████▉| 1891/1892 [7:13:13<00:54, 54.60s/it]100%|██████████| 1892/1892 [7:14:07<00:00, 54.61s/it]                                                     {'loss': 0.1975, 'learning_rate': 0.0, 'epoch': 4.0}
100%|██████████| 1892/1892 [7:14:07<00:00, 54.61s/it]/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
                                                     {'train_runtime': 26120.5964, 'train_samples_per_second': 11.6, 'train_steps_per_second': 0.072, 'train_loss': 0.052952645421343175, 'epoch': 4.0}
100%|██████████| 1892/1892 [7:15:20<00:00, 54.61s/it]100%|██████████| 1892/1892 [7:15:20<00:00, 13.81s/it]
***** train metrics *****
  epoch                    =        4.0
  train_loss               =      0.053
  train_runtime            = 7:15:20.59
  train_samples_per_second =       11.6
  train_steps_per_second   =      0.072
Figure saved at: /mnt/data_llm/model/checkpoints/checkpoints-phi-2.7b-moe-v101_0426/training_loss.png
Figure saved at: /mnt/data_llm/model/checkpoints/checkpoints-phi-2.7b-moe-v101_0426/training_eval_loss.png
odict_keys(['model.embed_tokens.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.0.self_attn.dense.weight', 'model.layers.0.self_attn.dense.bias', 'model.layers.0.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.0.input_layernorm.weight', 'model.layers.0.input_layernorm.bias', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.1.self_attn.dense.weight', 'model.layers.1.self_attn.dense.bias', 'model.layers.1.mlp.fc1.weight', 'model.layers.1.mlp.fc1.bias', 'model.layers.1.mlp.fc2.weight', 'model.layers.1.mlp.fc2.bias', 'model.layers.1.input_layernorm.weight', 'model.layers.1.input_layernorm.bias', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.2.self_attn.dense.weight', 'model.layers.2.self_attn.dense.bias', 'model.layers.2.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.2.input_layernorm.weight', 'model.layers.2.input_layernorm.bias', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.3.self_attn.dense.weight', 'model.layers.3.self_attn.dense.bias', 'model.layers.3.mlp.fc1.weight', 'model.layers.3.mlp.fc1.bias', 'model.layers.3.mlp.fc2.weight', 'model.layers.3.mlp.fc2.bias', 'model.layers.3.input_layernorm.weight', 'model.layers.3.input_layernorm.bias', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.4.self_attn.dense.weight', 'model.layers.4.self_attn.dense.bias', 'model.layers.4.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.4.input_layernorm.weight', 'model.layers.4.input_layernorm.bias', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.5.self_attn.dense.weight', 'model.layers.5.self_attn.dense.bias', 'model.layers.5.mlp.fc1.weight', 'model.layers.5.mlp.fc1.bias', 'model.layers.5.mlp.fc2.weight', 'model.layers.5.mlp.fc2.bias', 'model.layers.5.input_layernorm.weight', 'model.layers.5.input_layernorm.bias', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.6.self_attn.dense.weight', 'model.layers.6.self_attn.dense.bias', 'model.layers.6.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.6.input_layernorm.weight', 'model.layers.6.input_layernorm.bias', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.7.self_attn.dense.weight', 'model.layers.7.self_attn.dense.bias', 'model.layers.7.mlp.fc1.weight', 'model.layers.7.mlp.fc1.bias', 'model.layers.7.mlp.fc2.weight', 'model.layers.7.mlp.fc2.bias', 'model.layers.7.input_layernorm.weight', 'model.layers.7.input_layernorm.bias', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.8.self_attn.dense.weight', 'model.layers.8.self_attn.dense.bias', 'model.layers.8.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.8.input_layernorm.weight', 'model.layers.8.input_layernorm.bias', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.9.self_attn.dense.weight', 'model.layers.9.self_attn.dense.bias', 'model.layers.9.mlp.fc1.weight', 'model.layers.9.mlp.fc1.bias', 'model.layers.9.mlp.fc2.weight', 'model.layers.9.mlp.fc2.bias', 'model.layers.9.input_layernorm.weight', 'model.layers.9.input_layernorm.bias', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.10.self_attn.dense.weight', 'model.layers.10.self_attn.dense.bias', 'model.layers.10.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.10.input_layernorm.weight', 'model.layers.10.input_layernorm.bias', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.11.self_attn.dense.weight', 'model.layers.11.self_attn.dense.bias', 'model.layers.11.mlp.fc1.weight', 'model.layers.11.mlp.fc1.bias', 'model.layers.11.mlp.fc2.weight', 'model.layers.11.mlp.fc2.bias', 'model.layers.11.input_layernorm.weight', 'model.layers.11.input_layernorm.bias', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.12.self_attn.dense.weight', 'model.layers.12.self_attn.dense.bias', 'model.layers.12.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.12.input_layernorm.weight', 'model.layers.12.input_layernorm.bias', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.13.self_attn.dense.weight', 'model.layers.13.self_attn.dense.bias', 'model.layers.13.mlp.fc1.weight', 'model.layers.13.mlp.fc1.bias', 'model.layers.13.mlp.fc2.weight', 'model.layers.13.mlp.fc2.bias', 'model.layers.13.input_layernorm.weight', 'model.layers.13.input_layernorm.bias', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.14.self_attn.dense.weight', 'model.layers.14.self_attn.dense.bias', 'model.layers.14.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.14.input_layernorm.weight', 'model.layers.14.input_layernorm.bias', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.15.self_attn.dense.weight', 'model.layers.15.self_attn.dense.bias', 'model.layers.15.mlp.fc1.weight', 'model.layers.15.mlp.fc1.bias', 'model.layers.15.mlp.fc2.weight', 'model.layers.15.mlp.fc2.bias', 'model.layers.15.input_layernorm.weight', 'model.layers.15.input_layernorm.bias', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.16.self_attn.dense.weight', 'model.layers.16.self_attn.dense.bias', 'model.layers.16.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.16.input_layernorm.weight', 'model.layers.16.input_layernorm.bias', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.17.self_attn.dense.weight', 'model.layers.17.self_attn.dense.bias', 'model.layers.17.mlp.fc1.weight', 'model.layers.17.mlp.fc1.bias', 'model.layers.17.mlp.fc2.weight', 'model.layers.17.mlp.fc2.bias', 'model.layers.17.input_layernorm.weight', 'model.layers.17.input_layernorm.bias', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.18.self_attn.dense.weight', 'model.layers.18.self_attn.dense.bias', 'model.layers.18.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.18.input_layernorm.weight', 'model.layers.18.input_layernorm.bias', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.19.self_attn.dense.weight', 'model.layers.19.self_attn.dense.bias', 'model.layers.19.mlp.fc1.weight', 'model.layers.19.mlp.fc1.bias', 'model.layers.19.mlp.fc2.weight', 'model.layers.19.mlp.fc2.bias', 'model.layers.19.input_layernorm.weight', 'model.layers.19.input_layernorm.bias', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.20.self_attn.dense.weight', 'model.layers.20.self_attn.dense.bias', 'model.layers.20.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.20.input_layernorm.weight', 'model.layers.20.input_layernorm.bias', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.21.self_attn.dense.weight', 'model.layers.21.self_attn.dense.bias', 'model.layers.21.mlp.fc1.weight', 'model.layers.21.mlp.fc1.bias', 'model.layers.21.mlp.fc2.weight', 'model.layers.21.mlp.fc2.bias', 'model.layers.21.input_layernorm.weight', 'model.layers.21.input_layernorm.bias', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.22.self_attn.dense.weight', 'model.layers.22.self_attn.dense.bias', 'model.layers.22.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.22.input_layernorm.weight', 'model.layers.22.input_layernorm.bias', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.23.self_attn.dense.weight', 'model.layers.23.self_attn.dense.bias', 'model.layers.23.mlp.fc1.weight', 'model.layers.23.mlp.fc1.bias', 'model.layers.23.mlp.fc2.weight', 'model.layers.23.mlp.fc2.bias', 'model.layers.23.input_layernorm.weight', 'model.layers.23.input_layernorm.bias', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.24.self_attn.dense.weight', 'model.layers.24.self_attn.dense.bias', 'model.layers.24.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.24.input_layernorm.weight', 'model.layers.24.input_layernorm.bias', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.25.self_attn.dense.weight', 'model.layers.25.self_attn.dense.bias', 'model.layers.25.mlp.fc1.weight', 'model.layers.25.mlp.fc1.bias', 'model.layers.25.mlp.fc2.weight', 'model.layers.25.mlp.fc2.bias', 'model.layers.25.input_layernorm.weight', 'model.layers.25.input_layernorm.bias', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.26.self_attn.dense.weight', 'model.layers.26.self_attn.dense.bias', 'model.layers.26.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.26.input_layernorm.weight', 'model.layers.26.input_layernorm.bias', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.27.self_attn.dense.weight', 'model.layers.27.self_attn.dense.bias', 'model.layers.27.mlp.fc1.weight', 'model.layers.27.mlp.fc1.bias', 'model.layers.27.mlp.fc2.weight', 'model.layers.27.mlp.fc2.bias', 'model.layers.27.input_layernorm.weight', 'model.layers.27.input_layernorm.bias', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.28.self_attn.dense.weight', 'model.layers.28.self_attn.dense.bias', 'model.layers.28.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.28.input_layernorm.weight', 'model.layers.28.input_layernorm.bias', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.29.self_attn.dense.weight', 'model.layers.29.self_attn.dense.bias', 'model.layers.29.mlp.fc1.weight', 'model.layers.29.mlp.fc1.bias', 'model.layers.29.mlp.fc2.weight', 'model.layers.29.mlp.fc2.bias', 'model.layers.29.input_layernorm.weight', 'model.layers.29.input_layernorm.bias', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.30.self_attn.dense.weight', 'model.layers.30.self_attn.dense.bias', 'model.layers.30.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.30.input_layernorm.weight', 'model.layers.30.input_layernorm.bias', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.31.self_attn.dense.weight', 'model.layers.31.self_attn.dense.bias', 'model.layers.31.mlp.fc1.weight', 'model.layers.31.mlp.fc1.bias', 'model.layers.31.mlp.fc2.weight', 'model.layers.31.mlp.fc2.bias', 'model.layers.31.input_layernorm.weight', 'model.layers.31.input_layernorm.bias', 'model.final_layernorm.weight', 'model.final_layernorm.bias', 'model.image_tower.image_tower.vision_model.embeddings.class_embedding', 'model.image_tower.image_tower.vision_model.embeddings.patch_embedding.weight', 'model.image_tower.image_tower.vision_model.embeddings.position_embedding.weight', 'model.image_tower.image_tower.vision_model.pre_layrnorm.weight', 'model.image_tower.image_tower.vision_model.pre_layrnorm.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.post_layernorm.weight', 'model.image_tower.image_tower.vision_model.post_layernorm.bias', 'model.mm_projector.image_spatial_proj.0.weight', 'model.mm_projector.image_spatial_proj.0.bias', 'model.mm_projector.image_spatial_proj.2.weight', 'model.mm_projector.image_spatial_proj.2.bias', 'lm_head.weight'])odict_keys(['model.embed_tokens.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.0.self_attn.dense.weight', 'model.layers.0.self_attn.dense.bias', 'model.layers.0.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.0.input_layernorm.weight', 'model.layers.0.input_layernorm.bias', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.1.self_attn.dense.weight', 'model.layers.1.self_attn.dense.bias', 'model.layers.1.mlp.fc1.weight', 'model.layers.1.mlp.fc1.bias', 'model.layers.1.mlp.fc2.weight', 'model.layers.1.mlp.fc2.bias', 'model.layers.1.input_layernorm.weight', 'model.layers.1.input_layernorm.bias', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.2.self_attn.dense.weight', 'model.layers.2.self_attn.dense.bias', 'model.layers.2.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.2.input_layernorm.weight', 'model.layers.2.input_layernorm.bias', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.3.self_attn.dense.weight', 'model.layers.3.self_attn.dense.bias', 'model.layers.3.mlp.fc1.weight', 'model.layers.3.mlp.fc1.bias', 'model.layers.3.mlp.fc2.weight', 'model.layers.3.mlp.fc2.bias', 'model.layers.3.input_layernorm.weight', 'model.layers.3.input_layernorm.bias', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.4.self_attn.dense.weight', 'model.layers.4.self_attn.dense.bias', 'model.layers.4.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.4.input_layernorm.weight', 'model.layers.4.input_layernorm.bias', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.5.self_attn.dense.weight', 'model.layers.5.self_attn.dense.bias', 'model.layers.5.mlp.fc1.weight', 'model.layers.5.mlp.fc1.bias', 'model.layers.5.mlp.fc2.weight', 'model.layers.5.mlp.fc2.bias', 'model.layers.5.input_layernorm.weight', 'model.layers.5.input_layernorm.bias', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.6.self_attn.dense.weight', 'model.layers.6.self_attn.dense.bias', 'model.layers.6.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.6.input_layernorm.weight', 'model.layers.6.input_layernorm.bias', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.7.self_attn.dense.weight', 'model.layers.7.self_attn.dense.bias', 'model.layers.7.mlp.fc1.weight', 'model.layers.7.mlp.fc1.bias', 'model.layers.7.mlp.fc2.weight', 'model.layers.7.mlp.fc2.bias', 'model.layers.7.input_layernorm.weight', 'model.layers.7.input_layernorm.bias', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.8.self_attn.dense.weight', 'model.layers.8.self_attn.dense.bias', 'model.layers.8.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.8.input_layernorm.weight', 'model.layers.8.input_layernorm.bias', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.9.self_attn.dense.weight', 'model.layers.9.self_attn.dense.bias', 'model.layers.9.mlp.fc1.weight', 'model.layers.9.mlp.fc1.bias', 'model.layers.9.mlp.fc2.weight', 'model.layers.9.mlp.fc2.bias', 'model.layers.9.input_layernorm.weight', 'model.layers.9.input_layernorm.bias', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.10.self_attn.dense.weight', 'model.layers.10.self_attn.dense.bias', 'model.layers.10.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.10.input_layernorm.weight', 'model.layers.10.input_layernorm.bias', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.11.self_attn.dense.weight', 'model.layers.11.self_attn.dense.bias', 'model.layers.11.mlp.fc1.weight', 'model.layers.11.mlp.fc1.bias', 'model.layers.11.mlp.fc2.weight', 'model.layers.11.mlp.fc2.bias', 'model.layers.11.input_layernorm.weight', 'model.layers.11.input_layernorm.bias', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.12.self_attn.dense.weight', 'model.layers.12.self_attn.dense.bias', 'model.layers.12.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.12.input_layernorm.weight', 'model.layers.12.input_layernorm.bias', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.13.self_attn.dense.weight', 'model.layers.13.self_attn.dense.bias', 'model.layers.13.mlp.fc1.weight', 'model.layers.13.mlp.fc1.bias', 'model.layers.13.mlp.fc2.weight', 'model.layers.13.mlp.fc2.bias', 'model.layers.13.input_layernorm.weight', 'model.layers.13.input_layernorm.bias', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.14.self_attn.dense.weight', 'model.layers.14.self_attn.dense.bias', 'model.layers.14.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.14.input_layernorm.weight', 'model.layers.14.input_layernorm.bias', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.15.self_attn.dense.weight', 'model.layers.15.self_attn.dense.bias', 'model.layers.15.mlp.fc1.weight', 'model.layers.15.mlp.fc1.bias', 'model.layers.15.mlp.fc2.weight', 'model.layers.15.mlp.fc2.bias', 'model.layers.15.input_layernorm.weight', 'model.layers.15.input_layernorm.bias', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.16.self_attn.dense.weight', 'model.layers.16.self_attn.dense.bias', 'model.layers.16.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.16.input_layernorm.weight', 'model.layers.16.input_layernorm.bias', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.17.self_attn.dense.weight', 'model.layers.17.self_attn.dense.bias', 'model.layers.17.mlp.fc1.weight', 'model.layers.17.mlp.fc1.bias', 'model.layers.17.mlp.fc2.weight', 'model.layers.17.mlp.fc2.bias', 'model.layers.17.input_layernorm.weight', 'model.layers.17.input_layernorm.bias', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.18.self_attn.dense.weight', 'model.layers.18.self_attn.dense.bias', 'model.layers.18.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.18.input_layernorm.weight', 'model.layers.18.input_layernorm.bias', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.19.self_attn.dense.weight', 'model.layers.19.self_attn.dense.bias', 'model.layers.19.mlp.fc1.weight', 'model.layers.19.mlp.fc1.bias', 'model.layers.19.mlp.fc2.weight', 'model.layers.19.mlp.fc2.bias', 'model.layers.19.input_layernorm.weight', 'model.layers.19.input_layernorm.bias', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.20.self_attn.dense.weight', 'model.layers.20.self_attn.dense.bias', 'model.layers.20.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.20.input_layernorm.weight', 'model.layers.20.input_layernorm.bias', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.21.self_attn.dense.weight', 'model.layers.21.self_attn.dense.bias', 'model.layers.21.mlp.fc1.weight', 'model.layers.21.mlp.fc1.bias', 'model.layers.21.mlp.fc2.weight', 'model.layers.21.mlp.fc2.bias', 'model.layers.21.input_layernorm.weight', 'model.layers.21.input_layernorm.bias', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.22.self_attn.dense.weight', 'model.layers.22.self_attn.dense.bias', 'model.layers.22.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.22.input_layernorm.weight', 'model.layers.22.input_layernorm.bias', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.23.self_attn.dense.weight', 'model.layers.23.self_attn.dense.bias', 'model.layers.23.mlp.fc1.weight', 'model.layers.23.mlp.fc1.bias', 'model.layers.23.mlp.fc2.weight', 'model.layers.23.mlp.fc2.bias', 'model.layers.23.input_layernorm.weight', 'model.layers.23.input_layernorm.bias', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.24.self_attn.dense.weight', 'model.layers.24.self_attn.dense.bias', 'model.layers.24.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.24.input_layernorm.weight', 'model.layers.24.input_layernorm.bias', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.25.self_attn.dense.weight', 'model.layers.25.self_attn.dense.bias', 'model.layers.25.mlp.fc1.weight', 'model.layers.25.mlp.fc1.bias', 'model.layers.25.mlp.fc2.weight', 'model.layers.25.mlp.fc2.bias', 'model.layers.25.input_layernorm.weight', 'model.layers.25.input_layernorm.bias', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.26.self_attn.dense.weight', 'model.layers.26.self_attn.dense.bias', 'model.layers.26.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.26.input_layernorm.weight', 'model.layers.26.input_layernorm.bias', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.27.self_attn.dense.weight', 'model.layers.27.self_attn.dense.bias', 'model.layers.27.mlp.fc1.weight', 'model.layers.27.mlp.fc1.bias', 'model.layers.27.mlp.fc2.weight', 'model.layers.27.mlp.fc2.bias', 'model.layers.27.input_layernorm.weight', 'model.layers.27.input_layernorm.bias', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.28.self_attn.dense.weight', 'model.layers.28.self_attn.dense.bias', 'model.layers.28.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.28.input_layernorm.weight', 'model.layers.28.input_layernorm.bias', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.29.self_attn.dense.weight', 'model.layers.29.self_attn.dense.bias', 'model.layers.29.mlp.fc1.weight', 'model.layers.29.mlp.fc1.bias', 'model.layers.29.mlp.fc2.weight', 'model.layers.29.mlp.fc2.bias', 'model.layers.29.input_layernorm.weight', 'model.layers.29.input_layernorm.bias', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.30.self_attn.dense.weight', 'model.layers.30.self_attn.dense.bias', 'model.layers.30.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.30.input_layernorm.weight', 'model.layers.30.input_layernorm.bias', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.31.self_attn.dense.weight', 'model.layers.31.self_attn.dense.bias', 'model.layers.31.mlp.fc1.weight', 'model.layers.31.mlp.fc1.bias', 'model.layers.31.mlp.fc2.weight', 'model.layers.31.mlp.fc2.bias', 'model.layers.31.input_layernorm.weight', 'model.layers.31.input_layernorm.bias', 'model.final_layernorm.weight', 'model.final_layernorm.bias', 'model.image_tower.image_tower.vision_model.embeddings.class_embedding', 'model.image_tower.image_tower.vision_model.embeddings.patch_embedding.weight', 'model.image_tower.image_tower.vision_model.embeddings.position_embedding.weight', 'model.image_tower.image_tower.vision_model.pre_layrnorm.weight', 'model.image_tower.image_tower.vision_model.pre_layrnorm.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.post_layernorm.weight', 'model.image_tower.image_tower.vision_model.post_layernorm.bias', 'model.mm_projector.image_spatial_proj.0.weight', 'model.mm_projector.image_spatial_proj.0.bias', 'model.mm_projector.image_spatial_proj.2.weight', 'model.mm_projector.image_spatial_proj.2.bias', 'lm_head.weight'])

odict_keys(['model.embed_tokens.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.0.self_attn.dense.weight', 'model.layers.0.self_attn.dense.bias', 'model.layers.0.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.0.input_layernorm.weight', 'model.layers.0.input_layernorm.bias', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.1.self_attn.dense.weight', 'model.layers.1.self_attn.dense.bias', 'model.layers.1.mlp.fc1.weight', 'model.layers.1.mlp.fc1.bias', 'model.layers.1.mlp.fc2.weight', 'model.layers.1.mlp.fc2.bias', 'model.layers.1.input_layernorm.weight', 'model.layers.1.input_layernorm.bias', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.2.self_attn.dense.weight', 'model.layers.2.self_attn.dense.bias', 'model.layers.2.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.2.input_layernorm.weight', 'model.layers.2.input_layernorm.bias', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.3.self_attn.dense.weight', 'model.layers.3.self_attn.dense.bias', 'model.layers.3.mlp.fc1.weight', 'model.layers.3.mlp.fc1.bias', 'model.layers.3.mlp.fc2.weight', 'model.layers.3.mlp.fc2.bias', 'model.layers.3.input_layernorm.weight', 'model.layers.3.input_layernorm.bias', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.4.self_attn.dense.weight', 'model.layers.4.self_attn.dense.bias', 'model.layers.4.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.4.input_layernorm.weight', 'model.layers.4.input_layernorm.bias', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.5.self_attn.dense.weight', 'model.layers.5.self_attn.dense.bias', 'model.layers.5.mlp.fc1.weight', 'model.layers.5.mlp.fc1.bias', 'model.layers.5.mlp.fc2.weight', 'model.layers.5.mlp.fc2.bias', 'model.layers.5.input_layernorm.weight', 'model.layers.5.input_layernorm.bias', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.6.self_attn.dense.weight', 'model.layers.6.self_attn.dense.bias', 'model.layers.6.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.6.input_layernorm.weight', 'model.layers.6.input_layernorm.bias', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.7.self_attn.dense.weight', 'model.layers.7.self_attn.dense.bias', 'model.layers.7.mlp.fc1.weight', 'model.layers.7.mlp.fc1.bias', 'model.layers.7.mlp.fc2.weight', 'model.layers.7.mlp.fc2.bias', 'model.layers.7.input_layernorm.weight', 'model.layers.7.input_layernorm.bias', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.8.self_attn.dense.weight', 'model.layers.8.self_attn.dense.bias', 'model.layers.8.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.8.input_layernorm.weight', 'model.layers.8.input_layernorm.bias', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.9.self_attn.dense.weight', 'model.layers.9.self_attn.dense.bias', 'model.layers.9.mlp.fc1.weight', 'model.layers.9.mlp.fc1.bias', 'model.layers.9.mlp.fc2.weight', 'model.layers.9.mlp.fc2.bias', 'model.layers.9.input_layernorm.weight', 'model.layers.9.input_layernorm.bias', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.10.self_attn.dense.weight', 'model.layers.10.self_attn.dense.bias', 'model.layers.10.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.10.input_layernorm.weight', 'model.layers.10.input_layernorm.bias', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.11.self_attn.dense.weight', 'model.layers.11.self_attn.dense.bias', 'model.layers.11.mlp.fc1.weight', 'model.layers.11.mlp.fc1.bias', 'model.layers.11.mlp.fc2.weight', 'model.layers.11.mlp.fc2.bias', 'model.layers.11.input_layernorm.weight', 'model.layers.11.input_layernorm.bias', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.12.self_attn.dense.weight', 'model.layers.12.self_attn.dense.bias', 'model.layers.12.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.12.input_layernorm.weight', 'model.layers.12.input_layernorm.bias', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.13.self_attn.dense.weight', 'model.layers.13.self_attn.dense.bias', 'model.layers.13.mlp.fc1.weight', 'model.layers.13.mlp.fc1.bias', 'model.layers.13.mlp.fc2.weight', 'model.layers.13.mlp.fc2.bias', 'model.layers.13.input_layernorm.weight', 'model.layers.13.input_layernorm.bias', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.14.self_attn.dense.weight', 'model.layers.14.self_attn.dense.bias', 'model.layers.14.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.14.input_layernorm.weight', 'model.layers.14.input_layernorm.bias', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.15.self_attn.dense.weight', 'model.layers.15.self_attn.dense.bias', 'model.layers.15.mlp.fc1.weight', 'model.layers.15.mlp.fc1.bias', 'model.layers.15.mlp.fc2.weight', 'model.layers.15.mlp.fc2.bias', 'model.layers.15.input_layernorm.weight', 'model.layers.15.input_layernorm.bias', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.16.self_attn.dense.weight', 'model.layers.16.self_attn.dense.bias', 'model.layers.16.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.16.input_layernorm.weight', 'model.layers.16.input_layernorm.bias', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.17.self_attn.dense.weight', 'model.layers.17.self_attn.dense.bias', 'model.layers.17.mlp.fc1.weight', 'model.layers.17.mlp.fc1.bias', 'model.layers.17.mlp.fc2.weight', 'model.layers.17.mlp.fc2.bias', 'model.layers.17.input_layernorm.weight', 'model.layers.17.input_layernorm.bias', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.18.self_attn.dense.weight', 'model.layers.18.self_attn.dense.bias', 'model.layers.18.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.18.input_layernorm.weight', 'model.layers.18.input_layernorm.bias', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.19.self_attn.dense.weight', 'model.layers.19.self_attn.dense.bias', 'model.layers.19.mlp.fc1.weight', 'model.layers.19.mlp.fc1.bias', 'model.layers.19.mlp.fc2.weight', 'model.layers.19.mlp.fc2.bias', 'model.layers.19.input_layernorm.weight', 'model.layers.19.input_layernorm.bias', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.20.self_attn.dense.weight', 'model.layers.20.self_attn.dense.bias', 'model.layers.20.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.20.input_layernorm.weight', 'model.layers.20.input_layernorm.bias', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.21.self_attn.dense.weight', 'model.layers.21.self_attn.dense.bias', 'model.layers.21.mlp.fc1.weight', 'model.layers.21.mlp.fc1.bias', 'model.layers.21.mlp.fc2.weight', 'model.layers.21.mlp.fc2.bias', 'model.layers.21.input_layernorm.weight', 'model.layers.21.input_layernorm.bias', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.22.self_attn.dense.weight', 'model.layers.22.self_attn.dense.bias', 'model.layers.22.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.22.input_layernorm.weight', 'model.layers.22.input_layernorm.bias', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.23.self_attn.dense.weight', 'model.layers.23.self_attn.dense.bias', 'model.layers.23.mlp.fc1.weight', 'model.layers.23.mlp.fc1.bias', 'model.layers.23.mlp.fc2.weight', 'model.layers.23.mlp.fc2.bias', 'model.layers.23.input_layernorm.weight', 'model.layers.23.input_layernorm.bias', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.24.self_attn.dense.weight', 'model.layers.24.self_attn.dense.bias', 'model.layers.24.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.24.input_layernorm.weight', 'model.layers.24.input_layernorm.bias', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.25.self_attn.dense.weight', 'model.layers.25.self_attn.dense.bias', 'model.layers.25.mlp.fc1.weight', 'model.layers.25.mlp.fc1.bias', 'model.layers.25.mlp.fc2.weight', 'model.layers.25.mlp.fc2.bias', 'model.layers.25.input_layernorm.weight', 'model.layers.25.input_layernorm.bias', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.26.self_attn.dense.weight', 'model.layers.26.self_attn.dense.bias', 'model.layers.26.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.26.input_layernorm.weight', 'model.layers.26.input_layernorm.bias', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.27.self_attn.dense.weight', 'model.layers.27.self_attn.dense.bias', 'model.layers.27.mlp.fc1.weight', 'model.layers.27.mlp.fc1.bias', 'model.layers.27.mlp.fc2.weight', 'model.layers.27.mlp.fc2.bias', 'model.layers.27.input_layernorm.weight', 'model.layers.27.input_layernorm.bias', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.28.self_attn.dense.weight', 'model.layers.28.self_attn.dense.bias', 'model.layers.28.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.28.input_layernorm.weight', 'model.layers.28.input_layernorm.bias', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.29.self_attn.dense.weight', 'model.layers.29.self_attn.dense.bias', 'model.layers.29.mlp.fc1.weight', 'model.layers.29.mlp.fc1.bias', 'model.layers.29.mlp.fc2.weight', 'model.layers.29.mlp.fc2.bias', 'model.layers.29.input_layernorm.weight', 'model.layers.29.input_layernorm.bias', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.30.self_attn.dense.weight', 'model.layers.30.self_attn.dense.bias', 'model.layers.30.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.30.input_layernorm.weight', 'model.layers.30.input_layernorm.bias', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.31.self_attn.dense.weight', 'model.layers.31.self_attn.dense.bias', 'model.layers.31.mlp.fc1.weight', 'model.layers.31.mlp.fc1.bias', 'model.layers.31.mlp.fc2.weight', 'model.layers.31.mlp.fc2.bias', 'model.layers.31.input_layernorm.weight', 'model.layers.31.input_layernorm.bias', 'model.final_layernorm.weight', 'model.final_layernorm.bias', 'model.image_tower.image_tower.vision_model.embeddings.class_embedding', 'model.image_tower.image_tower.vision_model.embeddings.patch_embedding.weight', 'model.image_tower.image_tower.vision_model.embeddings.position_embedding.weight', 'model.image_tower.image_tower.vision_model.pre_layrnorm.weight', 'model.image_tower.image_tower.vision_model.pre_layrnorm.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.post_layernorm.weight', 'model.image_tower.image_tower.vision_model.post_layernorm.bias', 'model.mm_projector.image_spatial_proj.0.weight', 'model.mm_projector.image_spatial_proj.0.bias', 'model.mm_projector.image_spatial_proj.2.weight', 'model.mm_projector.image_spatial_proj.2.bias', 'lm_head.weight'])
odict_keys(['model.embed_tokens.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.0.self_attn.dense.weight', 'model.layers.0.self_attn.dense.bias', 'model.layers.0.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.0.input_layernorm.weight', 'model.layers.0.input_layernorm.bias', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.1.self_attn.dense.weight', 'model.layers.1.self_attn.dense.bias', 'model.layers.1.mlp.fc1.weight', 'model.layers.1.mlp.fc1.bias', 'model.layers.1.mlp.fc2.weight', 'model.layers.1.mlp.fc2.bias', 'model.layers.1.input_layernorm.weight', 'model.layers.1.input_layernorm.bias', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.2.self_attn.dense.weight', 'model.layers.2.self_attn.dense.bias', 'model.layers.2.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.2.input_layernorm.weight', 'model.layers.2.input_layernorm.bias', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.3.self_attn.dense.weight', 'model.layers.3.self_attn.dense.bias', 'model.layers.3.mlp.fc1.weight', 'model.layers.3.mlp.fc1.bias', 'model.layers.3.mlp.fc2.weight', 'model.layers.3.mlp.fc2.bias', 'model.layers.3.input_layernorm.weight', 'model.layers.3.input_layernorm.bias', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.4.self_attn.dense.weight', 'model.layers.4.self_attn.dense.bias', 'model.layers.4.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.4.input_layernorm.weight', 'model.layers.4.input_layernorm.bias', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.5.self_attn.dense.weight', 'model.layers.5.self_attn.dense.bias', 'model.layers.5.mlp.fc1.weight', 'model.layers.5.mlp.fc1.bias', 'model.layers.5.mlp.fc2.weight', 'model.layers.5.mlp.fc2.bias', 'model.layers.5.input_layernorm.weight', 'model.layers.5.input_layernorm.bias', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.6.self_attn.dense.weight', 'model.layers.6.self_attn.dense.bias', 'model.layers.6.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.6.input_layernorm.weight', 'model.layers.6.input_layernorm.bias', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.7.self_attn.dense.weight', 'model.layers.7.self_attn.dense.bias', 'model.layers.7.mlp.fc1.weight', 'model.layers.7.mlp.fc1.bias', 'model.layers.7.mlp.fc2.weight', 'model.layers.7.mlp.fc2.bias', 'model.layers.7.input_layernorm.weight', 'model.layers.7.input_layernorm.bias', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.8.self_attn.dense.weight', 'model.layers.8.self_attn.dense.bias', 'model.layers.8.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.8.input_layernorm.weight', 'model.layers.8.input_layernorm.bias', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.9.self_attn.dense.weight', 'model.layers.9.self_attn.dense.bias', 'model.layers.9.mlp.fc1.weight', 'model.layers.9.mlp.fc1.bias', 'model.layers.9.mlp.fc2.weight', 'model.layers.9.mlp.fc2.bias', 'model.layers.9.input_layernorm.weight', 'model.layers.9.input_layernorm.bias', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.10.self_attn.dense.weight', 'model.layers.10.self_attn.dense.bias', 'model.layers.10.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.10.input_layernorm.weight', 'model.layers.10.input_layernorm.bias', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.11.self_attn.dense.weight', 'model.layers.11.self_attn.dense.bias', 'model.layers.11.mlp.fc1.weight', 'model.layers.11.mlp.fc1.bias', 'model.layers.11.mlp.fc2.weight', 'model.layers.11.mlp.fc2.bias', 'model.layers.11.input_layernorm.weight', 'model.layers.11.input_layernorm.bias', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.12.self_attn.dense.weight', 'model.layers.12.self_attn.dense.bias', 'model.layers.12.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.12.input_layernorm.weight', 'model.layers.12.input_layernorm.bias', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.13.self_attn.dense.weight', 'model.layers.13.self_attn.dense.bias', 'model.layers.13.mlp.fc1.weight', 'model.layers.13.mlp.fc1.bias', 'model.layers.13.mlp.fc2.weight', 'model.layers.13.mlp.fc2.bias', 'model.layers.13.input_layernorm.weight', 'model.layers.13.input_layernorm.bias', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.14.self_attn.dense.weight', 'model.layers.14.self_attn.dense.bias', 'model.layers.14.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.14.input_layernorm.weight', 'model.layers.14.input_layernorm.bias', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.15.self_attn.dense.weight', 'model.layers.15.self_attn.dense.bias', 'model.layers.15.mlp.fc1.weight', 'model.layers.15.mlp.fc1.bias', 'model.layers.15.mlp.fc2.weight', 'model.layers.15.mlp.fc2.bias', 'model.layers.15.input_layernorm.weight', 'model.layers.15.input_layernorm.bias', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.16.self_attn.dense.weight', 'model.layers.16.self_attn.dense.bias', 'model.layers.16.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.16.input_layernorm.weight', 'model.layers.16.input_layernorm.bias', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.17.self_attn.dense.weight', 'model.layers.17.self_attn.dense.bias', 'model.layers.17.mlp.fc1.weight', 'model.layers.17.mlp.fc1.bias', 'model.layers.17.mlp.fc2.weight', 'model.layers.17.mlp.fc2.bias', 'model.layers.17.input_layernorm.weight', 'model.layers.17.input_layernorm.bias', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.18.self_attn.dense.weight', 'model.layers.18.self_attn.dense.bias', 'model.layers.18.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.18.input_layernorm.weight', 'model.layers.18.input_layernorm.bias', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.19.self_attn.dense.weight', 'model.layers.19.self_attn.dense.bias', 'model.layers.19.mlp.fc1.weight', 'model.layers.19.mlp.fc1.bias', 'model.layers.19.mlp.fc2.weight', 'model.layers.19.mlp.fc2.bias', 'model.layers.19.input_layernorm.weight', 'model.layers.19.input_layernorm.bias', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.20.self_attn.dense.weight', 'model.layers.20.self_attn.dense.bias', 'model.layers.20.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.20.input_layernorm.weight', 'model.layers.20.input_layernorm.bias', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.21.self_attn.dense.weight', 'model.layers.21.self_attn.dense.bias', 'model.layers.21.mlp.fc1.weight', 'model.layers.21.mlp.fc1.bias', 'model.layers.21.mlp.fc2.weight', 'model.layers.21.mlp.fc2.bias', 'model.layers.21.input_layernorm.weight', 'model.layers.21.input_layernorm.bias', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.22.self_attn.dense.weight', 'model.layers.22.self_attn.dense.bias', 'model.layers.22.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.22.input_layernorm.weight', 'model.layers.22.input_layernorm.bias', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.23.self_attn.dense.weight', 'model.layers.23.self_attn.dense.bias', 'model.layers.23.mlp.fc1.weight', 'model.layers.23.mlp.fc1.bias', 'model.layers.23.mlp.fc2.weight', 'model.layers.23.mlp.fc2.bias', 'model.layers.23.input_layernorm.weight', 'model.layers.23.input_layernorm.bias', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.24.self_attn.dense.weight', 'model.layers.24.self_attn.dense.bias', 'model.layers.24.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.24.input_layernorm.weight', 'model.layers.24.input_layernorm.bias', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.25.self_attn.dense.weight', 'model.layers.25.self_attn.dense.bias', 'model.layers.25.mlp.fc1.weight', 'model.layers.25.mlp.fc1.bias', 'model.layers.25.mlp.fc2.weight', 'model.layers.25.mlp.fc2.bias', 'model.layers.25.input_layernorm.weight', 'model.layers.25.input_layernorm.bias', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.26.self_attn.dense.weight', 'model.layers.26.self_attn.dense.bias', 'model.layers.26.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.26.input_layernorm.weight', 'model.layers.26.input_layernorm.bias', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.27.self_attn.dense.weight', 'model.layers.27.self_attn.dense.bias', 'model.layers.27.mlp.fc1.weight', 'model.layers.27.mlp.fc1.bias', 'model.layers.27.mlp.fc2.weight', 'model.layers.27.mlp.fc2.bias', 'model.layers.27.input_layernorm.weight', 'model.layers.27.input_layernorm.bias', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.28.self_attn.dense.weight', 'model.layers.28.self_attn.dense.bias', 'model.layers.28.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.28.input_layernorm.weight', 'model.layers.28.input_layernorm.bias', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.29.self_attn.dense.weight', 'model.layers.29.self_attn.dense.bias', 'model.layers.29.mlp.fc1.weight', 'model.layers.29.mlp.fc1.bias', 'model.layers.29.mlp.fc2.weight', 'model.layers.29.mlp.fc2.bias', 'model.layers.29.input_layernorm.weight', 'model.layers.29.input_layernorm.bias', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.30.self_attn.dense.weight', 'model.layers.30.self_attn.dense.bias', 'model.layers.30.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.30.input_layernorm.weight', 'model.layers.30.input_layernorm.bias', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.31.self_attn.dense.weight', 'model.layers.31.self_attn.dense.bias', 'model.layers.31.mlp.fc1.weight', 'model.layers.31.mlp.fc1.bias', 'model.layers.31.mlp.fc2.weight', 'model.layers.31.mlp.fc2.bias', 'model.layers.31.input_layernorm.weight', 'model.layers.31.input_layernorm.bias', 'model.final_layernorm.weight', 'model.final_layernorm.bias', 'model.image_tower.image_tower.vision_model.embeddings.class_embedding', 'model.image_tower.image_tower.vision_model.embeddings.patch_embedding.weight', 'model.image_tower.image_tower.vision_model.embeddings.position_embedding.weight', 'model.image_tower.image_tower.vision_model.pre_layrnorm.weight', 'model.image_tower.image_tower.vision_model.pre_layrnorm.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.post_layernorm.weight', 'model.image_tower.image_tower.vision_model.post_layernorm.bias', 'model.mm_projector.image_spatial_proj.0.weight', 'model.mm_projector.image_spatial_proj.0.bias', 'model.mm_projector.image_spatial_proj.2.weight', 'model.mm_projector.image_spatial_proj.2.bias', 'lm_head.weight'])
[2024-05-17 07:30:17,793] [INFO] [launch.py:347:main] Process 1447349 exits successfully.
[2024-05-17 07:30:17,794] [INFO] [launch.py:347:main] Process 1447350 exits successfully.
[2024-05-17 07:30:17,794] [INFO] [launch.py:347:main] Process 1447351 exits successfully.
[2024-05-17 07:30:17,794] [INFO] [launch.py:347:main] Process 1447348 exits successfully.
odict_keys(['model.embed_tokens.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.0.self_attn.dense.weight', 'model.layers.0.self_attn.dense.bias', 'model.layers.0.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.0.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.0.input_layernorm.weight', 'model.layers.0.input_layernorm.bias', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.1.self_attn.dense.weight', 'model.layers.1.self_attn.dense.bias', 'model.layers.1.mlp.fc1.weight', 'model.layers.1.mlp.fc1.bias', 'model.layers.1.mlp.fc2.weight', 'model.layers.1.mlp.fc2.bias', 'model.layers.1.input_layernorm.weight', 'model.layers.1.input_layernorm.bias', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.2.self_attn.dense.weight', 'model.layers.2.self_attn.dense.bias', 'model.layers.2.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.2.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.2.input_layernorm.weight', 'model.layers.2.input_layernorm.bias', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.3.self_attn.dense.weight', 'model.layers.3.self_attn.dense.bias', 'model.layers.3.mlp.fc1.weight', 'model.layers.3.mlp.fc1.bias', 'model.layers.3.mlp.fc2.weight', 'model.layers.3.mlp.fc2.bias', 'model.layers.3.input_layernorm.weight', 'model.layers.3.input_layernorm.bias', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.4.self_attn.dense.weight', 'model.layers.4.self_attn.dense.bias', 'model.layers.4.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.4.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.4.input_layernorm.weight', 'model.layers.4.input_layernorm.bias', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.5.self_attn.dense.weight', 'model.layers.5.self_attn.dense.bias', 'model.layers.5.mlp.fc1.weight', 'model.layers.5.mlp.fc1.bias', 'model.layers.5.mlp.fc2.weight', 'model.layers.5.mlp.fc2.bias', 'model.layers.5.input_layernorm.weight', 'model.layers.5.input_layernorm.bias', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.6.self_attn.dense.weight', 'model.layers.6.self_attn.dense.bias', 'model.layers.6.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.6.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.6.input_layernorm.weight', 'model.layers.6.input_layernorm.bias', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.7.self_attn.dense.weight', 'model.layers.7.self_attn.dense.bias', 'model.layers.7.mlp.fc1.weight', 'model.layers.7.mlp.fc1.bias', 'model.layers.7.mlp.fc2.weight', 'model.layers.7.mlp.fc2.bias', 'model.layers.7.input_layernorm.weight', 'model.layers.7.input_layernorm.bias', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.8.self_attn.dense.weight', 'model.layers.8.self_attn.dense.bias', 'model.layers.8.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.8.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.8.input_layernorm.weight', 'model.layers.8.input_layernorm.bias', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.9.self_attn.dense.weight', 'model.layers.9.self_attn.dense.bias', 'model.layers.9.mlp.fc1.weight', 'model.layers.9.mlp.fc1.bias', 'model.layers.9.mlp.fc2.weight', 'model.layers.9.mlp.fc2.bias', 'model.layers.9.input_layernorm.weight', 'model.layers.9.input_layernorm.bias', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.10.self_attn.dense.weight', 'model.layers.10.self_attn.dense.bias', 'model.layers.10.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.10.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.10.input_layernorm.weight', 'model.layers.10.input_layernorm.bias', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.11.self_attn.dense.weight', 'model.layers.11.self_attn.dense.bias', 'model.layers.11.mlp.fc1.weight', 'model.layers.11.mlp.fc1.bias', 'model.layers.11.mlp.fc2.weight', 'model.layers.11.mlp.fc2.bias', 'model.layers.11.input_layernorm.weight', 'model.layers.11.input_layernorm.bias', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.12.self_attn.dense.weight', 'model.layers.12.self_attn.dense.bias', 'model.layers.12.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.12.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.12.input_layernorm.weight', 'model.layers.12.input_layernorm.bias', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.13.self_attn.dense.weight', 'model.layers.13.self_attn.dense.bias', 'model.layers.13.mlp.fc1.weight', 'model.layers.13.mlp.fc1.bias', 'model.layers.13.mlp.fc2.weight', 'model.layers.13.mlp.fc2.bias', 'model.layers.13.input_layernorm.weight', 'model.layers.13.input_layernorm.bias', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.14.self_attn.dense.weight', 'model.layers.14.self_attn.dense.bias', 'model.layers.14.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.14.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.14.input_layernorm.weight', 'model.layers.14.input_layernorm.bias', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.15.self_attn.dense.weight', 'model.layers.15.self_attn.dense.bias', 'model.layers.15.mlp.fc1.weight', 'model.layers.15.mlp.fc1.bias', 'model.layers.15.mlp.fc2.weight', 'model.layers.15.mlp.fc2.bias', 'model.layers.15.input_layernorm.weight', 'model.layers.15.input_layernorm.bias', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.16.self_attn.dense.weight', 'model.layers.16.self_attn.dense.bias', 'model.layers.16.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.16.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.16.input_layernorm.weight', 'model.layers.16.input_layernorm.bias', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.17.self_attn.dense.weight', 'model.layers.17.self_attn.dense.bias', 'model.layers.17.mlp.fc1.weight', 'model.layers.17.mlp.fc1.bias', 'model.layers.17.mlp.fc2.weight', 'model.layers.17.mlp.fc2.bias', 'model.layers.17.input_layernorm.weight', 'model.layers.17.input_layernorm.bias', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.18.self_attn.dense.weight', 'model.layers.18.self_attn.dense.bias', 'model.layers.18.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.18.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.18.input_layernorm.weight', 'model.layers.18.input_layernorm.bias', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.19.self_attn.dense.weight', 'model.layers.19.self_attn.dense.bias', 'model.layers.19.mlp.fc1.weight', 'model.layers.19.mlp.fc1.bias', 'model.layers.19.mlp.fc2.weight', 'model.layers.19.mlp.fc2.bias', 'model.layers.19.input_layernorm.weight', 'model.layers.19.input_layernorm.bias', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.20.self_attn.dense.weight', 'model.layers.20.self_attn.dense.bias', 'model.layers.20.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.20.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.20.input_layernorm.weight', 'model.layers.20.input_layernorm.bias', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.21.self_attn.dense.weight', 'model.layers.21.self_attn.dense.bias', 'model.layers.21.mlp.fc1.weight', 'model.layers.21.mlp.fc1.bias', 'model.layers.21.mlp.fc2.weight', 'model.layers.21.mlp.fc2.bias', 'model.layers.21.input_layernorm.weight', 'model.layers.21.input_layernorm.bias', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.22.self_attn.dense.weight', 'model.layers.22.self_attn.dense.bias', 'model.layers.22.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.22.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.22.input_layernorm.weight', 'model.layers.22.input_layernorm.bias', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.23.self_attn.dense.weight', 'model.layers.23.self_attn.dense.bias', 'model.layers.23.mlp.fc1.weight', 'model.layers.23.mlp.fc1.bias', 'model.layers.23.mlp.fc2.weight', 'model.layers.23.mlp.fc2.bias', 'model.layers.23.input_layernorm.weight', 'model.layers.23.input_layernorm.bias', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.24.self_attn.dense.weight', 'model.layers.24.self_attn.dense.bias', 'model.layers.24.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.24.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.24.input_layernorm.weight', 'model.layers.24.input_layernorm.bias', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.25.self_attn.dense.weight', 'model.layers.25.self_attn.dense.bias', 'model.layers.25.mlp.fc1.weight', 'model.layers.25.mlp.fc1.bias', 'model.layers.25.mlp.fc2.weight', 'model.layers.25.mlp.fc2.bias', 'model.layers.25.input_layernorm.weight', 'model.layers.25.input_layernorm.bias', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.26.self_attn.dense.weight', 'model.layers.26.self_attn.dense.bias', 'model.layers.26.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.26.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.26.input_layernorm.weight', 'model.layers.26.input_layernorm.bias', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.27.self_attn.dense.weight', 'model.layers.27.self_attn.dense.bias', 'model.layers.27.mlp.fc1.weight', 'model.layers.27.mlp.fc1.bias', 'model.layers.27.mlp.fc2.weight', 'model.layers.27.mlp.fc2.bias', 'model.layers.27.input_layernorm.weight', 'model.layers.27.input_layernorm.bias', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.28.self_attn.dense.weight', 'model.layers.28.self_attn.dense.bias', 'model.layers.28.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.28.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.28.input_layernorm.weight', 'model.layers.28.input_layernorm.bias', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.29.self_attn.dense.weight', 'model.layers.29.self_attn.dense.bias', 'model.layers.29.mlp.fc1.weight', 'model.layers.29.mlp.fc1.bias', 'model.layers.29.mlp.fc2.weight', 'model.layers.29.mlp.fc2.bias', 'model.layers.29.input_layernorm.weight', 'model.layers.29.input_layernorm.bias', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.30.self_attn.dense.weight', 'model.layers.30.self_attn.dense.bias', 'model.layers.30.mlp.deepspeed_moe.gate.wg.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.0.fc2.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.1.fc2.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.2.fc2.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc1.bias', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.weight', 'model.layers.30.mlp.deepspeed_moe.experts.deepspeed_experts.3.fc2.bias', 'model.layers.30.input_layernorm.weight', 'model.layers.30.input_layernorm.bias', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.31.self_attn.dense.weight', 'model.layers.31.self_attn.dense.bias', 'model.layers.31.mlp.fc1.weight', 'model.layers.31.mlp.fc1.bias', 'model.layers.31.mlp.fc2.weight', 'model.layers.31.mlp.fc2.bias', 'model.layers.31.input_layernorm.weight', 'model.layers.31.input_layernorm.bias', 'model.final_layernorm.weight', 'model.final_layernorm.bias', 'model.image_tower.image_tower.vision_model.embeddings.class_embedding', 'model.image_tower.image_tower.vision_model.embeddings.patch_embedding.weight', 'model.image_tower.image_tower.vision_model.embeddings.position_embedding.weight', 'model.image_tower.image_tower.vision_model.pre_layrnorm.weight', 'model.image_tower.image_tower.vision_model.pre_layrnorm.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.image_tower.image_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.image_tower.image_tower.vision_model.post_layernorm.weight', 'model.image_tower.image_tower.vision_model.post_layernorm.bias', 'model.mm_projector.image_spatial_proj.0.weight', 'model.mm_projector.image_spatial_proj.0.bias', 'model.mm_projector.image_spatial_proj.2.weight', 'model.mm_projector.image_spatial_proj.2.bias', 'lm_head.weight'])
[2024-05-17 07:30:45,797] [INFO] [launch.py:347:main] Process 1447347 exits successfully.
